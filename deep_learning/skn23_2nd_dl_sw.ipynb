{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9b513b",
   "metadata": {},
   "source": [
    "### 데이터 로드 + 기본구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1154dd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seung\\Desktop\\SKN23\\dl\\dl_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DL (PyTorch)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import joblib\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "# 재현성\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_STATE)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "445c152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seung\\AppData\\Local\\Temp\\ipykernel_21532\\3282841514.py:1: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('./data/steam_reviews_last365d.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/steam_reviews_last365d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c14c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['appid', 'recommendationid', 'steamid', 'num_games_owned',\n",
       "       'num_reviews_author', 'playtime_forever', 'playtime_last_two_weeks',\n",
       "       'playtime_at_review', 'deck_playtime_at_review', 'last_played',\n",
       "       'language', 'review', 'timestamp_created', 'timestamp_updated',\n",
       "       'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score',\n",
       "       'comment_count', 'steam_purchase', 'received_for_free',\n",
       "       'written_during_early_access', 'developer_response',\n",
       "       'timestamp_dev_responded', 'primarily_steam_deck'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c08744fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "appid                                0\n",
       "recommendationid                     0\n",
       "steamid                              0\n",
       "num_games_owned                      0\n",
       "num_reviews_author                   0\n",
       "playtime_forever                     0\n",
       "playtime_last_two_weeks              0\n",
       "playtime_at_review                   0\n",
       "deck_playtime_at_review        4736661\n",
       "last_played                          0\n",
       "language                             0\n",
       "review                           15761\n",
       "timestamp_created                    0\n",
       "timestamp_updated                    0\n",
       "voted_up                             0\n",
       "votes_up                             0\n",
       "votes_funny                          0\n",
       "weighted_vote_score                  0\n",
       "comment_count                        0\n",
       "steam_purchase                       0\n",
       "received_for_free                    0\n",
       "written_during_early_access          0\n",
       "developer_response             4824716\n",
       "timestamp_dev_responded        4824716\n",
       "primarily_steam_deck                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상위 50개 게임으로만 이루어진 데이터\n",
    "appid_counts = df['appid'].value_counts()\n",
    "top50_appids = appid_counts.head(50).index.tolist()\n",
    "df_top50 = df[df['appid'].isin(top50_appids)].copy()\n",
    "\n",
    "# 결측치 확인\n",
    "df_top50.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e108b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "appid                              0\n",
       "recommendationid                   0\n",
       "steamid                            0\n",
       "num_games_owned                    0\n",
       "num_reviews_author                 0\n",
       "playtime_forever                   0\n",
       "playtime_last_two_weeks            0\n",
       "playtime_at_review                 0\n",
       "last_played                        0\n",
       "language                           0\n",
       "review                         15761\n",
       "timestamp_created                  0\n",
       "timestamp_updated                  0\n",
       "voted_up                           0\n",
       "votes_up                           0\n",
       "votes_funny                        0\n",
       "weighted_vote_score                0\n",
       "comment_count                      0\n",
       "steam_purchase                     0\n",
       "received_for_free                  0\n",
       "written_during_early_access        0\n",
       "primarily_steam_deck               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 있는 컬럼들 모두 제거\n",
    "df_model = df_top50.drop(columns=['deck_playtime_at_review', 'developer_response', 'timestamp_dev_responded'])\n",
    "df_model.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b368f2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>steamid</th>\n",
       "      <th>num_games_owned</th>\n",
       "      <th>num_reviews_author</th>\n",
       "      <th>playtime_forever</th>\n",
       "      <th>playtime_last_two_weeks</th>\n",
       "      <th>playtime_at_review</th>\n",
       "      <th>last_played</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp_updated</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>weighted_vote_score</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>steam_purchase</th>\n",
       "      <th>received_for_free</th>\n",
       "      <th>written_during_early_access</th>\n",
       "      <th>primarily_steam_deck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27798</th>\n",
       "      <td>2139460</td>\n",
       "      <td>215256415</td>\n",
       "      <td>76561198092089560</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1659</td>\n",
       "      <td>1659</td>\n",
       "      <td>1628.0</td>\n",
       "      <td>1767647101</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>1767645356</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27799</th>\n",
       "      <td>2139460</td>\n",
       "      <td>215256182</td>\n",
       "      <td>76561197995642012</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>370</td>\n",
       "      <td>367</td>\n",
       "      <td>339.0</td>\n",
       "      <td>1767646994</td>\n",
       "      <td>french</td>\n",
       "      <td>...</td>\n",
       "      <td>1767645190</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27800</th>\n",
       "      <td>2139460</td>\n",
       "      <td>215249671</td>\n",
       "      <td>76561198217416651</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>552</td>\n",
       "      <td>552</td>\n",
       "      <td>401.0</td>\n",
       "      <td>1767648127</td>\n",
       "      <td>greek</td>\n",
       "      <td>...</td>\n",
       "      <td>1767640383</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27801</th>\n",
       "      <td>2139460</td>\n",
       "      <td>215246874</td>\n",
       "      <td>76561198111964424</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1765836608</td>\n",
       "      <td>russian</td>\n",
       "      <td>...</td>\n",
       "      <td>1767638383</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27802</th>\n",
       "      <td>2139460</td>\n",
       "      <td>215244452</td>\n",
       "      <td>76561198000529800</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>47556</td>\n",
       "      <td>276</td>\n",
       "      <td>47519.0</td>\n",
       "      <td>1767638299</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>1767636538</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447568</th>\n",
       "      <td>570</td>\n",
       "      <td>192652367</td>\n",
       "      <td>76561199824228518</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "      <td>49329</td>\n",
       "      <td>9264</td>\n",
       "      <td>5671.0</td>\n",
       "      <td>1767667012</td>\n",
       "      <td>russian</td>\n",
       "      <td>...</td>\n",
       "      <td>1757669172</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447569</th>\n",
       "      <td>570</td>\n",
       "      <td>192652315</td>\n",
       "      <td>76561199509986279</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>129565</td>\n",
       "      <td>591</td>\n",
       "      <td>79079.0</td>\n",
       "      <td>1767661292</td>\n",
       "      <td>russian</td>\n",
       "      <td>...</td>\n",
       "      <td>1744542216</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447570</th>\n",
       "      <td>570</td>\n",
       "      <td>192652264</td>\n",
       "      <td>76561199699553706</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>36710</td>\n",
       "      <td>548</td>\n",
       "      <td>28793.0</td>\n",
       "      <td>1767315372</td>\n",
       "      <td>russian</td>\n",
       "      <td>...</td>\n",
       "      <td>1762351962</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447571</th>\n",
       "      <td>570</td>\n",
       "      <td>192652232</td>\n",
       "      <td>76561199815094533</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3633</td>\n",
       "      <td>0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>1766312795</td>\n",
       "      <td>russian</td>\n",
       "      <td>...</td>\n",
       "      <td>1744542138</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447572</th>\n",
       "      <td>570</td>\n",
       "      <td>192651805</td>\n",
       "      <td>76561199550876124</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>467</td>\n",
       "      <td>0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>1719835238</td>\n",
       "      <td>russian</td>\n",
       "      <td>...</td>\n",
       "      <td>1744541678</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4830884 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           appid  recommendationid            steamid  num_games_owned  \\\n",
       "27798    2139460         215256415  76561198092089560                0   \n",
       "27799    2139460         215256182  76561197995642012                0   \n",
       "27800    2139460         215249671  76561198217416651                0   \n",
       "27801    2139460         215246874  76561198111964424                0   \n",
       "27802    2139460         215244452  76561198000529800               85   \n",
       "...          ...               ...                ...              ...   \n",
       "5447568      570         192652367  76561199824228518               79   \n",
       "5447569      570         192652315  76561199509986279                0   \n",
       "5447570      570         192652264  76561199699553706               21   \n",
       "5447571      570         192652232  76561199815094533                2   \n",
       "5447572      570         192651805  76561199550876124               40   \n",
       "\n",
       "         num_reviews_author  playtime_forever  playtime_last_two_weeks  \\\n",
       "27798                     1              1659                     1659   \n",
       "27799                     4               370                      367   \n",
       "27800                    32               552                      552   \n",
       "27801                    16               146                        0   \n",
       "27802                     1             47556                      276   \n",
       "...                     ...               ...                      ...   \n",
       "5447568                   7             49329                     9264   \n",
       "5447569                   1            129565                      591   \n",
       "5447570                   4             36710                      548   \n",
       "5447571                   1              3633                        0   \n",
       "5447572                   4               467                        0   \n",
       "\n",
       "         playtime_at_review  last_played language  ... timestamp_updated  \\\n",
       "27798                1628.0   1767647101  english  ...        1767645356   \n",
       "27799                 339.0   1767646994   french  ...        1767645190   \n",
       "27800                 401.0   1767648127    greek  ...        1767640383   \n",
       "27801                 146.0   1765836608  russian  ...        1767638383   \n",
       "27802               47519.0   1767638299  english  ...        1767636538   \n",
       "...                     ...          ...      ...  ...               ...   \n",
       "5447568              5671.0   1767667012  russian  ...        1757669172   \n",
       "5447569             79079.0   1767661292  russian  ...        1744542216   \n",
       "5447570             28793.0   1767315372  russian  ...        1762351962   \n",
       "5447571              1422.0   1766312795  russian  ...        1744542138   \n",
       "5447572               467.0   1719835238  russian  ...        1744541678   \n",
       "\n",
       "         voted_up  votes_up  votes_funny  weighted_vote_score  comment_count  \\\n",
       "27798        True         0            0              0.50000              0   \n",
       "27799        True         0            0              0.50000              0   \n",
       "27800        True         0            0              0.50000              0   \n",
       "27801       False         0            0              0.50000              0   \n",
       "27802        True         0            0              0.50000              0   \n",
       "...           ...       ...          ...                  ...            ...   \n",
       "5447568      True         0            0              0.50000              0   \n",
       "5447569     False         0            0              0.50000              0   \n",
       "5447570      True         0            0              0.50000              0   \n",
       "5447571      True         1            0              0.52381              1   \n",
       "5447572      True         1            0              0.52381              0   \n",
       "\n",
       "         steam_purchase  received_for_free  written_during_early_access  \\\n",
       "27798             False              False                        False   \n",
       "27799             False              False                        False   \n",
       "27800             False              False                        False   \n",
       "27801             False              False                        False   \n",
       "27802             False              False                        False   \n",
       "...                 ...                ...                          ...   \n",
       "5447568           False               True                        False   \n",
       "5447569           False              False                        False   \n",
       "5447570           False              False                        False   \n",
       "5447571           False              False                        False   \n",
       "5447572           False              False                        False   \n",
       "\n",
       "         primarily_steam_deck  \n",
       "27798                   False  \n",
       "27799                   False  \n",
       "27800                   False  \n",
       "27801                   False  \n",
       "27802                   False  \n",
       "...                       ...  \n",
       "5447568                 False  \n",
       "5447569                 False  \n",
       "5447570                 False  \n",
       "5447571                 False  \n",
       "5447572                 False  \n",
       "\n",
       "[4830884 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ed228d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game_style\n",
       "online    2467704\n",
       "video     1427383\n",
       "story      935797\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top50 기반으로 매핑 (네가 적어준 game_style 그대로 반영)\n",
    "STYLE_MAP = {\n",
    "    3241660: \"online\",  # R.E.P.O\n",
    "    2807960: \"online\",  # Battlefield™ 6\n",
    "    730:     \"online\",  # Counter-Strike 2\n",
    "    1808500: \"online\",  # ARC Raiders\n",
    "    1030300: \"story\",   # Hollow Knight: Silksong\n",
    "    570:     \"online\",  # Dota 2\n",
    "    578080:  \"online\",  # PUBG\n",
    "    2246340: \"video\",   # Monster Hunter Wilds\n",
    "    2592160: \"story\",   # Dispatch\n",
    "    553850:  \"online\",  # HELLDIVERS™ 2\n",
    "    3240220: \"online\",  # Grand Theft Auto V Enhanced\n",
    "    1091500: \"story\",   # Cyberpunk 2077\n",
    "    1903340: \"video\",   # Clair Obscur: Expedition 33\n",
    "    2001120: \"story\",   # Split Fiction\n",
    "    1245620: \"video\",   # Elden Ring\n",
    "    1086940: \"video\",   # Baldur's Gate 3\n",
    "    1144200: \"online\",  # Ready or Not\n",
    "    3167020: \"video\",   # Escape From Duckov\n",
    "    3564740: \"online\",  # Where Winds Meet\n",
    "    227300:  \"video\",   # Euro Truck Simulator 2\n",
    "    108600:  \"video\",   # Project Zomboid\n",
    "    413150:  \"video\",   # Stardew Valley\n",
    "    1771300: \"video\",   # Kingdom Come 2\n",
    "    3489700: \"story\",   # Stellar Blade™\n",
    "    1172470: \"online\",  # Apex\n",
    "    1222140: \"story\",   # Detroit: Become Human\n",
    "    1326470: \"video\",   # Sons Of The Forest\n",
    "    990080:  \"story\",   # Hogwarts Legacy\n",
    "    1551360: \"video\",   # Forza Horizon 5\n",
    "    1623730: \"video\",   # Palworld\n",
    "    1145350: \"video\",   # Hades II\n",
    "    2183900: \"story\",   # Space Marine AE\n",
    "    230410:  \"online\",  # Warframe\n",
    "    2139460: \"online\",  # Once Human\n",
    "    236390:  \"online\",  # War Thunder\n",
    "    440:     \"online\",  # Team Fortress 2\n",
    "    1973530: \"online\",  # Limbus Company\n",
    "    394360:  \"video\",   # Hearts of Iron IV\n",
    "    3932890: \"online\",  # Escape from Tarkov\n",
    "    526870:  \"video\",   # Satisfactory\n",
    "    3513350: \"online\",  # Wuthering Waves\n",
    "    3405690: \"online\",  # EA SPORTS FC™ 26\n",
    "    2622380: \"video\",   # ELDEN RING NIGHTREIGN\n",
    "    814380:  \"video\",   # Sekiro™: Shadows Die Twice - GOTY Edition\n",
    "    648800:  \"video\",   # Raft\n",
    "    3159330: \"story\",   # Assassin’s Creed Shadows\n",
    "    3527290: \"video\",   # PEAK\n",
    "    2651280: \"story\",   # Spider-Man 2\n",
    "    294100:  \"video\",   # RimWorld\n",
    "    1222670: \"video\",   # The Sims 4\n",
    "}\n",
    "\n",
    "# game_style 컬럼 생성\n",
    "df_model[\"game_style\"] = df_model[\"appid\"].map(STYLE_MAP)\n",
    "df_model[\"game_style\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2eab15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_cnt</th>\n",
       "      <th>review_na_cnt</th>\n",
       "      <th>review_na_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3241660</th>\n",
       "      <td>341851</td>\n",
       "      <td>1067</td>\n",
       "      <td>0.003121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807960</th>\n",
       "      <td>301260</td>\n",
       "      <td>1051</td>\n",
       "      <td>0.003489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808500</th>\n",
       "      <td>253341</td>\n",
       "      <td>991</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240220</th>\n",
       "      <td>139431</td>\n",
       "      <td>675</td>\n",
       "      <td>0.004841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>273327</td>\n",
       "      <td>668</td>\n",
       "      <td>0.002444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091500</th>\n",
       "      <td>120404</td>\n",
       "      <td>566</td>\n",
       "      <td>0.004701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553850</th>\n",
       "      <td>148578</td>\n",
       "      <td>510</td>\n",
       "      <td>0.003433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578080</th>\n",
       "      <td>194464</td>\n",
       "      <td>500</td>\n",
       "      <td>0.002571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030300</th>\n",
       "      <td>239171</td>\n",
       "      <td>493</td>\n",
       "      <td>0.002061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086940</th>\n",
       "      <td>105688</td>\n",
       "      <td>474</td>\n",
       "      <td>0.004485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227300</th>\n",
       "      <td>92691</td>\n",
       "      <td>466</td>\n",
       "      <td>0.005027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245620</th>\n",
       "      <td>109316</td>\n",
       "      <td>390</td>\n",
       "      <td>0.003568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592160</th>\n",
       "      <td>151041</td>\n",
       "      <td>377</td>\n",
       "      <td>0.002496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990080</th>\n",
       "      <td>58136</td>\n",
       "      <td>372</td>\n",
       "      <td>0.006399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144200</th>\n",
       "      <td>98623</td>\n",
       "      <td>371</td>\n",
       "      <td>0.003762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246340</th>\n",
       "      <td>158188</td>\n",
       "      <td>322</td>\n",
       "      <td>0.002036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903340</th>\n",
       "      <td>119877</td>\n",
       "      <td>314</td>\n",
       "      <td>0.002619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551360</th>\n",
       "      <td>53383</td>\n",
       "      <td>310</td>\n",
       "      <td>0.005807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623730</th>\n",
       "      <td>53348</td>\n",
       "      <td>299</td>\n",
       "      <td>0.005605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>204419</td>\n",
       "      <td>296</td>\n",
       "      <td>0.001448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108600</th>\n",
       "      <td>83385</td>\n",
       "      <td>291</td>\n",
       "      <td>0.003490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564740</th>\n",
       "      <td>93928</td>\n",
       "      <td>290</td>\n",
       "      <td>0.003087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771300</th>\n",
       "      <td>80468</td>\n",
       "      <td>274</td>\n",
       "      <td>0.003405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326470</th>\n",
       "      <td>59603</td>\n",
       "      <td>265</td>\n",
       "      <td>0.004446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222140</th>\n",
       "      <td>64658</td>\n",
       "      <td>262</td>\n",
       "      <td>0.004052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413150</th>\n",
       "      <td>81595</td>\n",
       "      <td>256</td>\n",
       "      <td>0.003137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526870</th>\n",
       "      <td>40554</td>\n",
       "      <td>255</td>\n",
       "      <td>0.006288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172470</th>\n",
       "      <td>72148</td>\n",
       "      <td>245</td>\n",
       "      <td>0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145350</th>\n",
       "      <td>51645</td>\n",
       "      <td>232</td>\n",
       "      <td>0.004492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001120</th>\n",
       "      <td>109858</td>\n",
       "      <td>217</td>\n",
       "      <td>0.001975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         total_cnt  review_na_cnt  review_na_ratio\n",
       "appid                                             \n",
       "3241660     341851           1067         0.003121\n",
       "2807960     301260           1051         0.003489\n",
       "1808500     253341            991         0.003912\n",
       "3240220     139431            675         0.004841\n",
       "730         273327            668         0.002444\n",
       "1091500     120404            566         0.004701\n",
       "553850      148578            510         0.003433\n",
       "578080      194464            500         0.002571\n",
       "1030300     239171            493         0.002061\n",
       "1086940     105688            474         0.004485\n",
       "227300       92691            466         0.005027\n",
       "1245620     109316            390         0.003568\n",
       "2592160     151041            377         0.002496\n",
       "990080       58136            372         0.006399\n",
       "1144200      98623            371         0.003762\n",
       "2246340     158188            322         0.002036\n",
       "1903340     119877            314         0.002619\n",
       "1551360      53383            310         0.005807\n",
       "1623730      53348            299         0.005605\n",
       "570         204419            296         0.001448\n",
       "108600       83385            291         0.003490\n",
       "3564740      93928            290         0.003087\n",
       "1771300      80468            274         0.003405\n",
       "1326470      59603            265         0.004446\n",
       "1222140      64658            262         0.004052\n",
       "413150       81595            256         0.003137\n",
       "526870       40554            255         0.006288\n",
       "1172470      72148            245         0.003396\n",
       "1145350      51645            232         0.004492\n",
       "2001120     109858            217         0.001975"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# appid별 review 결측치 분포\n",
    "review_na_by_app = (\n",
    "    df_model.groupby(\"appid\")[\"review\"]\n",
    "      .apply(lambda s: s.isna().sum())\n",
    "      .rename(\"review_na_cnt\")\n",
    "      .to_frame()\n",
    ")\n",
    "\n",
    "# appid별 전체 행 수\n",
    "total_by_app = df_model.groupby(\"appid\").size().rename(\"total_cnt\").to_frame()\n",
    "\n",
    "# 합치기 + 비율\n",
    "review_na_stats = (\n",
    "    total_by_app.join(review_na_by_app, how=\"left\")\n",
    "                .fillna({\"review_na_cnt\": 0})\n",
    ")\n",
    "\n",
    "review_na_stats[\"review_na_ratio\"] = review_na_stats[\"review_na_cnt\"] / review_na_stats[\"total_cnt\"]\n",
    "\n",
    "# 결측치 많은 순으로 확인\n",
    "review_na_stats.sort_values(\"review_na_cnt\", ascending=False).head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd4c9be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[drop NaN review] before=4,830,884 -> after=4,815,123 (dropped 15,761)\n"
     ]
    }
   ],
   "source": [
    "# review NaN 드롭\n",
    "before = len(df_model)\n",
    "df_model = df_model[df_model[\"review\"].notna()].copy()\n",
    "after = len(df_model)\n",
    "\n",
    "print(f\"[drop NaN review] before={before:,} -> after={after:,} (dropped {before-after:,})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec5fb241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model[['review']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d66aabd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_cnt</th>\n",
       "      <th>blank_cnt</th>\n",
       "      <th>blank_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>272659</td>\n",
       "      <td>186</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241660</th>\n",
       "      <td>340784</td>\n",
       "      <td>159</td>\n",
       "      <td>0.000467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240220</th>\n",
       "      <td>138756</td>\n",
       "      <td>130</td>\n",
       "      <td>0.000937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807960</th>\n",
       "      <td>300209</td>\n",
       "      <td>121</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578080</th>\n",
       "      <td>193964</td>\n",
       "      <td>111</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>204123</td>\n",
       "      <td>94</td>\n",
       "      <td>0.000461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227300</th>\n",
       "      <td>92225</td>\n",
       "      <td>74</td>\n",
       "      <td>0.000802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808500</th>\n",
       "      <td>252350</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030300</th>\n",
       "      <td>238678</td>\n",
       "      <td>59</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553850</th>\n",
       "      <td>148068</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245620</th>\n",
       "      <td>108926</td>\n",
       "      <td>52</td>\n",
       "      <td>0.000477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172470</th>\n",
       "      <td>71903</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108600</th>\n",
       "      <td>83094</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144200</th>\n",
       "      <td>98252</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551360</th>\n",
       "      <td>53073</td>\n",
       "      <td>37</td>\n",
       "      <td>0.000697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973530</th>\n",
       "      <td>43098</td>\n",
       "      <td>37</td>\n",
       "      <td>0.000859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091500</th>\n",
       "      <td>119838</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592160</th>\n",
       "      <td>150664</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246340</th>\n",
       "      <td>157866</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222140</th>\n",
       "      <td>64396</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086940</th>\n",
       "      <td>105214</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413150</th>\n",
       "      <td>81339</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3405690</th>\n",
       "      <td>36185</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903340</th>\n",
       "      <td>119563</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771300</th>\n",
       "      <td>80194</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001120</th>\n",
       "      <td>109641</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394360</th>\n",
       "      <td>41990</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326470</th>\n",
       "      <td>59338</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990080</th>\n",
       "      <td>57764</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236390</th>\n",
       "      <td>45853</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513350</th>\n",
       "      <td>37648</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526870</th>\n",
       "      <td>40299</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814380</th>\n",
       "      <td>34875</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230410</th>\n",
       "      <td>48998</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183900</th>\n",
       "      <td>49560</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222670</th>\n",
       "      <td>30569</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>44221</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145350</th>\n",
       "      <td>51413</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139460</th>\n",
       "      <td>48154</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648800</th>\n",
       "      <td>34660</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623730</th>\n",
       "      <td>53049</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564740</th>\n",
       "      <td>93638</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622380</th>\n",
       "      <td>35210</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527290</th>\n",
       "      <td>31730</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489700</th>\n",
       "      <td>78710</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294100</th>\n",
       "      <td>30839</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651280</th>\n",
       "      <td>31535</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932890</th>\n",
       "      <td>41240</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167020</th>\n",
       "      <td>96660</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159330</th>\n",
       "      <td>32108</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         total_cnt  blank_cnt  blank_ratio\n",
       "appid                                     \n",
       "730         272659        186     0.000682\n",
       "3241660     340784        159     0.000467\n",
       "3240220     138756        130     0.000937\n",
       "2807960     300209        121     0.000403\n",
       "578080      193964        111     0.000572\n",
       "570         204123         94     0.000461\n",
       "227300       92225         74     0.000802\n",
       "1808500     252350         73     0.000289\n",
       "1030300     238678         59     0.000247\n",
       "553850      148068         56     0.000378\n",
       "1245620     108926         52     0.000477\n",
       "1172470      71903         47     0.000654\n",
       "108600       83094         40     0.000481\n",
       "1144200      98252         39     0.000397\n",
       "1551360      53073         37     0.000697\n",
       "1973530      43098         37     0.000859\n",
       "1091500     119838         36     0.000300\n",
       "2592160     150664         35     0.000232\n",
       "2246340     157866         33     0.000209\n",
       "1222140      64396         30     0.000466\n",
       "1086940     105214         27     0.000257\n",
       "413150       81339         24     0.000295\n",
       "3405690      36185         23     0.000636\n",
       "1903340     119563         21     0.000176\n",
       "1771300      80194         20     0.000249\n",
       "2001120     109641         20     0.000182\n",
       "394360       41990         19     0.000452\n",
       "1326470      59338         19     0.000320\n",
       "990080       57764         18     0.000312\n",
       "236390       45853         18     0.000393\n",
       "3513350      37648         17     0.000452\n",
       "526870       40299         17     0.000422\n",
       "814380       34875         16     0.000459\n",
       "230410       48998         16     0.000327\n",
       "2183900      49560         16     0.000323\n",
       "1222670      30569         16     0.000523\n",
       "440          44221         15     0.000339\n",
       "1145350      51413         15     0.000292\n",
       "2139460      48154         14     0.000291\n",
       "648800       34660         14     0.000404\n",
       "1623730      53049         13     0.000245\n",
       "3564740      93638         11     0.000117\n",
       "2622380      35210         10     0.000284\n",
       "3527290      31730          9     0.000284\n",
       "3489700      78710          9     0.000114\n",
       "294100       30839          8     0.000259\n",
       "2651280      31535          8     0.000254\n",
       "3932890      41240          8     0.000194\n",
       "3167020      96660          6     0.000062\n",
       "3159330      32108          6     0.000187"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공백 리뷰 총 개수: 1902\n"
     ]
    }
   ],
   "source": [
    "# 공백/빈문자열(whitespace-only 포함) 마스크\n",
    "blank_mask = df_model[\"review\"].astype(str).str.strip().eq(\"\")\n",
    "\n",
    "blank_by_appid = (\n",
    "    df_model.assign(is_blank_review=blank_mask)\n",
    "            .groupby(\"appid\")[\"is_blank_review\"]\n",
    "            .agg(total_cnt=\"size\", blank_cnt=\"sum\")\n",
    ")\n",
    "\n",
    "blank_by_appid[\"blank_ratio\"] = blank_by_appid[\"blank_cnt\"] / blank_by_appid[\"total_cnt\"]\n",
    "\n",
    "# 공백 리뷰가 있는 appid만, blank_cnt 큰 순으로 보기\n",
    "blank_by_appid_nonzero = blank_by_appid[blank_by_appid[\"blank_cnt\"] > 0].sort_values(\"blank_cnt\", ascending=False)\n",
    "\n",
    "display(blank_by_appid_nonzero.head(50))\n",
    "print(\"공백 리뷰 총 개수:\", int(blank_mask.sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe6e58",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05571b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[drop blank review] before=4,815,123 -> after=4,813,221 (dropped 1,902)\n"
     ]
    }
   ],
   "source": [
    "# 공백/빈 문자열 리뷰 드롭\n",
    "before = len(df_model)\n",
    "\n",
    "blank_mask = df_model[\"review\"].astype(str).str.strip().eq(\"\")\n",
    "df_model = df_model[~blank_mask].copy()\n",
    "\n",
    "after = len(df_model)\n",
    "print(f\"[drop blank review] before={before:,} -> after={after:,} (dropped {before-after:,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0035ba25",
   "metadata": {},
   "source": [
    "- 결측치 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fd4b85",
   "metadata": {},
   "source": [
    "- 플레이 타임/시간 관련 수치 컬럼 : 숫자로 변환후 NaN을 0으로 채움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57de690d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seung\\AppData\\Local\\Temp\\ipykernel_21532\\4077362005.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df_model.loc[df_model[\"last_played\"] == 0, \"churn\"] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn\n",
      "False    3432753\n",
      "True     1380468\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# style별 churn 기준일(일 단위)\n",
    "STYLE_WINDOW_DAYS = {\n",
    "    \"online\": 7,\n",
    "    \"video\": 10,\n",
    "    \"story\": 5,\n",
    "}\n",
    "\n",
    "# 리뷰 시각 / 마지막 플레이 시각\n",
    "review_dt = pd.to_datetime(df_model[\"timestamp_created\"], unit=\"s\", errors=\"coerce\")\n",
    "last_dt   = pd.to_datetime(df_model[\"last_played\"], unit=\"s\", errors=\"coerce\")\n",
    "\n",
    "# 리뷰 이후 며칠 뒤에 마지막 플레이가 있었는지\n",
    "df_model[\"days_after_review\"] = (last_dt - review_dt).dt.days\n",
    "\n",
    "# game_style별 기준일 매핑 (none은 NaN)\n",
    "df_model[\"churn_window_days\"] = df_model[\"game_style\"].map(STYLE_WINDOW_DAYS)\n",
    "\n",
    "# 기본 churn: days_after_review < window 이면 churn=1 (떠난 것)\n",
    "df_model[\"churn\"] = df_model[\"days_after_review\"] < df_model[\"churn_window_days\"].astype(int)\n",
    "\n",
    "# 예외 처리(기존 규칙 유지)\n",
    "df_model.loc[df_model[\"last_played\"] == 0, \"churn\"] = 1\n",
    "df_model.loc[df_model[\"days_after_review\"] < 0, \"churn\"] = 1\n",
    "\n",
    "print(df_model[\"churn\"].value_counts(dropna=False).sort_index())\n",
    "\n",
    "# DL에서 타깃 확실히 int로 고정\n",
    "df_model[\"churn\"] = df_model[\"churn\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e374869",
   "metadata": {},
   "source": [
    "review / developer_response 텍스트 : NaN을 \"N\"으로 채움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1ac2efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model[['language']].nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1fb03b",
   "metadata": {},
   "source": [
    "- 원본 df를 df2로 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6999a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>steamid</th>\n",
       "      <th>num_games_owned</th>\n",
       "      <th>num_reviews_author</th>\n",
       "      <th>playtime_forever</th>\n",
       "      <th>playtime_last_two_weeks</th>\n",
       "      <th>playtime_at_review</th>\n",
       "      <th>last_played</th>\n",
       "      <th>timestamp_created</th>\n",
       "      <th>timestamp_updated</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>weighted_vote_score</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>days_after_review</th>\n",
       "      <th>churn_window_days</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "      <td>4.813221e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.637917e+06</td>\n",
       "      <td>2.034422e+08</td>\n",
       "      <td>7.656120e+16</td>\n",
       "      <td>7.224943e+01</td>\n",
       "      <td>1.093352e+01</td>\n",
       "      <td>1.398406e+04</td>\n",
       "      <td>4.346475e+02</td>\n",
       "      <td>1.067346e+04</td>\n",
       "      <td>1.761394e+09</td>\n",
       "      <td>1.756335e+09</td>\n",
       "      <td>1.756654e+09</td>\n",
       "      <td>1.038864e+00</td>\n",
       "      <td>1.820704e-01</td>\n",
       "      <td>5.029349e-01</td>\n",
       "      <td>6.856697e-02</td>\n",
       "      <td>5.806457e+01</td>\n",
       "      <td>7.498542e+00</td>\n",
       "      <td>2.868075e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.156278e+06</td>\n",
       "      <td>8.342337e+06</td>\n",
       "      <td>6.190886e+08</td>\n",
       "      <td>2.492080e+02</td>\n",
       "      <td>6.318230e+01</td>\n",
       "      <td>4.066221e+04</td>\n",
       "      <td>1.151922e+03</td>\n",
       "      <td>3.810909e+04</td>\n",
       "      <td>1.145637e+07</td>\n",
       "      <td>8.849875e+06</td>\n",
       "      <td>8.803059e+06</td>\n",
       "      <td>3.084613e+01</td>\n",
       "      <td>6.968658e+00</td>\n",
       "      <td>2.391883e-02</td>\n",
       "      <td>2.379588e+00</td>\n",
       "      <td>1.368769e+02</td>\n",
       "      <td>1.784596e+00</td>\n",
       "      <td>4.522709e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.400000e+02</td>\n",
       "      <td>1.848840e+08</td>\n",
       "      <td>7.656120e+16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.736122e+09</td>\n",
       "      <td>1.736122e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.213739e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.044100e+04</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.780800e+05</td>\n",
       "      <td>1.967549e+08</td>\n",
       "      <td>7.656120e+16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.500000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.490000e+02</td>\n",
       "      <td>1.759989e+09</td>\n",
       "      <td>1.749423e+09</td>\n",
       "      <td>1.749911e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.551360e+06</td>\n",
       "      <td>2.059368e+08</td>\n",
       "      <td>7.656120e+16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.166000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.093000e+03</td>\n",
       "      <td>1.765025e+09</td>\n",
       "      <td>1.759660e+09</td>\n",
       "      <td>1.760116e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.807960e+06</td>\n",
       "      <td>2.102846e+08</td>\n",
       "      <td>7.656120e+16</td>\n",
       "      <td>6.900000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.034100e+04</td>\n",
       "      <td>2.330000e+02</td>\n",
       "      <td>6.120000e+03</td>\n",
       "      <td>1.767091e+09</td>\n",
       "      <td>1.764041e+09</td>\n",
       "      <td>1.764091e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.020000e+02</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.932890e+06</td>\n",
       "      <td>2.152792e+08</td>\n",
       "      <td>7.656120e+16</td>\n",
       "      <td>3.816800e+04</td>\n",
       "      <td>1.974800e+04</td>\n",
       "      <td>2.919994e+06</td>\n",
       "      <td>3.664700e+04</td>\n",
       "      <td>2.789459e+06</td>\n",
       "      <td>1.767667e+09</td>\n",
       "      <td>1.767666e+09</td>\n",
       "      <td>1.767666e+09</td>\n",
       "      <td>2.009800e+04</td>\n",
       "      <td>6.372000e+03</td>\n",
       "      <td>9.958196e-01</td>\n",
       "      <td>4.500000e+03</td>\n",
       "      <td>3.640000e+02</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              appid  recommendationid       steamid  num_games_owned  \\\n",
       "count  4.813221e+06      4.813221e+06  4.813221e+06     4.813221e+06   \n",
       "mean   1.637917e+06      2.034422e+08  7.656120e+16     7.224943e+01   \n",
       "std    1.156278e+06      8.342337e+06  6.190886e+08     2.492080e+02   \n",
       "min    4.400000e+02      1.848840e+08  7.656120e+16     0.000000e+00   \n",
       "25%    5.780800e+05      1.967549e+08  7.656120e+16     0.000000e+00   \n",
       "50%    1.551360e+06      2.059368e+08  7.656120e+16     0.000000e+00   \n",
       "75%    2.807960e+06      2.102846e+08  7.656120e+16     6.900000e+01   \n",
       "max    3.932890e+06      2.152792e+08  7.656120e+16     3.816800e+04   \n",
       "\n",
       "       num_reviews_author  playtime_forever  playtime_last_two_weeks  \\\n",
       "count        4.813221e+06      4.813221e+06             4.813221e+06   \n",
       "mean         1.093352e+01      1.398406e+04             4.346475e+02   \n",
       "std          6.318230e+01      4.066221e+04             1.151922e+03   \n",
       "min          1.000000e+00      0.000000e+00             0.000000e+00   \n",
       "25%          2.000000e+00      1.500000e+03             0.000000e+00   \n",
       "50%          4.000000e+00      4.166000e+03             0.000000e+00   \n",
       "75%          1.000000e+01      1.034100e+04             2.330000e+02   \n",
       "max          1.974800e+04      2.919994e+06             3.664700e+04   \n",
       "\n",
       "       playtime_at_review   last_played  timestamp_created  timestamp_updated  \\\n",
       "count        4.813221e+06  4.813221e+06       4.813221e+06       4.813221e+06   \n",
       "mean         1.067346e+04  1.761394e+09       1.756335e+09       1.756654e+09   \n",
       "std          3.810909e+04  1.145637e+07       8.849875e+06       8.803059e+06   \n",
       "min          5.000000e+00  0.000000e+00       1.736122e+09       1.736122e+09   \n",
       "25%          6.490000e+02  1.759989e+09       1.749423e+09       1.749911e+09   \n",
       "50%          2.093000e+03  1.765025e+09       1.759660e+09       1.760116e+09   \n",
       "75%          6.120000e+03  1.767091e+09       1.764041e+09       1.764091e+09   \n",
       "max          2.789459e+06  1.767667e+09       1.767666e+09       1.767666e+09   \n",
       "\n",
       "           votes_up   votes_funny  weighted_vote_score  comment_count  \\\n",
       "count  4.813221e+06  4.813221e+06         4.813221e+06   4.813221e+06   \n",
       "mean   1.038864e+00  1.820704e-01         5.029349e-01   6.856697e-02   \n",
       "std    3.084613e+01  6.968658e+00         2.391883e-02   2.379588e+00   \n",
       "min    0.000000e+00  0.000000e+00         2.213739e-02   0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00         5.000000e-01   0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00         5.000000e-01   0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00         5.000000e-01   0.000000e+00   \n",
       "max    2.009800e+04  6.372000e+03         9.958196e-01   4.500000e+03   \n",
       "\n",
       "       days_after_review  churn_window_days         churn  \n",
       "count       4.813221e+06       4.813221e+06  4.813221e+06  \n",
       "mean        5.806457e+01       7.498542e+00  2.868075e-01  \n",
       "std         1.368769e+02       1.784596e+00  4.522709e-01  \n",
       "min        -2.044100e+04       5.000000e+00  0.000000e+00  \n",
       "25%         4.000000e+00       7.000000e+00  0.000000e+00  \n",
       "50%         3.400000e+01       7.000000e+00  0.000000e+00  \n",
       "75%         1.020000e+02       1.000000e+01  1.000000e+00  \n",
       "max         3.640000e+02       1.000000e+01  1.000000e+00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f3db0",
   "metadata": {},
   "source": [
    "- game_style 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f7e2507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good_review\n",
      "0    3525940\n",
      "1    1287281\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1) 언어별 키워드 사전\n",
    "LEXICON = {\n",
    "    \"english\": {\n",
    "        \"phrases\": [\n",
    "            r\"highly recommend(?:ed)?\",\n",
    "            r\"definitely recommend\",\n",
    "            r\"worth (?:buying|it|the money|the time)\",\n",
    "            r\"great game\",\n",
    "            r\"amazing game\",\n",
    "            r\"awesome game\",\n",
    "            r\"best game(?:s)?\",\n",
    "        ],\n",
    "        \"words\": [\n",
    "            r\"awesome\", r\"amazing\", r\"great\", r\"excellent\", r\"fantastic\", r\"incredible\",\n",
    "            r\"masterpiece\", r\"perfect\", r\"love\", r\"fun\", r\"enjoy\", r\"recommend\", r\"worth\",\n",
    "        ],\n",
    "        \"neg\": [\n",
    "            r\"not\\s+good\", r\"not\\s+great\", r\"not\\s+worth\",\n",
    "            r\"(?:do\\s*not|don't|dont)\\s+recommend\",\n",
    "            r\"(?:do\\s*not|don't|dont)\\s+buy\",\n",
    "            r\"can't\\s+recommend|cant\\s+recommend\",\n",
    "            r\"avoid\\b\", r\"refund\\b\",\n",
    "        ],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"spanish\": {\n",
    "        \"phrases\": [r\"muy bueno\", r\"vale la pena\", r\"lo recomiendo\", r\"recomendad[oa]\"],\n",
    "        \"words\": [r\"genial\", r\"excelente\", r\"buen[oa]\", r\"incre[ií]ble\", r\"recomiendo\", r\"recomendar\"],\n",
    "        \"neg\": [r\"no\\s+recomiendo\", r\"no\\s+vale\\s+la\\s+pena\", r\"no\\s+es\\s+buen[oa]\", r\"no\\s+merece\\s+la\\s+pena\", r\"no\\s+compr(?:es|ar)\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"latam\": {\n",
    "        \"phrases\": [r\"muy bueno\", r\"vale la pena\", r\"lo recomiendo\", r\"recomendad[oa]\"],\n",
    "        \"words\": [r\"genial\", r\"excelente\", r\"buen[oa]\", r\"incre[ií]ble\", r\"recomiendo\", r\"recomendar\"],\n",
    "        \"neg\": [r\"no\\s+recomiendo\", r\"no\\s+vale\\s+la\\s+pena\", r\"no\\s+es\\s+buen[oa]\", r\"no\\s+merece\\s+la\\s+pena\", r\"no\\s+compr(?:es|ar)\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"portuguese\": {\n",
    "        \"phrases\": [r\"vale a pena\", r\"recomendo\", r\"muito bom\", r\"jogo (?:muito )?bom\"],\n",
    "        \"words\": [r\"ótimo\", r\"excelente\", r\"incr[ií]vel\", r\"perfeito\", r\"divertido\", r\"recomendar\"],\n",
    "        \"neg\": [r\"não\\s+recomendo\", r\"nao\\s+recomendo\", r\"não\\s+vale\\s+a\\s+pena\", r\"nao\\s+vale\\s+a\\s+pena\", r\"não\\s+é\\s+bom\", r\"nao\\s+e\\s+bom\", r\"não\\s+compr(?:e|ar)\", r\"nao\\s+compr(?:e|ar)\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"brazilian\": {\n",
    "        \"phrases\": [r\"vale a pena\", r\"recomendo\", r\"muito bom\", r\"jogo (?:muito )?bom\"],\n",
    "        \"words\": [r\"ótimo\", r\"excelente\", r\"incr[ií]vel\", r\"perfeito\", r\"divertido\", r\"recomendar\"],\n",
    "        \"neg\": [r\"não\\s+recomendo\", r\"nao\\s+recomendo\", r\"não\\s+vale\\s+a\\s+pena\", r\"nao\\s+vale\\s+a\\s+pena\", r\"não\\s+é\\s+bom\", r\"nao\\s+e\\s+bom\", r\"não\\s+compr(?:e|ar)\", r\"nao\\s+compr(?:e|ar)\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"german\": {\n",
    "        \"phrases\": [r\"sehr gut\", r\"klare(?:s)? empfehlung\", r\"lohnt sich\", r\"absolut empfehl\"],\n",
    "        \"words\": [r\"genial\", r\"toll\", r\"super\", r\"großartig\", r\"exzellent\", r\"empfehle\", r\"empfehlenswert\"],\n",
    "        \"neg\": [r\"nicht\\s+empfehl\", r\"lohnt\\s+sich\\s+nicht\", r\"nicht\\s+gut\", r\"kau(?:f|ft)\\s+nicht\", r\"kein\\s+kauf\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"french\": {\n",
    "        \"phrases\": [r\"je recommande\", r\"vaut le coup\", r\"tr[eè]s bon\", r\"excellent jeu\"],\n",
    "        \"words\": [r\"g[eé]nial\", r\"excellent\", r\"super\", r\"incroyable\", r\"parfait\", r\"recommande\"],\n",
    "        \"neg\": [r\"je\\s+ne\\s+recommande\\s+pas\", r\"ne\\s+vaut\\s+pas\\s+le\\s+coup\", r\"pas\\s+bon\", r\"n['’]achetez\\s+pas\", r\"n['’]ach[eè]te\\s+pas\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"italian\": {\n",
    "        \"phrases\": [r\"lo consiglio\", r\"vale la pena\", r\"molto bello\", r\"gioco (?:molto )?bello\"],\n",
    "        \"words\": [r\"fantastico\", r\"ottimo\", r\"eccellente\", r\"stupendo\", r\"divertente\", r\"consiglio\", r\"consigliare\"],\n",
    "        \"neg\": [r\"non\\s+lo\\s+consiglio\", r\"non\\s+vale\\s+la\\s+pena\", r\"non\\s+[eè]\\s+bello\", r\"non\\s+compr(?:are|atelo)\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"dutch\": {\n",
    "        \"phrases\": [r\"zeker aanraden\", r\"de moeite waard\", r\"heel goed\", r\"geweldig spel\"],\n",
    "        \"words\": [r\"geweldig\", r\"fantastisch\", r\"super\", r\"leuk\", r\"aanraden\", r\"aanbevelen\", r\"waarde\"],\n",
    "        \"neg\": [r\"niet\\s+aanrad\", r\"niet\\s+de\\s+moeite\\s+waard\", r\"niet\\s+goed\", r\"koop\\s+niet\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"swedish\": {\n",
    "        \"phrases\": [r\"rekommenderar\", r\"värt det\", r\"jättebra\", r\"riktigt bra\"],\n",
    "        \"words\": [r\"fantastisk\", r\"grym\", r\"suverän\", r\"toppen\", r\"kul\", r\"rekommendera\", r\"värd\"],\n",
    "        \"neg\": [r\"rekommenderar\\s+inte\", r\"inte\\s+värt\", r\"inte\\s+bra\", r\"köp\\s+inte\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"norwegian\": {\n",
    "        \"phrases\": [r\"anbefaler\", r\"verdt det\", r\"kjempebra\", r\"veldig bra\"],\n",
    "        \"words\": [r\"fantastisk\", r\"råbra\", r\"suveren\", r\"gøy\", r\"anbefale\", r\"verdt\"],\n",
    "        \"neg\": [r\"anbefaler\\s+ikke\", r\"ikke\\s+verdt\", r\"ikke\\s+bra\", r\"ikke\\s+kjøp\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"danish\": {\n",
    "        \"phrases\": [r\"anbefaler\", r\"v[æa]rd at\", r\"mega god\", r\"rigtig god\"],\n",
    "        \"words\": [r\"fantastisk\", r\"fremragende\", r\"super\", r\"sjov\", r\"anbefale\", r\"v[æa]rd\"],\n",
    "        \"neg\": [r\"anbefaler\\s+ikke\", r\"ikke\\s+v[æa]rd\", r\"ikke\\s+god\", r\"k[oø]b\\s+ikke\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"finnish\": {\n",
    "        \"phrases\": [r\"suosittelen\", r\"todella hyv[äa]\", r\"sen arvoinen\", r\"hyv[äa] peli\"],\n",
    "        \"words\": [r\"loistava\", r\"mahtava\", r\"erinomainen\", r\"hauska\", r\"suositella\", r\"arvoinen\"],\n",
    "        \"neg\": [r\"en\\s+suosittele\", r\"ei\\s+kannata\", r\"ei\\s+hyv[äa]\", r\"älä\\s+osta\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"polish\": {\n",
    "        \"phrases\": [r\"polecam\", r\"warto\", r\"świetna gra\", r\"bardzo dobra\"],\n",
    "        \"words\": [r\"świetn[aey]\", r\"super\", r\"rewelacyjna\", r\"doskonała\", r\"polecić\", r\"warto\"],\n",
    "        \"neg\": [r\"nie\\s+polecam\", r\"nie\\s+warto\", r\"nie\\s+jest\\s+dobr\", r\"nie\\s+kupuj\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"czech\": {\n",
    "        \"phrases\": [r\"doporu[čc]uji\", r\"stoj[ií]\\s+za\\s+to\", r\"skv[ěe]l[aá]\", r\"v[ýy]born[aá]\"],\n",
    "        \"words\": [r\"super\", r\"skv[ěe]l\", r\"v[ýy]born\", r\"bav[ií]\", r\"doporu[čc]it\"],\n",
    "        \"neg\": [r\"nedoporu[čc]uji\", r\"nestoj[ií]\\s+za\\s+to\", r\"nen[ií]\\s+dobr\", r\"nekupuj\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"romanian\": {\n",
    "        \"phrases\": [r\"recomand\", r\"merit[ăa]\", r\"foarte bun\", r\"joc (?:foarte )?bun\"],\n",
    "        \"words\": [r\"excelent\", r\"minunat\", r\"super\", r\"recomanda\", r\"merit\"],\n",
    "        \"neg\": [r\"nu\\s+recomand\", r\"nu\\s+merit[ăa]\", r\"nu\\s+e\\s+bun\", r\"nu\\s+cump[ăa]ra\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"hungarian\": {\n",
    "        \"phrases\": [r\"aj[aá]nlom\", r\"meg[eé]ri\", r\"nagyon j[oó]\", r\"szuper j[aá]t[eé]k\"],\n",
    "        \"words\": [r\"szuper\", r\"fantasztikus\", r\"kiv[aá]l[oó]\", r\"nagyon\", r\"aj[aá]nlani\", r\"meg[eé]r\"],\n",
    "        \"neg\": [r\"nem\\s+aj[aá]nlom\", r\"nem\\s+[eé]ri\\s+meg\", r\"nem\\s+j[oó]\", r\"ne\\s+vedd\\s+meg\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"bulgarian\": {\n",
    "        \"phrases\": [r\"препоръч\", r\"много добра\", r\"страхотна\", r\"заслужава си\"],\n",
    "        \"words\": [r\"страхот\", r\"отлич\", r\"супер\", r\"препоръч\", r\"шедьовър\"],\n",
    "        \"neg\": [r\"не\\s+препоръч\", r\"не\\s+си\\s+струва\", r\"не\\s+е\\s+доб\", r\"не\\s+купувай\"],\n",
    "        \"boundary\": False,\n",
    "    },\n",
    "    \"greek\": {\n",
    "        \"phrases\": [r\"το\\s+προτείν\", r\"αξίζει\", r\"πολύ\\s+καλ\", r\"εξαιρετικ\"],\n",
    "        \"words\": [r\"τέλει\", r\"φοβε\", r\"εξαιρετικ\", r\"καταπληκτικ\", r\"προτείν\", r\"αξίζ\"],\n",
    "        \"neg\": [r\"δεν\\s+προτείν\", r\"δεν\\s+αξίζ\", r\"δεν\\s+είναι\\s+καλ\", r\"μην\\s+αγοράσ\"],\n",
    "        \"boundary\": False,\n",
    "    },\n",
    "    \"ukrainian\": {\n",
    "        \"phrases\": [r\"рекоменд\", r\"дуже\\s+хорош\", r\"варто\", r\"чудов\"],\n",
    "        \"words\": [r\"відмін\", r\"класн\", r\"шедевр\", r\"рекоменд\", r\"варто\"],\n",
    "        \"neg\": [r\"не\\s+рекоменд\", r\"не\\s+варто\", r\"не\\s+хорош\", r\"не\\s+купуй\"],\n",
    "        \"boundary\": False,\n",
    "    },\n",
    "    \"russian\": {\n",
    "        \"phrases\": [r\"рекоменд\", r\"очень\\s+хорош\", r\"стоит\", r\"шедевр\"],\n",
    "        \"words\": [r\"отлич\", r\"классн\", r\"супер\", r\"шедевр\", r\"рекоменд\", r\"стоит\"],\n",
    "        \"neg\": [r\"не\\s+рекоменд\", r\"не\\s+стоит\", r\"плох\", r\"не\\s+покупай\", r\"не\\s+берите\"],\n",
    "        \"boundary\": False,\n",
    "    },\n",
    "    \"turkish\": {\n",
    "        \"phrases\": [r\"kesinlikle tavsiye\", r\"tavsiye ederim\", r\"çok iyi\", r\"mükemmel\", r\"harika\"],\n",
    "        \"words\": [r\"güzel\", r\"mükemmel\", r\"harika\", r\"şahane\", r\"tavsiye\", r\"değer\"],\n",
    "        \"neg\": [r\"tavsiye etmem\", r\"tavsiye etmiyorum\", r\"iyi değil\", r\"alma\", r\"almayın\", r\"değmez\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"koreana\": {\n",
    "        \"phrases\": [r\"강추\", r\"완전 추천\", r\"강력 추천\", r\"갓겜\", r\"명작\", r\"존잼\", r\"개꿀잼\", r\"재밌\", r\"재미있\"],\n",
    "        \"words\": [r\"추천\", r\"최고\", r\"꿀잼\", r\"재미\", r\"좋다\", r\"훌륭\", r\"완벽\", r\"감동\"],\n",
    "        \"neg\": [r\"비추\", r\"추천\\s*안\", r\"추천\\s*하지\", r\"재미없\", r\"별로\", r\"최악\", r\"사지\\s*마\", r\"사지마\", r\"환불\"],\n",
    "        \"boundary\": False,\n",
    "    },\n",
    "    \"japanese\": {\n",
    "        \"phrases\": [r\"おすすめ\", r\"オススメ\", r\"最高\", r\"神ゲー\", r\"買う価値\", r\"面白い\", r\"楽しい\"],\n",
    "        \"words\": [r\"おすすめ\", r\"最高\", r\"神\", r\"面白\", r\"楽しい\", r\"良い\", r\"素晴らしい\"],\n",
    "        \"neg\": [r\"おすすめしない\", r\"買わない方が\", r\"つまらない\", r\"面白くない\", r\"最悪\", r\"返品\"],\n",
    "        \"boundary\": False,\n",
    "    },\n",
    "    \"schinese\": {\n",
    "        \"phrases\": [r\"强烈推荐\", r\"非常推荐\", r\"值得买\", r\"值得入\", r\"很值得\", r\"很好玩\", r\"神作\", r\"精品\"],\n",
    "        \"words\": [r\"推荐\", r\"值得\", r\"好玩\", r\"很好\", r\"优秀\", r\"完美\", r\"喜欢\"],\n",
    "        \"neg\": [r\"不推荐\", r\"不值得\", r\"不好玩\", r\"垃圾\", r\"别买\", r\"千万别买\", r\"退款\"],\n",
    "        \"boundary\": False,\n",
    "    },\n",
    "    \"tchinese\": {\n",
    "        \"phrases\": [r\"強烈推薦\", r\"非常推薦\", r\"值得買\", r\"值得入\", r\"很值得\", r\"很好玩\", r\"神作\", r\"精品\"],\n",
    "        \"words\": [r\"推薦\", r\"值得\", r\"好玩\", r\"很好\", r\"優秀\", r\"完美\", r\"喜歡\"],\n",
    "        \"neg\": [r\"不推薦\", r\"不值得\", r\"不好玩\", r\"垃圾\", r\"別買\", r\"千萬別買\", r\"退款\"],\n",
    "        \"boundary\": False,\n",
    "    },\n",
    "    \"arabic\": {\n",
    "        \"phrases\": [r\"أنصح\", r\"ممتاز\", r\"رائع\", r\"يستحق\", r\"لعبة رائعة\", r\"ممتعة\"],\n",
    "        \"words\": [r\"ممتاز\", r\"رائع\", r\"جميل\", r\"ممتع\", r\"يستحق\", r\"أنصح\"],\n",
    "        \"neg\": [r\"لا\\s+أنصح\", r\"لا\\s+يستحق\", r\"سيئ\", r\"لا\\s+تشتري\", r\"استرجاع\"],\n",
    "        \"boundary\": False,\n",
    "    },\n",
    "    \"thai\": {\n",
    "        \"phrases\": [r\"แนะนำ\", r\"ดีมาก\", r\"สุดยอด\", r\"คุ้มค่า\", r\"สนุกมาก\", r\"โคตรสนุก\"],\n",
    "        \"words\": [r\"แนะนำ\", r\"ดี\", r\"สนุก\", r\"สุดยอด\", r\"คุ้ม\", r\"ชอบ\"],\n",
    "        \"neg\": [r\"ไม่แนะนำ\", r\"ไม่คุ้ม\", r\"ไม่ดี\", r\"แย่\", r\"อย่าซื้อ\", r\"ขอคืนเงิน\"],\n",
    "        \"boundary\": False,\n",
    "    },\n",
    "    \"vietnamese\": {\n",
    "        \"phrases\": [r\"rất hay\", r\"tuyệt vời\", r\"đáng mua\", r\"đáng tiền\", r\"nên mua\", r\"khuyên dùng\"],\n",
    "        \"words\": [r\"hay\", r\"tuyệt\", r\"xuất sắc\", r\"đáng\", r\"thích\", r\"khuyên\", r\"nên\"],\n",
    "        \"neg\": [r\"không\\s+khuyên\", r\"không\\s+đáng\", r\"đừng\\s+mua\", r\"tệ\", r\"chán\", r\"hoàn tiền\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "    \"indonesian\": {\n",
    "        \"phrases\": [r\"sangat bagus\", r\"rekomendasi\", r\"worth it\", r\"layak dibeli\", r\"seru banget\"],\n",
    "        \"words\": [r\"bagus\", r\"keren\", r\"mantap\", r\"seru\", r\"rekomend\", r\"layak\"],\n",
    "        \"neg\": [r\"tidak\\s+rekomend\", r\"jangan\\s+beli\", r\"tidak\\s+layak\", r\"jelek\", r\"buruk\", r\"refund\"],\n",
    "        \"boundary\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "DEFAULT_LANG = \"english\"\n",
    "\n",
    "def _compile_lexicon(cfg):\n",
    "    boundary = cfg.get(\"boundary\", True)\n",
    "\n",
    "    parts_good = []\n",
    "    for p in cfg.get(\"phrases\", []):\n",
    "        parts_good.append(f\"(?:{p})\")\n",
    "    for w in cfg.get(\"words\", []):\n",
    "        if boundary:\n",
    "            parts_good.append(rf\"\\b{w}\\b\")\n",
    "        else:\n",
    "            parts_good.append(f\"(?:{w})\")\n",
    "\n",
    "    good_pat = \"|\".join(parts_good) if parts_good else r\"$^\"\n",
    "    good_re = re.compile(good_pat, flags=re.UNICODE)\n",
    "\n",
    "    neg_parts = [f\"(?:{p})\" for p in cfg.get(\"neg\", [])]\n",
    "    neg_pat = \"|\".join(neg_parts) if neg_parts else r\"$^\"\n",
    "    neg_re = re.compile(neg_pat, flags=re.UNICODE)\n",
    "\n",
    "    return good_re, neg_re\n",
    "\n",
    "_COMPILED = {}\n",
    "for lang, cfg in LEXICON.items():\n",
    "    _COMPILED[lang] = _compile_lexicon(cfg)\n",
    "_COMPILED[DEFAULT_LANG] = _COMPILED.get(DEFAULT_LANG, _compile_lexicon(LEXICON[\"english\"]))\n",
    "\n",
    "def add_good_flag_multilang(df_model, text_col=\"review\", lang_col=\"language\"):\n",
    "    out = df_model.copy()\n",
    "\n",
    "    text = out[text_col].fillna(\"\").astype(str).str.casefold()\n",
    "    lang = out[lang_col].fillna(DEFAULT_LANG).astype(str)\n",
    "\n",
    "    good_hit = pd.Series(False, index=out.index)\n",
    "    neg_hit  = pd.Series(False, index=out.index)\n",
    "\n",
    "    for l in lang.unique():\n",
    "        mask = (lang == l)\n",
    "        good_re, neg_re = _COMPILED.get(l, _COMPILED[DEFAULT_LANG])\n",
    "\n",
    "        good_hit.loc[mask] = text.loc[mask].str.contains(good_re, regex=True)\n",
    "        neg_hit.loc[mask]  = text.loc[mask].str.contains(neg_re,  regex=True)\n",
    "\n",
    "    out[\"good_review\"] = (good_hit & (~neg_hit)).astype(int)\n",
    "    return out\n",
    "\n",
    "df_model = add_good_flag_multilang(df_model, text_col=\"review\", lang_col=\"language\")\n",
    "print(df_model[\"good_review\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3041d8",
   "metadata": {},
   "source": [
    "- churn 라벨 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7aa7e9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>recommendationid</th>\n",
       "      <th>steamid</th>\n",
       "      <th>num_games_owned</th>\n",
       "      <th>num_reviews_author</th>\n",
       "      <th>playtime_forever</th>\n",
       "      <th>playtime_last_two_weeks</th>\n",
       "      <th>playtime_at_review</th>\n",
       "      <th>last_played</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>log_num_games_owned</th>\n",
       "      <th>log_num_reviews_author</th>\n",
       "      <th>is_heavy_user</th>\n",
       "      <th>is_light_user</th>\n",
       "      <th>positive_but_short_play</th>\n",
       "      <th>negative_but_long_play</th>\n",
       "      <th>has_votes</th>\n",
       "      <th>has_comment</th>\n",
       "      <th>is_updated_review</th>\n",
       "      <th>social_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27798</th>\n",
       "      <td>2139460</td>\n",
       "      <td>215256415</td>\n",
       "      <td>76561198092089560</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1659</td>\n",
       "      <td>1659</td>\n",
       "      <td>1628.0</td>\n",
       "      <td>1767647101</td>\n",
       "      <td>english</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27799</th>\n",
       "      <td>2139460</td>\n",
       "      <td>215256182</td>\n",
       "      <td>76561197995642012</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>370</td>\n",
       "      <td>367</td>\n",
       "      <td>339.0</td>\n",
       "      <td>1767646994</td>\n",
       "      <td>french</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27800</th>\n",
       "      <td>2139460</td>\n",
       "      <td>215249671</td>\n",
       "      <td>76561198217416651</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>552</td>\n",
       "      <td>552</td>\n",
       "      <td>401.0</td>\n",
       "      <td>1767648127</td>\n",
       "      <td>greek</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         appid  recommendationid            steamid  num_games_owned  \\\n",
       "27798  2139460         215256415  76561198092089560                0   \n",
       "27799  2139460         215256182  76561197995642012                0   \n",
       "27800  2139460         215249671  76561198217416651                0   \n",
       "\n",
       "       num_reviews_author  playtime_forever  playtime_last_two_weeks  \\\n",
       "27798                   1              1659                     1659   \n",
       "27799                   4               370                      367   \n",
       "27800                  32               552                      552   \n",
       "\n",
       "       playtime_at_review  last_played language  ... log_num_games_owned  \\\n",
       "27798              1628.0   1767647101  english  ...                 0.0   \n",
       "27799               339.0   1767646994   french  ...                 0.0   \n",
       "27800               401.0   1767648127    greek  ...                 0.0   \n",
       "\n",
       "       log_num_reviews_author  is_heavy_user  is_light_user  \\\n",
       "27798                0.693147              0              1   \n",
       "27799                1.609438              0              0   \n",
       "27800                3.496508              0              0   \n",
       "\n",
       "       positive_but_short_play  negative_but_long_play  has_votes  \\\n",
       "27798                        0                       1          0   \n",
       "27799                        0                       0          0   \n",
       "27800                        0                       0          0   \n",
       "\n",
       "       has_comment  is_updated_review  social_density  \n",
       "27798            0                  0             0.0  \n",
       "27799            0                  0             0.0  \n",
       "27800            0                  0             0.0  \n",
       "\n",
       "[3 rows x 43 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# (중요) 숫자 컬럼은 float32로 계산해서 새 배열 메모리 절약\n",
    "pt = pd.to_numeric(df_model[\"playtime_at_review\"], errors=\"coerce\").fillna(0).to_numpy(dtype=np.float32)\n",
    "ng = pd.to_numeric(df_model[\"num_games_owned\"], errors=\"coerce\").fillna(0).to_numpy(dtype=np.float32)\n",
    "nr = pd.to_numeric(df_model[\"num_reviews_author\"], errors=\"coerce\").fillna(0).to_numpy(dtype=np.float32)\n",
    "\n",
    "# 1. 리뷰 시점 플레이 집중도\n",
    "df_model[\"playtime_per_game\"] = np.log1p(pt / (ng + 1)).astype(np.float32)\n",
    "\n",
    "# 2. 리뷰 작성 시점의 몰입 단계 (log_playtime + 3개 원핫)\n",
    "df_model[\"log_playtime\"] = np.log1p(pt).astype(np.float32)\n",
    "\n",
    "# playtime_stage는 카테고리라 메모리 부담 → 아예 안 만들고 바로 3개 이진 컬럼만 만든다 (로직 동일)\n",
    "# bins: (-inf,4], (4,8], (8,inf)\n",
    "lp = df_model[\"log_playtime\"].to_numpy(dtype=np.float32)\n",
    "\n",
    "df_model[\"is_short_play\"] = (lp <= 4).astype(np.int8)\n",
    "df_model[\"is_mid_play\"]   = ((lp > 4) & (lp <= 8)).astype(np.int8)\n",
    "df_model[\"is_long_play\"]  = (lp > 8).astype(np.int8)\n",
    "\n",
    "# 3. 리뷰어 성향\n",
    "df_model[\"reviews_per_game\"] = np.log1p(nr / (ng + 1)).astype(np.float32)\n",
    "\n",
    "# 4. 경험 많은/적은 유저\n",
    "df_model[\"log_num_games_owned\"] = np.log1p(ng).astype(np.float32)\n",
    "df_model[\"log_num_reviews_author\"] = np.log1p(nr).astype(np.float32)\n",
    "\n",
    "df_model[\"is_heavy_user\"] = (\n",
    "    (df_model[\"log_num_games_owned\"].to_numpy(dtype=np.float32) > 5.0) &\n",
    "    (df_model[\"log_num_reviews_author\"].to_numpy(dtype=np.float32) > 3.5)\n",
    ").astype(np.int8)\n",
    "\n",
    "df_model[\"is_light_user\"] = (\n",
    "    (df_model[\"log_num_games_owned\"].to_numpy(dtype=np.float32) < 2.0) &\n",
    "    (df_model[\"log_num_reviews_author\"].to_numpy(dtype=np.float32) < 1.0)\n",
    ").astype(np.int8)\n",
    "\n",
    "# 5. 감정×행동 결합 (그대로)\n",
    "gr = pd.to_numeric(df_model[\"good_review\"], errors=\"coerce\").fillna(0).to_numpy(dtype=np.int8)\n",
    "\n",
    "df_model[\"positive_but_short_play\"] = ((gr == 1) & (pt < 60)).astype(np.int8)\n",
    "df_model[\"negative_but_long_play\"]  = ((gr == 0) & (pt > 1200)).astype(np.int8)\n",
    "\n",
    "# 6. 사회적 반응 (그대로)\n",
    "vu = pd.to_numeric(df_model[\"votes_up\"], errors=\"coerce\").fillna(0).to_numpy(dtype=np.float32)\n",
    "vf = pd.to_numeric(df_model[\"votes_funny\"], errors=\"coerce\").fillna(0).to_numpy(dtype=np.float32)\n",
    "cc = pd.to_numeric(df_model[\"comment_count\"], errors=\"coerce\").fillna(0).to_numpy(dtype=np.float32)\n",
    "\n",
    "df_model[\"has_votes\"]   = ((vu + vf) > 0).astype(np.int8)\n",
    "df_model[\"has_comment\"] = (cc > 0).astype(np.int8)\n",
    "\n",
    "# 7. 리뷰 업데이트 여부 (그대로)\n",
    "df_model[\"is_updated_review\"] = (df_model[\"timestamp_created\"] != df_model[\"timestamp_updated\"]).astype(np.int8)\n",
    "\n",
    "# 8. 커뮤니티 신뢰도 밀도 (그대로)\n",
    "df_model[\"social_density\"] = np.log1p((vu + cc) / (nr + 1)).astype(np.float32)\n",
    "\n",
    "# 안전 처리: 여기서는 3개만 inf 제거(전체 replace 금지)\n",
    "fix_cols = [\"playtime_per_game\", \"reviews_per_game\", \"social_density\"]\n",
    "for c in fix_cols:\n",
    "    s = pd.to_numeric(df_model[c], errors=\"coerce\")\n",
    "    df_model[c] = s.replace([np.inf, -np.inf], np.nan).fillna(0).astype(np.float32)\n",
    "\n",
    "df_model.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8511944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 10개 언어만 유지, 나머지는 other\n",
    "top_n = 10\n",
    "top_langs = df_model['language'].value_counts().head(top_n).index\n",
    "\n",
    "df_model['language'] = df_model['language'].where(\n",
    "    df_model['language'].isin(top_langs),\n",
    "    'other'\n",
    ")\n",
    "\n",
    "df_model = pd.get_dummies(\n",
    "    df_model,\n",
    "    columns=['language', 'game_style'],\n",
    "    drop_first=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ddc86b",
   "metadata": {},
   "source": [
    "good_review 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecdaba42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['language_english', 'language_french', 'language_german', 'language_koreana', 'language_other', 'language_polish', 'language_russian', 'language_schinese', 'language_spanish', 'language_turkish']\n",
      "['game_style_story', 'game_style_video']\n"
     ]
    }
   ],
   "source": [
    "# 생성된 컬럼 확인\n",
    "print([col for col in df_model.columns if col.startswith('language_')])\n",
    "print([col for col in df_model.columns if col.startswith('game_style_')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a04f6e",
   "metadata": {},
   "source": [
    "### good_review가 생성된 df_model을 최종 학습용 데이터로 확정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5639df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "appid                            int64\n",
       "recommendationid                 int64\n",
       "steamid                          int64\n",
       "num_games_owned                  int64\n",
       "num_reviews_author               int64\n",
       "playtime_forever                 int64\n",
       "playtime_last_two_weeks          int64\n",
       "playtime_at_review             float64\n",
       "last_played                      int64\n",
       "review                          object\n",
       "timestamp_created                int64\n",
       "timestamp_updated                int64\n",
       "voted_up                         int64\n",
       "votes_up                         int64\n",
       "votes_funny                      int64\n",
       "weighted_vote_score            float64\n",
       "comment_count                    int64\n",
       "steam_purchase                   int64\n",
       "received_for_free                int64\n",
       "written_during_early_access      int64\n",
       "primarily_steam_deck             int64\n",
       "days_after_review                int64\n",
       "churn_window_days                int64\n",
       "churn                            int64\n",
       "good_review                      int64\n",
       "playtime_per_game              float32\n",
       "log_playtime                   float32\n",
       "is_short_play                    int64\n",
       "is_mid_play                      int64\n",
       "is_long_play                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원핫인코딩/불리언류 int화 (DL에서도 필수: tensor 변환이 깔끔해짐)\n",
    "bool_cols = ['voted_up', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'primarily_steam_deck',\n",
    "            'language_english', 'language_french', 'language_german','language_koreana','language_other','language_polish','language_russian','language_schinese','language_spanish','language_turkish',\n",
    "            'game_style_story', 'game_style_video'\n",
    "            ]\n",
    "\n",
    "for col in bool_cols:\n",
    "    if col in df_model.columns:\n",
    "        df_model[col] = df_model[col].astype(int)\n",
    "\n",
    "# 타깃/이진 파생도 int 확정\n",
    "for c in [\"churn\", \"good_review\",\n",
    "          \"is_short_play\",\"is_mid_play\",\"is_long_play\",\n",
    "          \"is_heavy_user\",\"is_light_user\",\n",
    "          \"positive_but_short_play\",\"negative_but_long_play\",\n",
    "          \"has_votes\",\"has_comment\",\"is_updated_review\"]:\n",
    "    if c in df_model.columns:\n",
    "        df_model[c] = pd.to_numeric(df_model[c], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "df_model.dtypes.head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a932f4",
   "metadata": {},
   "source": [
    "- good_review 값 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d05ebbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 30\n",
      "top_appids(50) sample: [3241660, 2807960, 730, 1808500, 1030300]\n"
     ]
    }
   ],
   "source": [
    "TARGET = \"churn\"\n",
    "\n",
    "FEATURES = [\n",
    "    \"voted_up\",\n",
    "    \"steam_purchase\",\n",
    "    \"received_for_free\",\n",
    "    \"written_during_early_access\",\n",
    "    \"primarily_steam_deck\",\n",
    "\n",
    "    \"language_english\", \"language_french\", \"language_german\", \"language_koreana\",\n",
    "    \"language_other\", \"language_polish\", \"language_russian\", \"language_schinese\",\n",
    "    \"language_spanish\", \"language_turkish\",\n",
    "    \"game_style_story\", \"game_style_video\",\n",
    "\n",
    "    \"weighted_vote_score\",\n",
    "    \"playtime_per_game\",\n",
    "    \"is_short_play\", \"is_mid_play\", \"is_long_play\",\n",
    "    \"reviews_per_game\",\n",
    "    \"is_heavy_user\",\n",
    "    \"positive_but_short_play\",\n",
    "    \"negative_but_long_play\",\n",
    "    \"has_votes\",\n",
    "    \"has_comment\",\n",
    "    \"social_density\",\n",
    "    \"is_updated_review\",\n",
    "]\n",
    "\n",
    "FEATURES = [c for c in FEATURES if c in df_model.columns]\n",
    "\n",
    "top_appids = (\n",
    "    df_model.groupby(\"appid\")\n",
    "            .size()\n",
    "            .sort_values(ascending=False)\n",
    "            .head(50)\n",
    "            .index.tolist()\n",
    ")\n",
    "\n",
    "print(\"n_features:\", len(FEATURES))\n",
    "print(\"top_appids(50) sample:\", top_appids[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308d1581",
   "metadata": {},
   "source": [
    "- Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93771f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# 1. Dataset 정의\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # 입력 피처는 신경망이 float 연산을 하니까 float32가 표준.\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        # 타깃레이블\n",
    "        # 중요 포인트 : BCEWithLogitsLoss를 쓰면 타깃 y는 float (0.0/1.0)이어야 안전해\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)  # BCEWithLogitsLoss -> float\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f1ab7",
   "metadata": {},
   "source": [
    "### MLP 모델 정의\n",
    "- MLP는 완전연결층을 여러 개 쌓은 신경망\n",
    "- 표 형태 데이터에서 CNN/RNN보다 흔히 쓰이는 딥러닝 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "263f489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. MLP 모델 정의\n",
    "class MLP(nn.Module):\n",
    "    # input_dim: 피처 개수\n",
    "    # hidden_dims=(128, 64): 은닉층 크기 2개\n",
    "    def __init__(self, input_dim, hidden_dims=(128, 64), dropout=0.2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_dim                        # 첫 Linear의 입력 크기\n",
    "        \n",
    "        # 은닉층들을 순서대로 쌓기\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(prev, h))   # 선형변환\n",
    "            layers.append(nn.ReLU())            # 비선형활성화\n",
    "            layers.append(nn.Dropout(dropout))  # 과적합 방지\n",
    "            prev = h\n",
    "\n",
    "        # 마지막 출력층: 1개의 뉴런\n",
    "        # sigmoid를 바로 안쓰는 이유\n",
    "        # BCEWithLogitsLoss가 내부적으로 sigmoid + BCE를 합쳐 수치적으로 안정적이기 때문\n",
    "        layers.append(nn.Linear(prev, 1))  # logit\n",
    "\n",
    "        # 위에 만든 레이어 리스트를 Sequential로 묶어서 forward에서 한 번에 호출 가능하게 함\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):             # 기존 (batch, 1)을 \n",
    "        return self.net(x).squeeze(1) # (batch, )로 만듦\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e306aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 확률 예측 함수 (torch -> numpy proba)\n",
    "def predict_proba_torch(model, loader):\n",
    "    model.eval()    # 평가모드 전환\n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "        for xb, _ in loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            logits = model(xb)\n",
    "            # logit을 확률로 변환\n",
    "            p = torch.sigmoid(logits).detach().cpu().numpy()    \n",
    "            probs.append(p) # 배치 확률을 리스트로 모음\n",
    "    return np.concatenate(probs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e1e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 threshold grid + best threshold 찾기(F1 최대)\n",
    "THR_GRID = np.round(np.arange(0.10, 0.91, 0.02), 2)\n",
    "\n",
    "def best_threshold_by_f1(y_true, proba, thr_grid=THR_GRID):\n",
    "    # y_true 정답레이블(0/1)\n",
    "    # proba 예측값\n",
    "    best_f1, best_thr = -1.0, 0.5\n",
    "    # thr_grid: 탐색할 threshold 리스트\n",
    "    for thr in thr_grid:\n",
    "        # threshold 기준으로 0/1 예측 라벨 생성\n",
    "        pred = (proba >= thr).astype(int)\n",
    "        # F1 계산\n",
    "        f1 = f1_score(y_true, pred, zero_division=0)\n",
    "        # 더 좋으면 갱신\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_thr = f1, float(thr)\n",
    "    return best_thr, float(best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54428c9c",
   "metadata": {},
   "source": [
    "- MLP는 기본적으로 확률 또는 logit 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d75dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. proba -> metric 계산\n",
    "def eval_from_proba(y_true, proba, thr):\n",
    "    # threshold를 적용해 확률을 라벨(0/1)로 바꿈\n",
    "    pred = (proba >= thr).astype(int)\n",
    "\n",
    "    # confusion_matrix ravel은 (tn, fp, fn, tp) 4개가 나오는 게 전제라\n",
    "    # 혹시 한쪽 클래스만 생길 경우를 방어\n",
    "    cm = confusion_matrix(y_true, pred, labels=[0, 1])\n",
    "    if cm.size == 4:\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "    else:\n",
    "        # 비정상 케이스 방어\n",
    "        tn, fp, fn, tp = 0, 0, 0, 0\n",
    "\n",
    "    return {\n",
    "        \"acc\": accuracy_score(y_true, pred),\n",
    "        \"roc_auc\": roc_auc_score(y_true, proba) if len(np.unique(y_true)) == 2 else np.nan,\n",
    "        \"precision\": precision_score(y_true, pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, pred, zero_division=0),\n",
    "        # 예측이 1로 나온 비율 (모델이 얼마나 공격적으로 1을 찍는지 확인)\n",
    "        \"pred_pos_rate\": float(np.mean(pred == 1)),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4df359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 1개 게임 학습 함수 (early stopping: val_f1)\n",
    "def train_mlp_one_game(\n",
    "    X_train, y_train, X_val, y_val, *,  # * 이후는 키워드 인자만 허용. 실수로 순서 바꿔넣는 버그 방지\n",
    "    hidden_dims=(128, 64), dropout=0.2,\n",
    "    lr=1e-3, weight_decay=1e-4, # 옵티마이저 하이퍼파라미터\n",
    "    batch_size=2048, max_epochs=30, patience=5  \n",
    "):\n",
    "    \n",
    "    # churn=1(양성)이 적을수록, 모델이 0만 찍는 쪽으로 치우칠 수 있음.\n",
    "    # BCEWithLogitsLoss의 pos_weight는 \"양성 샘플의 loss를 더 크게\" 만들어\n",
    "    # 양성을 놓치면(FN) 더 큰 벌점을 받게 함\n",
    "    neg = int((y_train == 0).sum())\n",
    "    pos = int((y_train == 1).sum())\n",
    "    pos_weight = (neg / max(pos, 1))\n",
    "\n",
    "    # Dataset/Loader 구성\n",
    "    train_ds = TabDataset(X_train, y_train)\n",
    "    val_ds   = TabDataset(X_val, y_val)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    # 모델 생성\n",
    "    model = MLP(input_dim=X_train.shape[1], hidden_dims=hidden_dims, dropout=dropout).to(DEVICE)\n",
    "    # AdamW로 과적합 완화\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    # BCEWithLogitsLoss는 sigmoid를 내부에서 포함한 loss\n",
    "    criterion = nn.BCEWithLogitsLoss(\n",
    "        pos_weight=torch.tensor([pos_weight], dtype=torch.float32, device=DEVICE)\n",
    "    )\n",
    "\n",
    "    # 얼리스탑핑 위한 변수들\n",
    "    best_state = None\n",
    "    best_val_f1 = -1.0\n",
    "    best_epoch = -1\n",
    "    wait = 0\n",
    "\n",
    "    # 학습 반복 시작\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        # Train Loop 배치 학습\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()   # 기울기 초기화\n",
    "            logits = model(xb)      # 순전파\n",
    "            loss = criterion(logits, yb) # 손실계산\n",
    "            loss.backward()         # 기울기 계산\n",
    "            optimizer.step()        # 업데이트\n",
    "\n",
    "            # total_loss는 배치 loss * 배치크기로 누적해서 전체 샘플 평균을 내기 좋게 해둔 형태\n",
    "            total_loss += float(loss.item()) * len(yb)\n",
    "\n",
    "        # val f1 기준 early stopping\n",
    "        # predict_proba_torch: val_loader 전체 돌면서 sigmoid 확률을 numpy로 반환\n",
    "        val_proba = predict_proba_torch(model, val_loader)\n",
    "        # predict_proba_torch: val에서 F1이 최대가 되는 threshold를 찾고, 그 때의 val_f1도 같이 반환\n",
    "        thr, val_f1 = best_threshold_by_f1(y_val, val_proba)\n",
    "\n",
    "        # 얼리스탑핑 업데이트\n",
    "        if val_f1 > best_val_f1 + 1e-6:\n",
    "            best_val_f1 = val_f1\n",
    "            best_epoch = epoch\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                break\n",
    "\n",
    "    # best state 복원\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return model, float(pos_weight), int(best_epoch), float(best_val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6ee3031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_SIZE: 0.2 VAL_SIZE_IN_TRAIN: 0.2\n"
     ]
    }
   ],
   "source": [
    "# 7. 저장 폴더 생성 + 기본 파라미터\n",
    "os.makedirs(\"dl_model\", exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.20\n",
    "VAL_SIZE_IN_TRAIN = 0.20\n",
    "\n",
    "print(\"TEST_SIZE:\", TEST_SIZE, \"VAL_SIZE_IN_TRAIN:\", VAL_SIZE_IN_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aa3a10",
   "metadata": {},
   "source": [
    "- 필수 변수 준비 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d42587fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET: churn\n",
      "n_features: 30\n",
      "top_appids len: 50\n",
      "sample appids: [3241660, 2807960, 730, 1808500, 1030300]\n"
     ]
    }
   ],
   "source": [
    "# df_model, FEATURES, TARGET, top_appids (50개)\n",
    "print(\"TARGET:\", TARGET)\n",
    "print(\"n_features:\", len(FEATURES))\n",
    "print(\"top_appids len:\", len(top_appids))\n",
    "print(\"sample appids:\", top_appids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f2f4082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DL Games: 100%|██████████| 50/50 [23:38<00:00, 28.36s/game, appid=1222670]  \n"
     ]
    }
   ],
   "source": [
    "# 9. Top50 전체(appid 50개) 딥러닝 학습 + 저장 (메인 루프)\n",
    "rows = []\n",
    "\n",
    "pbar = tqdm(top_appids, desc=\"DL Games\", unit=\"game\")\n",
    "\n",
    "for appid in pbar:\n",
    "    # gdf: 해당 게임 리뷰만 모은 DataFrame\n",
    "    gdf = df_model[df_model[\"appid\"] == appid].copy()\n",
    "    gdf = gdf.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    # 타깃이 한쪽만 있으면 학습 불가\n",
    "    if gdf[TARGET].nunique() < 2:\n",
    "        continue\n",
    "\n",
    "    # X/y 구성 (딥러닝용 dtype)\n",
    "    X = gdf[FEATURES].apply(pd.to_numeric, errors=\"coerce\").fillna(0).to_numpy(dtype=np.float32)\n",
    "    y = gdf[TARGET].astype(int).to_numpy(dtype=np.int64)\n",
    "\n",
    "    # split (stratify)\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full,\n",
    "        test_size=VAL_SIZE_IN_TRAIN, random_state=RANDOM_STATE, stratify=y_train_full\n",
    "    )\n",
    "\n",
    "    # 스케일링(게임별 train에만 fit)\n",
    "    # scaler는 train에만 fit해야 데이터 누수가 없음.\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_val_s   = scaler.transform(X_val)\n",
    "    X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "    # 학습 호출\n",
    "    pbar.set_postfix_str(f\"appid={appid}\")\n",
    "    model, pos_weight, best_epoch, best_val_f1 = train_mlp_one_game(\n",
    "        X_train_s, y_train, X_val_s, y_val,\n",
    "        hidden_dims=(128, 64),\n",
    "        dropout=0.25,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "        batch_size=2048,\n",
    "        max_epochs=30,\n",
    "        patience=5\n",
    "    )\n",
    "\n",
    "    # val 기준 thr 선택\n",
    "    val_loader = DataLoader(TabDataset(X_val_s, y_val), batch_size=4096, shuffle=False)\n",
    "    val_proba = predict_proba_torch(model, val_loader)\n",
    "    best_thr, _ = best_threshold_by_f1(y_val, val_proba)\n",
    "\n",
    "    # test 평가\n",
    "    test_loader = DataLoader(TabDataset(X_test_s, y_test), batch_size=4096, shuffle=False)\n",
    "    test_proba = predict_proba_torch(model, test_loader)\n",
    "    m = eval_from_proba(y_test, test_proba, best_thr)\n",
    "\n",
    "    # baseline(전부 1찍기)와 비교\n",
    "    churn_rate = float(y.mean())\n",
    "    all1_f1 = f1_score(y_test, np.ones_like(y_test), zero_division=0)\n",
    "    # 양수면 최소한 baseline은 이겼다라는 의미\n",
    "    gain_vs_all1 = float(m[\"f1\"] - all1_f1)\n",
    "\n",
    "    # 결과 저장\n",
    "    row = {\n",
    "        \"appid\": int(appid),\n",
    "        \"n_rows\": int(len(gdf)),\n",
    "        \"churn_rate\": churn_rate,\n",
    "        \"pos_weight\": float(pos_weight),\n",
    "        \"best_valid_f1\": float(best_val_f1),\n",
    "        \"best_epoch\": int(best_epoch),\n",
    "        \"best_thr\": float(best_thr),\n",
    "\n",
    "        \"test_f1\": float(m[\"f1\"]),\n",
    "        \"test_precision\": float(m[\"precision\"]),\n",
    "        \"test_recall\": float(m[\"recall\"]),\n",
    "        \"test_roc_auc\": float(m[\"roc_auc\"]),\n",
    "        \"test_pred_pos_rate\": float(m[\"pred_pos_rate\"]),\n",
    "\n",
    "        \"tn\": int(m[\"tn\"]), \"fp\": int(m[\"fp\"]), \"fn\": int(m[\"fn\"]), \"tp\": int(m[\"tp\"]),\n",
    "        \"all1_f1\": float(all1_f1),\n",
    "        \"gain_vs_all1\": float(gain_vs_all1),\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "    # 저장(payload)\n",
    "    payload = {\n",
    "        \"model_state_dict\": {k: v.cpu() for k, v in model.state_dict().items()},\n",
    "        \"scaler\": scaler,\n",
    "        \"features\": FEATURES,\n",
    "        \"best_thr\": float(best_thr),\n",
    "        \"meta\": {\n",
    "            \"appid\": int(appid),\n",
    "            \"pos_weight\": float(pos_weight),\n",
    "            \"best_valid_f1\": float(best_val_f1),\n",
    "            \"best_epoch\": int(best_epoch),\n",
    "        }\n",
    "    }\n",
    "    joblib.dump(payload, f\"dl_model/model_{int(appid)}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87c7dd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done. games: 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>churn_rate</th>\n",
       "      <th>pos_weight</th>\n",
       "      <th>best_valid_f1</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>best_thr</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_pred_pos_rate</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>all1_f1</th>\n",
       "      <th>gain_vs_all1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3527290</td>\n",
       "      <td>31721</td>\n",
       "      <td>0.699001</td>\n",
       "      <td>0.430585</td>\n",
       "      <td>0.823557</td>\n",
       "      <td>3</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.823288</td>\n",
       "      <td>0.701429</td>\n",
       "      <td>0.996392</td>\n",
       "      <td>0.632280</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>29</td>\n",
       "      <td>1881</td>\n",
       "      <td>16</td>\n",
       "      <td>4419</td>\n",
       "      <td>0.822820</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1222140</td>\n",
       "      <td>64366</td>\n",
       "      <td>0.648681</td>\n",
       "      <td>0.541596</td>\n",
       "      <td>0.788677</td>\n",
       "      <td>21</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.787336</td>\n",
       "      <td>0.651553</td>\n",
       "      <td>0.994611</td>\n",
       "      <td>0.583590</td>\n",
       "      <td>0.990213</td>\n",
       "      <td>81</td>\n",
       "      <td>4442</td>\n",
       "      <td>45</td>\n",
       "      <td>8306</td>\n",
       "      <td>0.786902</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2592160</td>\n",
       "      <td>150629</td>\n",
       "      <td>0.594527</td>\n",
       "      <td>0.682027</td>\n",
       "      <td>0.770578</td>\n",
       "      <td>30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.765926</td>\n",
       "      <td>0.665063</td>\n",
       "      <td>0.902853</td>\n",
       "      <td>0.688863</td>\n",
       "      <td>0.807110</td>\n",
       "      <td>4071</td>\n",
       "      <td>8144</td>\n",
       "      <td>1740</td>\n",
       "      <td>16171</td>\n",
       "      <td>0.745717</td>\n",
       "      <td>0.020209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001120</td>\n",
       "      <td>109621</td>\n",
       "      <td>0.562949</td>\n",
       "      <td>0.776371</td>\n",
       "      <td>0.739562</td>\n",
       "      <td>30</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.739890</td>\n",
       "      <td>0.607041</td>\n",
       "      <td>0.947177</td>\n",
       "      <td>0.699665</td>\n",
       "      <td>0.878404</td>\n",
       "      <td>2014</td>\n",
       "      <td>7568</td>\n",
       "      <td>652</td>\n",
       "      <td>11691</td>\n",
       "      <td>0.720381</td>\n",
       "      <td>0.019509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1903340</td>\n",
       "      <td>119542</td>\n",
       "      <td>0.546661</td>\n",
       "      <td>0.829281</td>\n",
       "      <td>0.709035</td>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.707433</td>\n",
       "      <td>0.558304</td>\n",
       "      <td>0.965264</td>\n",
       "      <td>0.625107</td>\n",
       "      <td>0.945125</td>\n",
       "      <td>858</td>\n",
       "      <td>9981</td>\n",
       "      <td>454</td>\n",
       "      <td>12616</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3167020</td>\n",
       "      <td>96654</td>\n",
       "      <td>0.487222</td>\n",
       "      <td>1.052424</td>\n",
       "      <td>0.670666</td>\n",
       "      <td>5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.666091</td>\n",
       "      <td>0.528583</td>\n",
       "      <td>0.900297</td>\n",
       "      <td>0.689701</td>\n",
       "      <td>0.829807</td>\n",
       "      <td>2351</td>\n",
       "      <td>7562</td>\n",
       "      <td>939</td>\n",
       "      <td>8479</td>\n",
       "      <td>0.655188</td>\n",
       "      <td>0.010903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>648800</td>\n",
       "      <td>34646</td>\n",
       "      <td>0.489638</td>\n",
       "      <td>1.042373</td>\n",
       "      <td>0.659837</td>\n",
       "      <td>9</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.657240</td>\n",
       "      <td>0.491110</td>\n",
       "      <td>0.993221</td>\n",
       "      <td>0.625994</td>\n",
       "      <td>0.990188</td>\n",
       "      <td>45</td>\n",
       "      <td>3492</td>\n",
       "      <td>23</td>\n",
       "      <td>3370</td>\n",
       "      <td>0.657367</td>\n",
       "      <td>-0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1145350</td>\n",
       "      <td>51398</td>\n",
       "      <td>0.410814</td>\n",
       "      <td>1.434249</td>\n",
       "      <td>0.658013</td>\n",
       "      <td>5</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.654708</td>\n",
       "      <td>0.508038</td>\n",
       "      <td>0.920436</td>\n",
       "      <td>0.712488</td>\n",
       "      <td>0.744261</td>\n",
       "      <td>2293</td>\n",
       "      <td>3764</td>\n",
       "      <td>336</td>\n",
       "      <td>3887</td>\n",
       "      <td>0.582362</td>\n",
       "      <td>0.072345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1326470</td>\n",
       "      <td>59319</td>\n",
       "      <td>0.456481</td>\n",
       "      <td>1.190652</td>\n",
       "      <td>0.633636</td>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.631787</td>\n",
       "      <td>0.474426</td>\n",
       "      <td>0.945347</td>\n",
       "      <td>0.625029</td>\n",
       "      <td>0.909643</td>\n",
       "      <td>776</td>\n",
       "      <td>5672</td>\n",
       "      <td>296</td>\n",
       "      <td>5120</td>\n",
       "      <td>0.626852</td>\n",
       "      <td>0.004935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1771300</td>\n",
       "      <td>80174</td>\n",
       "      <td>0.424252</td>\n",
       "      <td>1.357067</td>\n",
       "      <td>0.605381</td>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.605669</td>\n",
       "      <td>0.457654</td>\n",
       "      <td>0.895193</td>\n",
       "      <td>0.629807</td>\n",
       "      <td>0.829872</td>\n",
       "      <td>2015</td>\n",
       "      <td>7217</td>\n",
       "      <td>713</td>\n",
       "      <td>6090</td>\n",
       "      <td>0.595761</td>\n",
       "      <td>0.009907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3564740</td>\n",
       "      <td>93627</td>\n",
       "      <td>0.323475</td>\n",
       "      <td>2.091369</td>\n",
       "      <td>0.609566</td>\n",
       "      <td>30</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.603965</td>\n",
       "      <td>0.521880</td>\n",
       "      <td>0.716691</td>\n",
       "      <td>0.771939</td>\n",
       "      <td>0.444195</td>\n",
       "      <td>8692</td>\n",
       "      <td>3977</td>\n",
       "      <td>1716</td>\n",
       "      <td>4341</td>\n",
       "      <td>0.488803</td>\n",
       "      <td>0.115162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>990080</td>\n",
       "      <td>57746</td>\n",
       "      <td>0.407145</td>\n",
       "      <td>1.456201</td>\n",
       "      <td>0.600435</td>\n",
       "      <td>11</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.590995</td>\n",
       "      <td>0.482138</td>\n",
       "      <td>0.763343</td>\n",
       "      <td>0.673640</td>\n",
       "      <td>0.644675</td>\n",
       "      <td>2991</td>\n",
       "      <td>3856</td>\n",
       "      <td>1113</td>\n",
       "      <td>3590</td>\n",
       "      <td>0.578724</td>\n",
       "      <td>0.012271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3932890</td>\n",
       "      <td>41232</td>\n",
       "      <td>0.303817</td>\n",
       "      <td>2.291506</td>\n",
       "      <td>0.597028</td>\n",
       "      <td>16</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.585758</td>\n",
       "      <td>0.512890</td>\n",
       "      <td>0.682761</td>\n",
       "      <td>0.767138</td>\n",
       "      <td>0.404511</td>\n",
       "      <td>4116</td>\n",
       "      <td>1625</td>\n",
       "      <td>795</td>\n",
       "      <td>1711</td>\n",
       "      <td>0.466102</td>\n",
       "      <td>0.119656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1222670</td>\n",
       "      <td>30553</td>\n",
       "      <td>0.348804</td>\n",
       "      <td>1.867009</td>\n",
       "      <td>0.592544</td>\n",
       "      <td>14</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.580998</td>\n",
       "      <td>0.465405</td>\n",
       "      <td>0.772983</td>\n",
       "      <td>0.720112</td>\n",
       "      <td>0.579447</td>\n",
       "      <td>2086</td>\n",
       "      <td>1893</td>\n",
       "      <td>484</td>\n",
       "      <td>1648</td>\n",
       "      <td>0.517287</td>\n",
       "      <td>0.063710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>814380</td>\n",
       "      <td>34859</td>\n",
       "      <td>0.367107</td>\n",
       "      <td>1.723932</td>\n",
       "      <td>0.570114</td>\n",
       "      <td>9</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.571943</td>\n",
       "      <td>0.442943</td>\n",
       "      <td>0.806956</td>\n",
       "      <td>0.667472</td>\n",
       "      <td>0.668675</td>\n",
       "      <td>1816</td>\n",
       "      <td>2597</td>\n",
       "      <td>494</td>\n",
       "      <td>2065</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.034958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2139460</td>\n",
       "      <td>48140</td>\n",
       "      <td>0.270627</td>\n",
       "      <td>2.695454</td>\n",
       "      <td>0.563551</td>\n",
       "      <td>7</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.568597</td>\n",
       "      <td>0.481867</td>\n",
       "      <td>0.693400</td>\n",
       "      <td>0.786311</td>\n",
       "      <td>0.389489</td>\n",
       "      <td>5079</td>\n",
       "      <td>1943</td>\n",
       "      <td>799</td>\n",
       "      <td>1807</td>\n",
       "      <td>0.426026</td>\n",
       "      <td>0.142571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>440</td>\n",
       "      <td>44206</td>\n",
       "      <td>0.319821</td>\n",
       "      <td>2.126768</td>\n",
       "      <td>0.562488</td>\n",
       "      <td>27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.565448</td>\n",
       "      <td>0.506435</td>\n",
       "      <td>0.640028</td>\n",
       "      <td>0.739962</td>\n",
       "      <td>0.404207</td>\n",
       "      <td>4250</td>\n",
       "      <td>1764</td>\n",
       "      <td>1018</td>\n",
       "      <td>1810</td>\n",
       "      <td>0.484662</td>\n",
       "      <td>0.080787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1030300</td>\n",
       "      <td>238619</td>\n",
       "      <td>0.335510</td>\n",
       "      <td>1.980522</td>\n",
       "      <td>0.557365</td>\n",
       "      <td>13</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.552964</td>\n",
       "      <td>0.426261</td>\n",
       "      <td>0.786847</td>\n",
       "      <td>0.691619</td>\n",
       "      <td>0.619332</td>\n",
       "      <td>14754</td>\n",
       "      <td>16958</td>\n",
       "      <td>3413</td>\n",
       "      <td>12599</td>\n",
       "      <td>0.502448</td>\n",
       "      <td>0.050516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1144200</td>\n",
       "      <td>98213</td>\n",
       "      <td>0.322768</td>\n",
       "      <td>2.098186</td>\n",
       "      <td>0.555333</td>\n",
       "      <td>21</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.551508</td>\n",
       "      <td>0.463580</td>\n",
       "      <td>0.680599</td>\n",
       "      <td>0.714748</td>\n",
       "      <td>0.473858</td>\n",
       "      <td>8310</td>\n",
       "      <td>4993</td>\n",
       "      <td>2025</td>\n",
       "      <td>4315</td>\n",
       "      <td>0.488011</td>\n",
       "      <td>0.063497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>570</td>\n",
       "      <td>204029</td>\n",
       "      <td>0.193169</td>\n",
       "      <td>4.176736</td>\n",
       "      <td>0.561055</td>\n",
       "      <td>30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.544200</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.565466</td>\n",
       "      <td>0.797197</td>\n",
       "      <td>0.208254</td>\n",
       "      <td>28883</td>\n",
       "      <td>4041</td>\n",
       "      <td>3425</td>\n",
       "      <td>4457</td>\n",
       "      <td>0.323776</td>\n",
       "      <td>0.220424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>236390</td>\n",
       "      <td>45835</td>\n",
       "      <td>0.309480</td>\n",
       "      <td>2.231328</td>\n",
       "      <td>0.540079</td>\n",
       "      <td>16</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.540954</td>\n",
       "      <td>0.441912</td>\n",
       "      <td>0.697215</td>\n",
       "      <td>0.703639</td>\n",
       "      <td>0.488273</td>\n",
       "      <td>3832</td>\n",
       "      <td>2498</td>\n",
       "      <td>859</td>\n",
       "      <td>1978</td>\n",
       "      <td>0.472676</td>\n",
       "      <td>0.068279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2622380</td>\n",
       "      <td>35200</td>\n",
       "      <td>0.294801</td>\n",
       "      <td>2.391749</td>\n",
       "      <td>0.552177</td>\n",
       "      <td>20</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.540172</td>\n",
       "      <td>0.453652</td>\n",
       "      <td>0.667470</td>\n",
       "      <td>0.722758</td>\n",
       "      <td>0.433665</td>\n",
       "      <td>3297</td>\n",
       "      <td>1668</td>\n",
       "      <td>690</td>\n",
       "      <td>1385</td>\n",
       "      <td>0.455293</td>\n",
       "      <td>0.084878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1172470</td>\n",
       "      <td>71856</td>\n",
       "      <td>0.237767</td>\n",
       "      <td>3.205872</td>\n",
       "      <td>0.523689</td>\n",
       "      <td>4</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.527898</td>\n",
       "      <td>0.448051</td>\n",
       "      <td>0.642376</td>\n",
       "      <td>0.766489</td>\n",
       "      <td>0.340871</td>\n",
       "      <td>8251</td>\n",
       "      <td>2704</td>\n",
       "      <td>1222</td>\n",
       "      <td>2195</td>\n",
       "      <td>0.384170</td>\n",
       "      <td>0.143728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2246340</td>\n",
       "      <td>157833</td>\n",
       "      <td>0.263139</td>\n",
       "      <td>2.800301</td>\n",
       "      <td>0.512513</td>\n",
       "      <td>17</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.521556</td>\n",
       "      <td>0.415689</td>\n",
       "      <td>0.699771</td>\n",
       "      <td>0.732096</td>\n",
       "      <td>0.442994</td>\n",
       "      <td>15089</td>\n",
       "      <td>8171</td>\n",
       "      <td>2494</td>\n",
       "      <td>5813</td>\n",
       "      <td>0.416662</td>\n",
       "      <td>0.104893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1623730</td>\n",
       "      <td>53036</td>\n",
       "      <td>0.332397</td>\n",
       "      <td>2.008509</td>\n",
       "      <td>0.517183</td>\n",
       "      <td>15</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.516991</td>\n",
       "      <td>0.377999</td>\n",
       "      <td>0.817640</td>\n",
       "      <td>0.633839</td>\n",
       "      <td>0.718986</td>\n",
       "      <td>2338</td>\n",
       "      <td>4744</td>\n",
       "      <td>643</td>\n",
       "      <td>2883</td>\n",
       "      <td>0.498939</td>\n",
       "      <td>0.018052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2651280</td>\n",
       "      <td>31527</td>\n",
       "      <td>0.307705</td>\n",
       "      <td>2.249477</td>\n",
       "      <td>0.505055</td>\n",
       "      <td>25</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.514776</td>\n",
       "      <td>0.378674</td>\n",
       "      <td>0.803608</td>\n",
       "      <td>0.675250</td>\n",
       "      <td>0.652870</td>\n",
       "      <td>1808</td>\n",
       "      <td>2558</td>\n",
       "      <td>381</td>\n",
       "      <td>1559</td>\n",
       "      <td>0.470531</td>\n",
       "      <td>0.044245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>413150</td>\n",
       "      <td>81315</td>\n",
       "      <td>0.336420</td>\n",
       "      <td>1.972413</td>\n",
       "      <td>0.517344</td>\n",
       "      <td>17</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.514166</td>\n",
       "      <td>0.372920</td>\n",
       "      <td>0.827637</td>\n",
       "      <td>0.616336</td>\n",
       "      <td>0.746603</td>\n",
       "      <td>3178</td>\n",
       "      <td>7614</td>\n",
       "      <td>943</td>\n",
       "      <td>4528</td>\n",
       "      <td>0.503451</td>\n",
       "      <td>0.010715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2183900</td>\n",
       "      <td>49544</td>\n",
       "      <td>0.267722</td>\n",
       "      <td>2.735187</td>\n",
       "      <td>0.510077</td>\n",
       "      <td>10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.508977</td>\n",
       "      <td>0.409164</td>\n",
       "      <td>0.673200</td>\n",
       "      <td>0.726830</td>\n",
       "      <td>0.440509</td>\n",
       "      <td>4677</td>\n",
       "      <td>2579</td>\n",
       "      <td>867</td>\n",
       "      <td>1786</td>\n",
       "      <td>0.422385</td>\n",
       "      <td>0.086592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1086940</td>\n",
       "      <td>105187</td>\n",
       "      <td>0.299067</td>\n",
       "      <td>2.343714</td>\n",
       "      <td>0.482605</td>\n",
       "      <td>7</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.484358</td>\n",
       "      <td>0.357278</td>\n",
       "      <td>0.751748</td>\n",
       "      <td>0.637379</td>\n",
       "      <td>0.629290</td>\n",
       "      <td>6237</td>\n",
       "      <td>8509</td>\n",
       "      <td>1562</td>\n",
       "      <td>4730</td>\n",
       "      <td>0.460446</td>\n",
       "      <td>0.023912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>526870</td>\n",
       "      <td>40282</td>\n",
       "      <td>0.309940</td>\n",
       "      <td>2.226533</td>\n",
       "      <td>0.483668</td>\n",
       "      <td>16</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.483539</td>\n",
       "      <td>0.323295</td>\n",
       "      <td>0.958751</td>\n",
       "      <td>0.618508</td>\n",
       "      <td>0.919077</td>\n",
       "      <td>549</td>\n",
       "      <td>5011</td>\n",
       "      <td>103</td>\n",
       "      <td>2394</td>\n",
       "      <td>0.473186</td>\n",
       "      <td>0.010353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3159330</td>\n",
       "      <td>32102</td>\n",
       "      <td>0.222946</td>\n",
       "      <td>3.485590</td>\n",
       "      <td>0.486445</td>\n",
       "      <td>16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.479753</td>\n",
       "      <td>0.430394</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.718346</td>\n",
       "      <td>0.280797</td>\n",
       "      <td>3962</td>\n",
       "      <td>1027</td>\n",
       "      <td>656</td>\n",
       "      <td>776</td>\n",
       "      <td>0.364701</td>\n",
       "      <td>0.115051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3489700</td>\n",
       "      <td>78701</td>\n",
       "      <td>0.268586</td>\n",
       "      <td>2.723241</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>18</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.479288</td>\n",
       "      <td>0.394027</td>\n",
       "      <td>0.611637</td>\n",
       "      <td>0.680943</td>\n",
       "      <td>0.416937</td>\n",
       "      <td>7536</td>\n",
       "      <td>3977</td>\n",
       "      <td>1642</td>\n",
       "      <td>2586</td>\n",
       "      <td>0.423456</td>\n",
       "      <td>0.055832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>230410</td>\n",
       "      <td>48982</td>\n",
       "      <td>0.204279</td>\n",
       "      <td>3.895066</td>\n",
       "      <td>0.473326</td>\n",
       "      <td>10</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.476069</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.559220</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.275595</td>\n",
       "      <td>6215</td>\n",
       "      <td>1581</td>\n",
       "      <td>882</td>\n",
       "      <td>1119</td>\n",
       "      <td>0.339210</td>\n",
       "      <td>0.136859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>108600</td>\n",
       "      <td>83054</td>\n",
       "      <td>0.287054</td>\n",
       "      <td>2.483681</td>\n",
       "      <td>0.471217</td>\n",
       "      <td>11</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.474826</td>\n",
       "      <td>0.341618</td>\n",
       "      <td>0.778314</td>\n",
       "      <td>0.651062</td>\n",
       "      <td>0.653964</td>\n",
       "      <td>4691</td>\n",
       "      <td>7152</td>\n",
       "      <td>1057</td>\n",
       "      <td>3711</td>\n",
       "      <td>0.446045</td>\n",
       "      <td>0.028780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3513350</td>\n",
       "      <td>37631</td>\n",
       "      <td>0.179878</td>\n",
       "      <td>4.559326</td>\n",
       "      <td>0.448748</td>\n",
       "      <td>17</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.442659</td>\n",
       "      <td>0.437861</td>\n",
       "      <td>0.447563</td>\n",
       "      <td>0.735379</td>\n",
       "      <td>0.183871</td>\n",
       "      <td>5395</td>\n",
       "      <td>778</td>\n",
       "      <td>748</td>\n",
       "      <td>606</td>\n",
       "      <td>0.304921</td>\n",
       "      <td>0.137738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>578080</td>\n",
       "      <td>193853</td>\n",
       "      <td>0.173090</td>\n",
       "      <td>4.777452</td>\n",
       "      <td>0.440316</td>\n",
       "      <td>30</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.441363</td>\n",
       "      <td>0.372906</td>\n",
       "      <td>0.540605</td>\n",
       "      <td>0.739769</td>\n",
       "      <td>0.250935</td>\n",
       "      <td>25959</td>\n",
       "      <td>6101</td>\n",
       "      <td>3083</td>\n",
       "      <td>3628</td>\n",
       "      <td>0.295106</td>\n",
       "      <td>0.146257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1091500</td>\n",
       "      <td>119802</td>\n",
       "      <td>0.257667</td>\n",
       "      <td>2.880948</td>\n",
       "      <td>0.439219</td>\n",
       "      <td>10</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.439674</td>\n",
       "      <td>0.335232</td>\n",
       "      <td>0.638646</td>\n",
       "      <td>0.643203</td>\n",
       "      <td>0.490881</td>\n",
       "      <td>9968</td>\n",
       "      <td>7819</td>\n",
       "      <td>2231</td>\n",
       "      <td>3943</td>\n",
       "      <td>0.409756</td>\n",
       "      <td>0.029918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2807960</td>\n",
       "      <td>300088</td>\n",
       "      <td>0.157780</td>\n",
       "      <td>5.338063</td>\n",
       "      <td>0.444263</td>\n",
       "      <td>13</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.436897</td>\n",
       "      <td>0.352693</td>\n",
       "      <td>0.573918</td>\n",
       "      <td>0.756216</td>\n",
       "      <td>0.256756</td>\n",
       "      <td>40573</td>\n",
       "      <td>9975</td>\n",
       "      <td>4035</td>\n",
       "      <td>5435</td>\n",
       "      <td>0.272565</td>\n",
       "      <td>0.164332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1245620</td>\n",
       "      <td>108874</td>\n",
       "      <td>0.265821</td>\n",
       "      <td>2.761959</td>\n",
       "      <td>0.432670</td>\n",
       "      <td>7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.432127</td>\n",
       "      <td>0.284342</td>\n",
       "      <td>0.899793</td>\n",
       "      <td>0.623547</td>\n",
       "      <td>0.841148</td>\n",
       "      <td>2879</td>\n",
       "      <td>13108</td>\n",
       "      <td>580</td>\n",
       "      <td>5208</td>\n",
       "      <td>0.419983</td>\n",
       "      <td>0.012144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>394360</td>\n",
       "      <td>41971</td>\n",
       "      <td>0.188463</td>\n",
       "      <td>4.306203</td>\n",
       "      <td>0.444881</td>\n",
       "      <td>12</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.365435</td>\n",
       "      <td>0.525284</td>\n",
       "      <td>0.717861</td>\n",
       "      <td>0.270876</td>\n",
       "      <td>5370</td>\n",
       "      <td>1443</td>\n",
       "      <td>751</td>\n",
       "      <td>831</td>\n",
       "      <td>0.317129</td>\n",
       "      <td>0.113887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3241660</td>\n",
       "      <td>340625</td>\n",
       "      <td>0.219902</td>\n",
       "      <td>3.547541</td>\n",
       "      <td>0.422256</td>\n",
       "      <td>29</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.421843</td>\n",
       "      <td>0.334178</td>\n",
       "      <td>0.571858</td>\n",
       "      <td>0.674870</td>\n",
       "      <td>0.376308</td>\n",
       "      <td>36075</td>\n",
       "      <td>17069</td>\n",
       "      <td>6414</td>\n",
       "      <td>8567</td>\n",
       "      <td>0.360528</td>\n",
       "      <td>0.061316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>294100</td>\n",
       "      <td>30831</td>\n",
       "      <td>0.233110</td>\n",
       "      <td>3.290280</td>\n",
       "      <td>0.402726</td>\n",
       "      <td>11</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.400075</td>\n",
       "      <td>0.273776</td>\n",
       "      <td>0.742698</td>\n",
       "      <td>0.621121</td>\n",
       "      <td>0.632560</td>\n",
       "      <td>1896</td>\n",
       "      <td>2833</td>\n",
       "      <td>370</td>\n",
       "      <td>1068</td>\n",
       "      <td>0.378172</td>\n",
       "      <td>0.021903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>227300</td>\n",
       "      <td>92151</td>\n",
       "      <td>0.227171</td>\n",
       "      <td>3.401851</td>\n",
       "      <td>0.404417</td>\n",
       "      <td>10</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.396119</td>\n",
       "      <td>0.270296</td>\n",
       "      <td>0.741103</td>\n",
       "      <td>0.627108</td>\n",
       "      <td>0.622864</td>\n",
       "      <td>5867</td>\n",
       "      <td>8377</td>\n",
       "      <td>1084</td>\n",
       "      <td>3103</td>\n",
       "      <td>0.370236</td>\n",
       "      <td>0.025883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3240220</td>\n",
       "      <td>138626</td>\n",
       "      <td>0.219338</td>\n",
       "      <td>3.559096</td>\n",
       "      <td>0.400922</td>\n",
       "      <td>6</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.383962</td>\n",
       "      <td>0.262139</td>\n",
       "      <td>0.717316</td>\n",
       "      <td>0.630309</td>\n",
       "      <td>0.600159</td>\n",
       "      <td>9367</td>\n",
       "      <td>12278</td>\n",
       "      <td>1719</td>\n",
       "      <td>4362</td>\n",
       "      <td>0.359748</td>\n",
       "      <td>0.024214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1551360</td>\n",
       "      <td>53036</td>\n",
       "      <td>0.217230</td>\n",
       "      <td>3.602929</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.382538</td>\n",
       "      <td>0.288229</td>\n",
       "      <td>0.568576</td>\n",
       "      <td>0.639317</td>\n",
       "      <td>0.428450</td>\n",
       "      <td>5069</td>\n",
       "      <td>3235</td>\n",
       "      <td>994</td>\n",
       "      <td>1310</td>\n",
       "      <td>0.356877</td>\n",
       "      <td>0.025660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1973530</td>\n",
       "      <td>43061</td>\n",
       "      <td>0.084206</td>\n",
       "      <td>10.873330</td>\n",
       "      <td>0.346130</td>\n",
       "      <td>8</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.379401</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0.497931</td>\n",
       "      <td>0.781688</td>\n",
       "      <td>0.136770</td>\n",
       "      <td>7071</td>\n",
       "      <td>817</td>\n",
       "      <td>364</td>\n",
       "      <td>361</td>\n",
       "      <td>0.155280</td>\n",
       "      <td>0.224121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1808500</td>\n",
       "      <td>252277</td>\n",
       "      <td>0.186660</td>\n",
       "      <td>4.357401</td>\n",
       "      <td>0.384392</td>\n",
       "      <td>28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.375319</td>\n",
       "      <td>0.309792</td>\n",
       "      <td>0.476003</td>\n",
       "      <td>0.673607</td>\n",
       "      <td>0.286804</td>\n",
       "      <td>31050</td>\n",
       "      <td>9988</td>\n",
       "      <td>4935</td>\n",
       "      <td>4483</td>\n",
       "      <td>0.314594</td>\n",
       "      <td>0.060725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3405690</td>\n",
       "      <td>36162</td>\n",
       "      <td>0.174050</td>\n",
       "      <td>4.745531</td>\n",
       "      <td>0.370243</td>\n",
       "      <td>23</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.363878</td>\n",
       "      <td>0.273344</td>\n",
       "      <td>0.544083</td>\n",
       "      <td>0.679149</td>\n",
       "      <td>0.346468</td>\n",
       "      <td>4153</td>\n",
       "      <td>1821</td>\n",
       "      <td>574</td>\n",
       "      <td>685</td>\n",
       "      <td>0.296514</td>\n",
       "      <td>0.067363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>553850</td>\n",
       "      <td>148012</td>\n",
       "      <td>0.139239</td>\n",
       "      <td>6.181729</td>\n",
       "      <td>0.364004</td>\n",
       "      <td>17</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.353713</td>\n",
       "      <td>0.302763</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>0.715653</td>\n",
       "      <td>0.195588</td>\n",
       "      <td>21444</td>\n",
       "      <td>4037</td>\n",
       "      <td>2369</td>\n",
       "      <td>1753</td>\n",
       "      <td>0.244448</td>\n",
       "      <td>0.109265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>730</td>\n",
       "      <td>272473</td>\n",
       "      <td>0.184881</td>\n",
       "      <td>4.408871</td>\n",
       "      <td>0.347161</td>\n",
       "      <td>14</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.344486</td>\n",
       "      <td>0.228729</td>\n",
       "      <td>0.697469</td>\n",
       "      <td>0.630139</td>\n",
       "      <td>0.563758</td>\n",
       "      <td>20725</td>\n",
       "      <td>23695</td>\n",
       "      <td>3048</td>\n",
       "      <td>7027</td>\n",
       "      <td>0.312064</td>\n",
       "      <td>0.032422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      appid  n_rows  churn_rate  pos_weight  best_valid_f1  best_epoch  \\\n",
       "0   3527290   31721    0.699001    0.430585       0.823557           3   \n",
       "1   1222140   64366    0.648681    0.541596       0.788677          21   \n",
       "2   2592160  150629    0.594527    0.682027       0.770578          30   \n",
       "3   2001120  109621    0.562949    0.776371       0.739562          30   \n",
       "4   1903340  119542    0.546661    0.829281       0.709035           4   \n",
       "5   3167020   96654    0.487222    1.052424       0.670666           5   \n",
       "6    648800   34646    0.489638    1.042373       0.659837           9   \n",
       "7   1145350   51398    0.410814    1.434249       0.658013           5   \n",
       "8   1326470   59319    0.456481    1.190652       0.633636           8   \n",
       "9   1771300   80174    0.424252    1.357067       0.605381           5   \n",
       "10  3564740   93627    0.323475    2.091369       0.609566          30   \n",
       "11   990080   57746    0.407145    1.456201       0.600435          11   \n",
       "12  3932890   41232    0.303817    2.291506       0.597028          16   \n",
       "13  1222670   30553    0.348804    1.867009       0.592544          14   \n",
       "14   814380   34859    0.367107    1.723932       0.570114           9   \n",
       "15  2139460   48140    0.270627    2.695454       0.563551           7   \n",
       "16      440   44206    0.319821    2.126768       0.562488          27   \n",
       "17  1030300  238619    0.335510    1.980522       0.557365          13   \n",
       "18  1144200   98213    0.322768    2.098186       0.555333          21   \n",
       "19      570  204029    0.193169    4.176736       0.561055          30   \n",
       "20   236390   45835    0.309480    2.231328       0.540079          16   \n",
       "21  2622380   35200    0.294801    2.391749       0.552177          20   \n",
       "22  1172470   71856    0.237767    3.205872       0.523689           4   \n",
       "23  2246340  157833    0.263139    2.800301       0.512513          17   \n",
       "24  1623730   53036    0.332397    2.008509       0.517183          15   \n",
       "25  2651280   31527    0.307705    2.249477       0.505055          25   \n",
       "26   413150   81315    0.336420    1.972413       0.517344          17   \n",
       "27  2183900   49544    0.267722    2.735187       0.510077          10   \n",
       "28  1086940  105187    0.299067    2.343714       0.482605           7   \n",
       "29   526870   40282    0.309940    2.226533       0.483668          16   \n",
       "30  3159330   32102    0.222946    3.485590       0.486445          16   \n",
       "31  3489700   78701    0.268586    2.723241       0.490909          18   \n",
       "32   230410   48982    0.204279    3.895066       0.473326          10   \n",
       "33   108600   83054    0.287054    2.483681       0.471217          11   \n",
       "34  3513350   37631    0.179878    4.559326       0.448748          17   \n",
       "35   578080  193853    0.173090    4.777452       0.440316          30   \n",
       "36  1091500  119802    0.257667    2.880948       0.439219          10   \n",
       "37  2807960  300088    0.157780    5.338063       0.444263          13   \n",
       "38  1245620  108874    0.265821    2.761959       0.432670           7   \n",
       "39   394360   41971    0.188463    4.306203       0.444881          12   \n",
       "40  3241660  340625    0.219902    3.547541       0.422256          29   \n",
       "41   294100   30831    0.233110    3.290280       0.402726          11   \n",
       "42   227300   92151    0.227171    3.401851       0.404417          10   \n",
       "43  3240220  138626    0.219338    3.559096       0.400922           6   \n",
       "44  1551360   53036    0.217230    3.602929       0.392500          10   \n",
       "45  1973530   43061    0.084206   10.873330       0.346130           8   \n",
       "46  1808500  252277    0.186660    4.357401       0.384392          28   \n",
       "47  3405690   36162    0.174050    4.745531       0.370243          23   \n",
       "48   553850  148012    0.139239    6.181729       0.364004          17   \n",
       "49      730  272473    0.184881    4.408871       0.347161          14   \n",
       "\n",
       "    best_thr   test_f1  test_precision  test_recall  test_roc_auc  \\\n",
       "0       0.18  0.823288        0.701429     0.996392      0.632280   \n",
       "1       0.32  0.787336        0.651553     0.994611      0.583590   \n",
       "2       0.34  0.765926        0.665063     0.902853      0.688863   \n",
       "3       0.32  0.739890        0.607041     0.947177      0.699665   \n",
       "4       0.34  0.707433        0.558304     0.965264      0.625107   \n",
       "5       0.36  0.666091        0.528583     0.900297      0.689701   \n",
       "6       0.32  0.657240        0.491110     0.993221      0.625994   \n",
       "7       0.44  0.654708        0.508038     0.920436      0.712488   \n",
       "8       0.36  0.631787        0.474426     0.945347      0.625029   \n",
       "9       0.40  0.605669        0.457654     0.895193      0.629807   \n",
       "10      0.44  0.603965        0.521880     0.716691      0.771939   \n",
       "11      0.40  0.590995        0.482138     0.763343      0.673640   \n",
       "12      0.52  0.585758        0.512890     0.682761      0.767138   \n",
       "13      0.42  0.580998        0.465405     0.772983      0.720112   \n",
       "14      0.42  0.571943        0.442943     0.806956      0.667472   \n",
       "15      0.50  0.568597        0.481867     0.693400      0.786311   \n",
       "16      0.50  0.565448        0.506435     0.640028      0.739962   \n",
       "17      0.42  0.552964        0.426261     0.786847      0.691619   \n",
       "18      0.44  0.551508        0.463580     0.680599      0.714748   \n",
       "19      0.60  0.544200        0.524476     0.565466      0.797197   \n",
       "20      0.46  0.540954        0.441912     0.697215      0.703639   \n",
       "21      0.48  0.540172        0.453652     0.667470      0.722758   \n",
       "22      0.52  0.527898        0.448051     0.642376      0.766489   \n",
       "23      0.50  0.521556        0.415689     0.699771      0.732096   \n",
       "24      0.42  0.516991        0.377999     0.817640      0.633839   \n",
       "25      0.42  0.514776        0.378674     0.803608      0.675250   \n",
       "26      0.42  0.514166        0.372920     0.827637      0.616336   \n",
       "27      0.52  0.508977        0.409164     0.673200      0.726830   \n",
       "28      0.44  0.484358        0.357278     0.751748      0.637379   \n",
       "29      0.36  0.483539        0.323295     0.958751      0.618508   \n",
       "30      0.54  0.479753        0.430394     0.541899      0.718346   \n",
       "31      0.48  0.479288        0.394027     0.611637      0.680943   \n",
       "32      0.56  0.476069        0.414444     0.559220      0.741321   \n",
       "33      0.44  0.474826        0.341618     0.778314      0.651062   \n",
       "34      0.58  0.442659        0.437861     0.447563      0.735379   \n",
       "35      0.58  0.441363        0.372906     0.540605      0.739769   \n",
       "36      0.46  0.439674        0.335232     0.638646      0.643203   \n",
       "37      0.58  0.436897        0.352693     0.573918      0.756216   \n",
       "38      0.40  0.432127        0.284342     0.899793      0.623547   \n",
       "39      0.52  0.431017        0.365435     0.525284      0.717861   \n",
       "40      0.50  0.421843        0.334178     0.571858      0.674870   \n",
       "41      0.44  0.400075        0.273776     0.742698      0.621121   \n",
       "42      0.46  0.396119        0.270296     0.741103      0.627108   \n",
       "43      0.46  0.383962        0.262139     0.717316      0.630309   \n",
       "44      0.48  0.382538        0.288229     0.568576      0.639317   \n",
       "45      0.68  0.379401        0.306452     0.497931      0.781688   \n",
       "46      0.50  0.375319        0.309792     0.476003      0.673607   \n",
       "47      0.52  0.363878        0.273344     0.544083      0.679149   \n",
       "48      0.58  0.353713        0.302763     0.425279      0.715653   \n",
       "49      0.46  0.344486        0.228729     0.697469      0.630139   \n",
       "\n",
       "    test_pred_pos_rate     tn     fp    fn     tp   all1_f1  gain_vs_all1  \n",
       "0             0.992908     29   1881    16   4419  0.822820      0.000468  \n",
       "1             0.990213     81   4442    45   8306  0.786902      0.000434  \n",
       "2             0.807110   4071   8144  1740  16171  0.745717      0.020209  \n",
       "3             0.878404   2014   7568   652  11691  0.720381      0.019509  \n",
       "4             0.945125    858   9981   454  12616  0.706888      0.000545  \n",
       "5             0.829807   2351   7562   939   8479  0.655188      0.010903  \n",
       "6             0.990188     45   3492    23   3370  0.657367     -0.000127  \n",
       "7             0.744261   2293   3764   336   3887  0.582362      0.072345  \n",
       "8             0.909643    776   5672   296   5120  0.626852      0.004935  \n",
       "9             0.829872   2015   7217   713   6090  0.595761      0.009907  \n",
       "10            0.444195   8692   3977  1716   4341  0.488803      0.115162  \n",
       "11            0.644675   2991   3856  1113   3590  0.578724      0.012271  \n",
       "12            0.404511   4116   1625   795   1711  0.466102      0.119656  \n",
       "13            0.579447   2086   1893   484   1648  0.517287      0.063710  \n",
       "14            0.668675   1816   2597   494   2065  0.536985      0.034958  \n",
       "15            0.389489   5079   1943   799   1807  0.426026      0.142571  \n",
       "16            0.404207   4250   1764  1018   1810  0.484662      0.080787  \n",
       "17            0.619332  14754  16958  3413  12599  0.502448      0.050516  \n",
       "18            0.473858   8310   4993  2025   4315  0.488011      0.063497  \n",
       "19            0.208254  28883   4041  3425   4457  0.323776      0.220424  \n",
       "20            0.488273   3832   2498   859   1978  0.472676      0.068279  \n",
       "21            0.433665   3297   1668   690   1385  0.455293      0.084878  \n",
       "22            0.340871   8251   2704  1222   2195  0.384170      0.143728  \n",
       "23            0.442994  15089   8171  2494   5813  0.416662      0.104893  \n",
       "24            0.718986   2338   4744   643   2883  0.498939      0.018052  \n",
       "25            0.652870   1808   2558   381   1559  0.470531      0.044245  \n",
       "26            0.746603   3178   7614   943   4528  0.503451      0.010715  \n",
       "27            0.440509   4677   2579   867   1786  0.422385      0.086592  \n",
       "28            0.629290   6237   8509  1562   4730  0.460446      0.023912  \n",
       "29            0.919077    549   5011   103   2394  0.473186      0.010353  \n",
       "30            0.280797   3962   1027   656    776  0.364701      0.115051  \n",
       "31            0.416937   7536   3977  1642   2586  0.423456      0.055832  \n",
       "32            0.275595   6215   1581   882   1119  0.339210      0.136859  \n",
       "33            0.653964   4691   7152  1057   3711  0.446045      0.028780  \n",
       "34            0.183871   5395    778   748    606  0.304921      0.137738  \n",
       "35            0.250935  25959   6101  3083   3628  0.295106      0.146257  \n",
       "36            0.490881   9968   7819  2231   3943  0.409756      0.029918  \n",
       "37            0.256756  40573   9975  4035   5435  0.272565      0.164332  \n",
       "38            0.841148   2879  13108   580   5208  0.419983      0.012144  \n",
       "39            0.270876   5370   1443   751    831  0.317129      0.113887  \n",
       "40            0.376308  36075  17069  6414   8567  0.360528      0.061316  \n",
       "41            0.632560   1896   2833   370   1068  0.378172      0.021903  \n",
       "42            0.622864   5867   8377  1084   3103  0.370236      0.025883  \n",
       "43            0.600159   9367  12278  1719   4362  0.359748      0.024214  \n",
       "44            0.428450   5069   3235   994   1310  0.356877      0.025660  \n",
       "45            0.136770   7071    817   364    361  0.155280      0.224121  \n",
       "46            0.286804  31050   9988  4935   4483  0.314594      0.060725  \n",
       "47            0.346468   4153   1821   574    685  0.296514      0.067363  \n",
       "48            0.195588  21444   4037  2369   1753  0.244448      0.109265  \n",
       "49            0.563758  20725  23695  3048   7027  0.312064      0.032422  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10 결과 DF 만들기 + 상위 확인\n",
    "results_df = pd.DataFrame(rows).sort_values([\"test_f1\", \"test_recall\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"done. games:\", len(results_df))\n",
    "display(results_df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9cf8caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>churn_rate</th>\n",
       "      <th>pos_weight</th>\n",
       "      <th>best_valid_f1</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>best_thr</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_pred_pos_rate</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>all1_f1</th>\n",
       "      <th>gain_vs_all1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3527290</td>\n",
       "      <td>31721</td>\n",
       "      <td>0.699001</td>\n",
       "      <td>0.430585</td>\n",
       "      <td>0.823557</td>\n",
       "      <td>3</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.823288</td>\n",
       "      <td>0.701429</td>\n",
       "      <td>0.996392</td>\n",
       "      <td>0.632280</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>29</td>\n",
       "      <td>1881</td>\n",
       "      <td>16</td>\n",
       "      <td>4419</td>\n",
       "      <td>0.822820</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1222140</td>\n",
       "      <td>64366</td>\n",
       "      <td>0.648681</td>\n",
       "      <td>0.541596</td>\n",
       "      <td>0.788677</td>\n",
       "      <td>21</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.787336</td>\n",
       "      <td>0.651553</td>\n",
       "      <td>0.994611</td>\n",
       "      <td>0.583590</td>\n",
       "      <td>0.990213</td>\n",
       "      <td>81</td>\n",
       "      <td>4442</td>\n",
       "      <td>45</td>\n",
       "      <td>8306</td>\n",
       "      <td>0.786902</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2592160</td>\n",
       "      <td>150629</td>\n",
       "      <td>0.594527</td>\n",
       "      <td>0.682027</td>\n",
       "      <td>0.770578</td>\n",
       "      <td>30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.765926</td>\n",
       "      <td>0.665063</td>\n",
       "      <td>0.902853</td>\n",
       "      <td>0.688863</td>\n",
       "      <td>0.807110</td>\n",
       "      <td>4071</td>\n",
       "      <td>8144</td>\n",
       "      <td>1740</td>\n",
       "      <td>16171</td>\n",
       "      <td>0.745717</td>\n",
       "      <td>0.020209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001120</td>\n",
       "      <td>109621</td>\n",
       "      <td>0.562949</td>\n",
       "      <td>0.776371</td>\n",
       "      <td>0.739562</td>\n",
       "      <td>30</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.739890</td>\n",
       "      <td>0.607041</td>\n",
       "      <td>0.947177</td>\n",
       "      <td>0.699665</td>\n",
       "      <td>0.878404</td>\n",
       "      <td>2014</td>\n",
       "      <td>7568</td>\n",
       "      <td>652</td>\n",
       "      <td>11691</td>\n",
       "      <td>0.720381</td>\n",
       "      <td>0.019509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1903340</td>\n",
       "      <td>119542</td>\n",
       "      <td>0.546661</td>\n",
       "      <td>0.829281</td>\n",
       "      <td>0.709035</td>\n",
       "      <td>4</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.707433</td>\n",
       "      <td>0.558304</td>\n",
       "      <td>0.965264</td>\n",
       "      <td>0.625107</td>\n",
       "      <td>0.945125</td>\n",
       "      <td>858</td>\n",
       "      <td>9981</td>\n",
       "      <td>454</td>\n",
       "      <td>12616</td>\n",
       "      <td>0.706888</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3167020</td>\n",
       "      <td>96654</td>\n",
       "      <td>0.487222</td>\n",
       "      <td>1.052424</td>\n",
       "      <td>0.670666</td>\n",
       "      <td>5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.666091</td>\n",
       "      <td>0.528583</td>\n",
       "      <td>0.900297</td>\n",
       "      <td>0.689701</td>\n",
       "      <td>0.829807</td>\n",
       "      <td>2351</td>\n",
       "      <td>7562</td>\n",
       "      <td>939</td>\n",
       "      <td>8479</td>\n",
       "      <td>0.655188</td>\n",
       "      <td>0.010903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>648800</td>\n",
       "      <td>34646</td>\n",
       "      <td>0.489638</td>\n",
       "      <td>1.042373</td>\n",
       "      <td>0.659837</td>\n",
       "      <td>9</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.657240</td>\n",
       "      <td>0.491110</td>\n",
       "      <td>0.993221</td>\n",
       "      <td>0.625994</td>\n",
       "      <td>0.990188</td>\n",
       "      <td>45</td>\n",
       "      <td>3492</td>\n",
       "      <td>23</td>\n",
       "      <td>3370</td>\n",
       "      <td>0.657367</td>\n",
       "      <td>-0.000127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1145350</td>\n",
       "      <td>51398</td>\n",
       "      <td>0.410814</td>\n",
       "      <td>1.434249</td>\n",
       "      <td>0.658013</td>\n",
       "      <td>5</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.654708</td>\n",
       "      <td>0.508038</td>\n",
       "      <td>0.920436</td>\n",
       "      <td>0.712488</td>\n",
       "      <td>0.744261</td>\n",
       "      <td>2293</td>\n",
       "      <td>3764</td>\n",
       "      <td>336</td>\n",
       "      <td>3887</td>\n",
       "      <td>0.582362</td>\n",
       "      <td>0.072345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1326470</td>\n",
       "      <td>59319</td>\n",
       "      <td>0.456481</td>\n",
       "      <td>1.190652</td>\n",
       "      <td>0.633636</td>\n",
       "      <td>8</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.631787</td>\n",
       "      <td>0.474426</td>\n",
       "      <td>0.945347</td>\n",
       "      <td>0.625029</td>\n",
       "      <td>0.909643</td>\n",
       "      <td>776</td>\n",
       "      <td>5672</td>\n",
       "      <td>296</td>\n",
       "      <td>5120</td>\n",
       "      <td>0.626852</td>\n",
       "      <td>0.004935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1771300</td>\n",
       "      <td>80174</td>\n",
       "      <td>0.424252</td>\n",
       "      <td>1.357067</td>\n",
       "      <td>0.605381</td>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.605669</td>\n",
       "      <td>0.457654</td>\n",
       "      <td>0.895193</td>\n",
       "      <td>0.629807</td>\n",
       "      <td>0.829872</td>\n",
       "      <td>2015</td>\n",
       "      <td>7217</td>\n",
       "      <td>713</td>\n",
       "      <td>6090</td>\n",
       "      <td>0.595761</td>\n",
       "      <td>0.009907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3564740</td>\n",
       "      <td>93627</td>\n",
       "      <td>0.323475</td>\n",
       "      <td>2.091369</td>\n",
       "      <td>0.609566</td>\n",
       "      <td>30</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.603965</td>\n",
       "      <td>0.521880</td>\n",
       "      <td>0.716691</td>\n",
       "      <td>0.771939</td>\n",
       "      <td>0.444195</td>\n",
       "      <td>8692</td>\n",
       "      <td>3977</td>\n",
       "      <td>1716</td>\n",
       "      <td>4341</td>\n",
       "      <td>0.488803</td>\n",
       "      <td>0.115162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>990080</td>\n",
       "      <td>57746</td>\n",
       "      <td>0.407145</td>\n",
       "      <td>1.456201</td>\n",
       "      <td>0.600435</td>\n",
       "      <td>11</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.590995</td>\n",
       "      <td>0.482138</td>\n",
       "      <td>0.763343</td>\n",
       "      <td>0.673640</td>\n",
       "      <td>0.644675</td>\n",
       "      <td>2991</td>\n",
       "      <td>3856</td>\n",
       "      <td>1113</td>\n",
       "      <td>3590</td>\n",
       "      <td>0.578724</td>\n",
       "      <td>0.012271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3932890</td>\n",
       "      <td>41232</td>\n",
       "      <td>0.303817</td>\n",
       "      <td>2.291506</td>\n",
       "      <td>0.597028</td>\n",
       "      <td>16</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.585758</td>\n",
       "      <td>0.512890</td>\n",
       "      <td>0.682761</td>\n",
       "      <td>0.767138</td>\n",
       "      <td>0.404511</td>\n",
       "      <td>4116</td>\n",
       "      <td>1625</td>\n",
       "      <td>795</td>\n",
       "      <td>1711</td>\n",
       "      <td>0.466102</td>\n",
       "      <td>0.119656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1222670</td>\n",
       "      <td>30553</td>\n",
       "      <td>0.348804</td>\n",
       "      <td>1.867009</td>\n",
       "      <td>0.592544</td>\n",
       "      <td>14</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.580998</td>\n",
       "      <td>0.465405</td>\n",
       "      <td>0.772983</td>\n",
       "      <td>0.720112</td>\n",
       "      <td>0.579447</td>\n",
       "      <td>2086</td>\n",
       "      <td>1893</td>\n",
       "      <td>484</td>\n",
       "      <td>1648</td>\n",
       "      <td>0.517287</td>\n",
       "      <td>0.063710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>814380</td>\n",
       "      <td>34859</td>\n",
       "      <td>0.367107</td>\n",
       "      <td>1.723932</td>\n",
       "      <td>0.570114</td>\n",
       "      <td>9</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.571943</td>\n",
       "      <td>0.442943</td>\n",
       "      <td>0.806956</td>\n",
       "      <td>0.667472</td>\n",
       "      <td>0.668675</td>\n",
       "      <td>1816</td>\n",
       "      <td>2597</td>\n",
       "      <td>494</td>\n",
       "      <td>2065</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.034958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2139460</td>\n",
       "      <td>48140</td>\n",
       "      <td>0.270627</td>\n",
       "      <td>2.695454</td>\n",
       "      <td>0.563551</td>\n",
       "      <td>7</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.568597</td>\n",
       "      <td>0.481867</td>\n",
       "      <td>0.693400</td>\n",
       "      <td>0.786311</td>\n",
       "      <td>0.389489</td>\n",
       "      <td>5079</td>\n",
       "      <td>1943</td>\n",
       "      <td>799</td>\n",
       "      <td>1807</td>\n",
       "      <td>0.426026</td>\n",
       "      <td>0.142571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>440</td>\n",
       "      <td>44206</td>\n",
       "      <td>0.319821</td>\n",
       "      <td>2.126768</td>\n",
       "      <td>0.562488</td>\n",
       "      <td>27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.565448</td>\n",
       "      <td>0.506435</td>\n",
       "      <td>0.640028</td>\n",
       "      <td>0.739962</td>\n",
       "      <td>0.404207</td>\n",
       "      <td>4250</td>\n",
       "      <td>1764</td>\n",
       "      <td>1018</td>\n",
       "      <td>1810</td>\n",
       "      <td>0.484662</td>\n",
       "      <td>0.080787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1030300</td>\n",
       "      <td>238619</td>\n",
       "      <td>0.335510</td>\n",
       "      <td>1.980522</td>\n",
       "      <td>0.557365</td>\n",
       "      <td>13</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.552964</td>\n",
       "      <td>0.426261</td>\n",
       "      <td>0.786847</td>\n",
       "      <td>0.691619</td>\n",
       "      <td>0.619332</td>\n",
       "      <td>14754</td>\n",
       "      <td>16958</td>\n",
       "      <td>3413</td>\n",
       "      <td>12599</td>\n",
       "      <td>0.502448</td>\n",
       "      <td>0.050516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1144200</td>\n",
       "      <td>98213</td>\n",
       "      <td>0.322768</td>\n",
       "      <td>2.098186</td>\n",
       "      <td>0.555333</td>\n",
       "      <td>21</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.551508</td>\n",
       "      <td>0.463580</td>\n",
       "      <td>0.680599</td>\n",
       "      <td>0.714748</td>\n",
       "      <td>0.473858</td>\n",
       "      <td>8310</td>\n",
       "      <td>4993</td>\n",
       "      <td>2025</td>\n",
       "      <td>4315</td>\n",
       "      <td>0.488011</td>\n",
       "      <td>0.063497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>570</td>\n",
       "      <td>204029</td>\n",
       "      <td>0.193169</td>\n",
       "      <td>4.176736</td>\n",
       "      <td>0.561055</td>\n",
       "      <td>30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.544200</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.565466</td>\n",
       "      <td>0.797197</td>\n",
       "      <td>0.208254</td>\n",
       "      <td>28883</td>\n",
       "      <td>4041</td>\n",
       "      <td>3425</td>\n",
       "      <td>4457</td>\n",
       "      <td>0.323776</td>\n",
       "      <td>0.220424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>236390</td>\n",
       "      <td>45835</td>\n",
       "      <td>0.309480</td>\n",
       "      <td>2.231328</td>\n",
       "      <td>0.540079</td>\n",
       "      <td>16</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.540954</td>\n",
       "      <td>0.441912</td>\n",
       "      <td>0.697215</td>\n",
       "      <td>0.703639</td>\n",
       "      <td>0.488273</td>\n",
       "      <td>3832</td>\n",
       "      <td>2498</td>\n",
       "      <td>859</td>\n",
       "      <td>1978</td>\n",
       "      <td>0.472676</td>\n",
       "      <td>0.068279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2622380</td>\n",
       "      <td>35200</td>\n",
       "      <td>0.294801</td>\n",
       "      <td>2.391749</td>\n",
       "      <td>0.552177</td>\n",
       "      <td>20</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.540172</td>\n",
       "      <td>0.453652</td>\n",
       "      <td>0.667470</td>\n",
       "      <td>0.722758</td>\n",
       "      <td>0.433665</td>\n",
       "      <td>3297</td>\n",
       "      <td>1668</td>\n",
       "      <td>690</td>\n",
       "      <td>1385</td>\n",
       "      <td>0.455293</td>\n",
       "      <td>0.084878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1172470</td>\n",
       "      <td>71856</td>\n",
       "      <td>0.237767</td>\n",
       "      <td>3.205872</td>\n",
       "      <td>0.523689</td>\n",
       "      <td>4</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.527898</td>\n",
       "      <td>0.448051</td>\n",
       "      <td>0.642376</td>\n",
       "      <td>0.766489</td>\n",
       "      <td>0.340871</td>\n",
       "      <td>8251</td>\n",
       "      <td>2704</td>\n",
       "      <td>1222</td>\n",
       "      <td>2195</td>\n",
       "      <td>0.384170</td>\n",
       "      <td>0.143728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2246340</td>\n",
       "      <td>157833</td>\n",
       "      <td>0.263139</td>\n",
       "      <td>2.800301</td>\n",
       "      <td>0.512513</td>\n",
       "      <td>17</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.521556</td>\n",
       "      <td>0.415689</td>\n",
       "      <td>0.699771</td>\n",
       "      <td>0.732096</td>\n",
       "      <td>0.442994</td>\n",
       "      <td>15089</td>\n",
       "      <td>8171</td>\n",
       "      <td>2494</td>\n",
       "      <td>5813</td>\n",
       "      <td>0.416662</td>\n",
       "      <td>0.104893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1623730</td>\n",
       "      <td>53036</td>\n",
       "      <td>0.332397</td>\n",
       "      <td>2.008509</td>\n",
       "      <td>0.517183</td>\n",
       "      <td>15</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.516991</td>\n",
       "      <td>0.377999</td>\n",
       "      <td>0.817640</td>\n",
       "      <td>0.633839</td>\n",
       "      <td>0.718986</td>\n",
       "      <td>2338</td>\n",
       "      <td>4744</td>\n",
       "      <td>643</td>\n",
       "      <td>2883</td>\n",
       "      <td>0.498939</td>\n",
       "      <td>0.018052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2651280</td>\n",
       "      <td>31527</td>\n",
       "      <td>0.307705</td>\n",
       "      <td>2.249477</td>\n",
       "      <td>0.505055</td>\n",
       "      <td>25</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.514776</td>\n",
       "      <td>0.378674</td>\n",
       "      <td>0.803608</td>\n",
       "      <td>0.675250</td>\n",
       "      <td>0.652870</td>\n",
       "      <td>1808</td>\n",
       "      <td>2558</td>\n",
       "      <td>381</td>\n",
       "      <td>1559</td>\n",
       "      <td>0.470531</td>\n",
       "      <td>0.044245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>413150</td>\n",
       "      <td>81315</td>\n",
       "      <td>0.336420</td>\n",
       "      <td>1.972413</td>\n",
       "      <td>0.517344</td>\n",
       "      <td>17</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.514166</td>\n",
       "      <td>0.372920</td>\n",
       "      <td>0.827637</td>\n",
       "      <td>0.616336</td>\n",
       "      <td>0.746603</td>\n",
       "      <td>3178</td>\n",
       "      <td>7614</td>\n",
       "      <td>943</td>\n",
       "      <td>4528</td>\n",
       "      <td>0.503451</td>\n",
       "      <td>0.010715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2183900</td>\n",
       "      <td>49544</td>\n",
       "      <td>0.267722</td>\n",
       "      <td>2.735187</td>\n",
       "      <td>0.510077</td>\n",
       "      <td>10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.508977</td>\n",
       "      <td>0.409164</td>\n",
       "      <td>0.673200</td>\n",
       "      <td>0.726830</td>\n",
       "      <td>0.440509</td>\n",
       "      <td>4677</td>\n",
       "      <td>2579</td>\n",
       "      <td>867</td>\n",
       "      <td>1786</td>\n",
       "      <td>0.422385</td>\n",
       "      <td>0.086592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1086940</td>\n",
       "      <td>105187</td>\n",
       "      <td>0.299067</td>\n",
       "      <td>2.343714</td>\n",
       "      <td>0.482605</td>\n",
       "      <td>7</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.484358</td>\n",
       "      <td>0.357278</td>\n",
       "      <td>0.751748</td>\n",
       "      <td>0.637379</td>\n",
       "      <td>0.629290</td>\n",
       "      <td>6237</td>\n",
       "      <td>8509</td>\n",
       "      <td>1562</td>\n",
       "      <td>4730</td>\n",
       "      <td>0.460446</td>\n",
       "      <td>0.023912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>526870</td>\n",
       "      <td>40282</td>\n",
       "      <td>0.309940</td>\n",
       "      <td>2.226533</td>\n",
       "      <td>0.483668</td>\n",
       "      <td>16</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.483539</td>\n",
       "      <td>0.323295</td>\n",
       "      <td>0.958751</td>\n",
       "      <td>0.618508</td>\n",
       "      <td>0.919077</td>\n",
       "      <td>549</td>\n",
       "      <td>5011</td>\n",
       "      <td>103</td>\n",
       "      <td>2394</td>\n",
       "      <td>0.473186</td>\n",
       "      <td>0.010353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3159330</td>\n",
       "      <td>32102</td>\n",
       "      <td>0.222946</td>\n",
       "      <td>3.485590</td>\n",
       "      <td>0.486445</td>\n",
       "      <td>16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.479753</td>\n",
       "      <td>0.430394</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.718346</td>\n",
       "      <td>0.280797</td>\n",
       "      <td>3962</td>\n",
       "      <td>1027</td>\n",
       "      <td>656</td>\n",
       "      <td>776</td>\n",
       "      <td>0.364701</td>\n",
       "      <td>0.115051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3489700</td>\n",
       "      <td>78701</td>\n",
       "      <td>0.268586</td>\n",
       "      <td>2.723241</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>18</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.479288</td>\n",
       "      <td>0.394027</td>\n",
       "      <td>0.611637</td>\n",
       "      <td>0.680943</td>\n",
       "      <td>0.416937</td>\n",
       "      <td>7536</td>\n",
       "      <td>3977</td>\n",
       "      <td>1642</td>\n",
       "      <td>2586</td>\n",
       "      <td>0.423456</td>\n",
       "      <td>0.055832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>230410</td>\n",
       "      <td>48982</td>\n",
       "      <td>0.204279</td>\n",
       "      <td>3.895066</td>\n",
       "      <td>0.473326</td>\n",
       "      <td>10</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.476069</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.559220</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.275595</td>\n",
       "      <td>6215</td>\n",
       "      <td>1581</td>\n",
       "      <td>882</td>\n",
       "      <td>1119</td>\n",
       "      <td>0.339210</td>\n",
       "      <td>0.136859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>108600</td>\n",
       "      <td>83054</td>\n",
       "      <td>0.287054</td>\n",
       "      <td>2.483681</td>\n",
       "      <td>0.471217</td>\n",
       "      <td>11</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.474826</td>\n",
       "      <td>0.341618</td>\n",
       "      <td>0.778314</td>\n",
       "      <td>0.651062</td>\n",
       "      <td>0.653964</td>\n",
       "      <td>4691</td>\n",
       "      <td>7152</td>\n",
       "      <td>1057</td>\n",
       "      <td>3711</td>\n",
       "      <td>0.446045</td>\n",
       "      <td>0.028780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3513350</td>\n",
       "      <td>37631</td>\n",
       "      <td>0.179878</td>\n",
       "      <td>4.559326</td>\n",
       "      <td>0.448748</td>\n",
       "      <td>17</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.442659</td>\n",
       "      <td>0.437861</td>\n",
       "      <td>0.447563</td>\n",
       "      <td>0.735379</td>\n",
       "      <td>0.183871</td>\n",
       "      <td>5395</td>\n",
       "      <td>778</td>\n",
       "      <td>748</td>\n",
       "      <td>606</td>\n",
       "      <td>0.304921</td>\n",
       "      <td>0.137738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>578080</td>\n",
       "      <td>193853</td>\n",
       "      <td>0.173090</td>\n",
       "      <td>4.777452</td>\n",
       "      <td>0.440316</td>\n",
       "      <td>30</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.441363</td>\n",
       "      <td>0.372906</td>\n",
       "      <td>0.540605</td>\n",
       "      <td>0.739769</td>\n",
       "      <td>0.250935</td>\n",
       "      <td>25959</td>\n",
       "      <td>6101</td>\n",
       "      <td>3083</td>\n",
       "      <td>3628</td>\n",
       "      <td>0.295106</td>\n",
       "      <td>0.146257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1091500</td>\n",
       "      <td>119802</td>\n",
       "      <td>0.257667</td>\n",
       "      <td>2.880948</td>\n",
       "      <td>0.439219</td>\n",
       "      <td>10</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.439674</td>\n",
       "      <td>0.335232</td>\n",
       "      <td>0.638646</td>\n",
       "      <td>0.643203</td>\n",
       "      <td>0.490881</td>\n",
       "      <td>9968</td>\n",
       "      <td>7819</td>\n",
       "      <td>2231</td>\n",
       "      <td>3943</td>\n",
       "      <td>0.409756</td>\n",
       "      <td>0.029918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2807960</td>\n",
       "      <td>300088</td>\n",
       "      <td>0.157780</td>\n",
       "      <td>5.338063</td>\n",
       "      <td>0.444263</td>\n",
       "      <td>13</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.436897</td>\n",
       "      <td>0.352693</td>\n",
       "      <td>0.573918</td>\n",
       "      <td>0.756216</td>\n",
       "      <td>0.256756</td>\n",
       "      <td>40573</td>\n",
       "      <td>9975</td>\n",
       "      <td>4035</td>\n",
       "      <td>5435</td>\n",
       "      <td>0.272565</td>\n",
       "      <td>0.164332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1245620</td>\n",
       "      <td>108874</td>\n",
       "      <td>0.265821</td>\n",
       "      <td>2.761959</td>\n",
       "      <td>0.432670</td>\n",
       "      <td>7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.432127</td>\n",
       "      <td>0.284342</td>\n",
       "      <td>0.899793</td>\n",
       "      <td>0.623547</td>\n",
       "      <td>0.841148</td>\n",
       "      <td>2879</td>\n",
       "      <td>13108</td>\n",
       "      <td>580</td>\n",
       "      <td>5208</td>\n",
       "      <td>0.419983</td>\n",
       "      <td>0.012144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>394360</td>\n",
       "      <td>41971</td>\n",
       "      <td>0.188463</td>\n",
       "      <td>4.306203</td>\n",
       "      <td>0.444881</td>\n",
       "      <td>12</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.365435</td>\n",
       "      <td>0.525284</td>\n",
       "      <td>0.717861</td>\n",
       "      <td>0.270876</td>\n",
       "      <td>5370</td>\n",
       "      <td>1443</td>\n",
       "      <td>751</td>\n",
       "      <td>831</td>\n",
       "      <td>0.317129</td>\n",
       "      <td>0.113887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3241660</td>\n",
       "      <td>340625</td>\n",
       "      <td>0.219902</td>\n",
       "      <td>3.547541</td>\n",
       "      <td>0.422256</td>\n",
       "      <td>29</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.421843</td>\n",
       "      <td>0.334178</td>\n",
       "      <td>0.571858</td>\n",
       "      <td>0.674870</td>\n",
       "      <td>0.376308</td>\n",
       "      <td>36075</td>\n",
       "      <td>17069</td>\n",
       "      <td>6414</td>\n",
       "      <td>8567</td>\n",
       "      <td>0.360528</td>\n",
       "      <td>0.061316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>294100</td>\n",
       "      <td>30831</td>\n",
       "      <td>0.233110</td>\n",
       "      <td>3.290280</td>\n",
       "      <td>0.402726</td>\n",
       "      <td>11</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.400075</td>\n",
       "      <td>0.273776</td>\n",
       "      <td>0.742698</td>\n",
       "      <td>0.621121</td>\n",
       "      <td>0.632560</td>\n",
       "      <td>1896</td>\n",
       "      <td>2833</td>\n",
       "      <td>370</td>\n",
       "      <td>1068</td>\n",
       "      <td>0.378172</td>\n",
       "      <td>0.021903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>227300</td>\n",
       "      <td>92151</td>\n",
       "      <td>0.227171</td>\n",
       "      <td>3.401851</td>\n",
       "      <td>0.404417</td>\n",
       "      <td>10</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.396119</td>\n",
       "      <td>0.270296</td>\n",
       "      <td>0.741103</td>\n",
       "      <td>0.627108</td>\n",
       "      <td>0.622864</td>\n",
       "      <td>5867</td>\n",
       "      <td>8377</td>\n",
       "      <td>1084</td>\n",
       "      <td>3103</td>\n",
       "      <td>0.370236</td>\n",
       "      <td>0.025883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3240220</td>\n",
       "      <td>138626</td>\n",
       "      <td>0.219338</td>\n",
       "      <td>3.559096</td>\n",
       "      <td>0.400922</td>\n",
       "      <td>6</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.383962</td>\n",
       "      <td>0.262139</td>\n",
       "      <td>0.717316</td>\n",
       "      <td>0.630309</td>\n",
       "      <td>0.600159</td>\n",
       "      <td>9367</td>\n",
       "      <td>12278</td>\n",
       "      <td>1719</td>\n",
       "      <td>4362</td>\n",
       "      <td>0.359748</td>\n",
       "      <td>0.024214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1551360</td>\n",
       "      <td>53036</td>\n",
       "      <td>0.217230</td>\n",
       "      <td>3.602929</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.382538</td>\n",
       "      <td>0.288229</td>\n",
       "      <td>0.568576</td>\n",
       "      <td>0.639317</td>\n",
       "      <td>0.428450</td>\n",
       "      <td>5069</td>\n",
       "      <td>3235</td>\n",
       "      <td>994</td>\n",
       "      <td>1310</td>\n",
       "      <td>0.356877</td>\n",
       "      <td>0.025660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1973530</td>\n",
       "      <td>43061</td>\n",
       "      <td>0.084206</td>\n",
       "      <td>10.873330</td>\n",
       "      <td>0.346130</td>\n",
       "      <td>8</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.379401</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0.497931</td>\n",
       "      <td>0.781688</td>\n",
       "      <td>0.136770</td>\n",
       "      <td>7071</td>\n",
       "      <td>817</td>\n",
       "      <td>364</td>\n",
       "      <td>361</td>\n",
       "      <td>0.155280</td>\n",
       "      <td>0.224121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1808500</td>\n",
       "      <td>252277</td>\n",
       "      <td>0.186660</td>\n",
       "      <td>4.357401</td>\n",
       "      <td>0.384392</td>\n",
       "      <td>28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.375319</td>\n",
       "      <td>0.309792</td>\n",
       "      <td>0.476003</td>\n",
       "      <td>0.673607</td>\n",
       "      <td>0.286804</td>\n",
       "      <td>31050</td>\n",
       "      <td>9988</td>\n",
       "      <td>4935</td>\n",
       "      <td>4483</td>\n",
       "      <td>0.314594</td>\n",
       "      <td>0.060725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3405690</td>\n",
       "      <td>36162</td>\n",
       "      <td>0.174050</td>\n",
       "      <td>4.745531</td>\n",
       "      <td>0.370243</td>\n",
       "      <td>23</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.363878</td>\n",
       "      <td>0.273344</td>\n",
       "      <td>0.544083</td>\n",
       "      <td>0.679149</td>\n",
       "      <td>0.346468</td>\n",
       "      <td>4153</td>\n",
       "      <td>1821</td>\n",
       "      <td>574</td>\n",
       "      <td>685</td>\n",
       "      <td>0.296514</td>\n",
       "      <td>0.067363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>553850</td>\n",
       "      <td>148012</td>\n",
       "      <td>0.139239</td>\n",
       "      <td>6.181729</td>\n",
       "      <td>0.364004</td>\n",
       "      <td>17</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.353713</td>\n",
       "      <td>0.302763</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>0.715653</td>\n",
       "      <td>0.195588</td>\n",
       "      <td>21444</td>\n",
       "      <td>4037</td>\n",
       "      <td>2369</td>\n",
       "      <td>1753</td>\n",
       "      <td>0.244448</td>\n",
       "      <td>0.109265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>730</td>\n",
       "      <td>272473</td>\n",
       "      <td>0.184881</td>\n",
       "      <td>4.408871</td>\n",
       "      <td>0.347161</td>\n",
       "      <td>14</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.344486</td>\n",
       "      <td>0.228729</td>\n",
       "      <td>0.697469</td>\n",
       "      <td>0.630139</td>\n",
       "      <td>0.563758</td>\n",
       "      <td>20725</td>\n",
       "      <td>23695</td>\n",
       "      <td>3048</td>\n",
       "      <td>7027</td>\n",
       "      <td>0.312064</td>\n",
       "      <td>0.032422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      appid  n_rows  churn_rate  pos_weight  best_valid_f1  best_epoch  \\\n",
       "0   3527290   31721    0.699001    0.430585       0.823557           3   \n",
       "1   1222140   64366    0.648681    0.541596       0.788677          21   \n",
       "2   2592160  150629    0.594527    0.682027       0.770578          30   \n",
       "3   2001120  109621    0.562949    0.776371       0.739562          30   \n",
       "4   1903340  119542    0.546661    0.829281       0.709035           4   \n",
       "5   3167020   96654    0.487222    1.052424       0.670666           5   \n",
       "6    648800   34646    0.489638    1.042373       0.659837           9   \n",
       "7   1145350   51398    0.410814    1.434249       0.658013           5   \n",
       "8   1326470   59319    0.456481    1.190652       0.633636           8   \n",
       "9   1771300   80174    0.424252    1.357067       0.605381           5   \n",
       "10  3564740   93627    0.323475    2.091369       0.609566          30   \n",
       "11   990080   57746    0.407145    1.456201       0.600435          11   \n",
       "12  3932890   41232    0.303817    2.291506       0.597028          16   \n",
       "13  1222670   30553    0.348804    1.867009       0.592544          14   \n",
       "14   814380   34859    0.367107    1.723932       0.570114           9   \n",
       "15  2139460   48140    0.270627    2.695454       0.563551           7   \n",
       "16      440   44206    0.319821    2.126768       0.562488          27   \n",
       "17  1030300  238619    0.335510    1.980522       0.557365          13   \n",
       "18  1144200   98213    0.322768    2.098186       0.555333          21   \n",
       "19      570  204029    0.193169    4.176736       0.561055          30   \n",
       "20   236390   45835    0.309480    2.231328       0.540079          16   \n",
       "21  2622380   35200    0.294801    2.391749       0.552177          20   \n",
       "22  1172470   71856    0.237767    3.205872       0.523689           4   \n",
       "23  2246340  157833    0.263139    2.800301       0.512513          17   \n",
       "24  1623730   53036    0.332397    2.008509       0.517183          15   \n",
       "25  2651280   31527    0.307705    2.249477       0.505055          25   \n",
       "26   413150   81315    0.336420    1.972413       0.517344          17   \n",
       "27  2183900   49544    0.267722    2.735187       0.510077          10   \n",
       "28  1086940  105187    0.299067    2.343714       0.482605           7   \n",
       "29   526870   40282    0.309940    2.226533       0.483668          16   \n",
       "30  3159330   32102    0.222946    3.485590       0.486445          16   \n",
       "31  3489700   78701    0.268586    2.723241       0.490909          18   \n",
       "32   230410   48982    0.204279    3.895066       0.473326          10   \n",
       "33   108600   83054    0.287054    2.483681       0.471217          11   \n",
       "34  3513350   37631    0.179878    4.559326       0.448748          17   \n",
       "35   578080  193853    0.173090    4.777452       0.440316          30   \n",
       "36  1091500  119802    0.257667    2.880948       0.439219          10   \n",
       "37  2807960  300088    0.157780    5.338063       0.444263          13   \n",
       "38  1245620  108874    0.265821    2.761959       0.432670           7   \n",
       "39   394360   41971    0.188463    4.306203       0.444881          12   \n",
       "40  3241660  340625    0.219902    3.547541       0.422256          29   \n",
       "41   294100   30831    0.233110    3.290280       0.402726          11   \n",
       "42   227300   92151    0.227171    3.401851       0.404417          10   \n",
       "43  3240220  138626    0.219338    3.559096       0.400922           6   \n",
       "44  1551360   53036    0.217230    3.602929       0.392500          10   \n",
       "45  1973530   43061    0.084206   10.873330       0.346130           8   \n",
       "46  1808500  252277    0.186660    4.357401       0.384392          28   \n",
       "47  3405690   36162    0.174050    4.745531       0.370243          23   \n",
       "48   553850  148012    0.139239    6.181729       0.364004          17   \n",
       "49      730  272473    0.184881    4.408871       0.347161          14   \n",
       "\n",
       "    best_thr   test_f1  test_precision  test_recall  test_roc_auc  \\\n",
       "0       0.18  0.823288        0.701429     0.996392      0.632280   \n",
       "1       0.32  0.787336        0.651553     0.994611      0.583590   \n",
       "2       0.34  0.765926        0.665063     0.902853      0.688863   \n",
       "3       0.32  0.739890        0.607041     0.947177      0.699665   \n",
       "4       0.34  0.707433        0.558304     0.965264      0.625107   \n",
       "5       0.36  0.666091        0.528583     0.900297      0.689701   \n",
       "6       0.32  0.657240        0.491110     0.993221      0.625994   \n",
       "7       0.44  0.654708        0.508038     0.920436      0.712488   \n",
       "8       0.36  0.631787        0.474426     0.945347      0.625029   \n",
       "9       0.40  0.605669        0.457654     0.895193      0.629807   \n",
       "10      0.44  0.603965        0.521880     0.716691      0.771939   \n",
       "11      0.40  0.590995        0.482138     0.763343      0.673640   \n",
       "12      0.52  0.585758        0.512890     0.682761      0.767138   \n",
       "13      0.42  0.580998        0.465405     0.772983      0.720112   \n",
       "14      0.42  0.571943        0.442943     0.806956      0.667472   \n",
       "15      0.50  0.568597        0.481867     0.693400      0.786311   \n",
       "16      0.50  0.565448        0.506435     0.640028      0.739962   \n",
       "17      0.42  0.552964        0.426261     0.786847      0.691619   \n",
       "18      0.44  0.551508        0.463580     0.680599      0.714748   \n",
       "19      0.60  0.544200        0.524476     0.565466      0.797197   \n",
       "20      0.46  0.540954        0.441912     0.697215      0.703639   \n",
       "21      0.48  0.540172        0.453652     0.667470      0.722758   \n",
       "22      0.52  0.527898        0.448051     0.642376      0.766489   \n",
       "23      0.50  0.521556        0.415689     0.699771      0.732096   \n",
       "24      0.42  0.516991        0.377999     0.817640      0.633839   \n",
       "25      0.42  0.514776        0.378674     0.803608      0.675250   \n",
       "26      0.42  0.514166        0.372920     0.827637      0.616336   \n",
       "27      0.52  0.508977        0.409164     0.673200      0.726830   \n",
       "28      0.44  0.484358        0.357278     0.751748      0.637379   \n",
       "29      0.36  0.483539        0.323295     0.958751      0.618508   \n",
       "30      0.54  0.479753        0.430394     0.541899      0.718346   \n",
       "31      0.48  0.479288        0.394027     0.611637      0.680943   \n",
       "32      0.56  0.476069        0.414444     0.559220      0.741321   \n",
       "33      0.44  0.474826        0.341618     0.778314      0.651062   \n",
       "34      0.58  0.442659        0.437861     0.447563      0.735379   \n",
       "35      0.58  0.441363        0.372906     0.540605      0.739769   \n",
       "36      0.46  0.439674        0.335232     0.638646      0.643203   \n",
       "37      0.58  0.436897        0.352693     0.573918      0.756216   \n",
       "38      0.40  0.432127        0.284342     0.899793      0.623547   \n",
       "39      0.52  0.431017        0.365435     0.525284      0.717861   \n",
       "40      0.50  0.421843        0.334178     0.571858      0.674870   \n",
       "41      0.44  0.400075        0.273776     0.742698      0.621121   \n",
       "42      0.46  0.396119        0.270296     0.741103      0.627108   \n",
       "43      0.46  0.383962        0.262139     0.717316      0.630309   \n",
       "44      0.48  0.382538        0.288229     0.568576      0.639317   \n",
       "45      0.68  0.379401        0.306452     0.497931      0.781688   \n",
       "46      0.50  0.375319        0.309792     0.476003      0.673607   \n",
       "47      0.52  0.363878        0.273344     0.544083      0.679149   \n",
       "48      0.58  0.353713        0.302763     0.425279      0.715653   \n",
       "49      0.46  0.344486        0.228729     0.697469      0.630139   \n",
       "\n",
       "    test_pred_pos_rate     tn     fp    fn     tp   all1_f1  gain_vs_all1  \n",
       "0             0.992908     29   1881    16   4419  0.822820      0.000468  \n",
       "1             0.990213     81   4442    45   8306  0.786902      0.000434  \n",
       "2             0.807110   4071   8144  1740  16171  0.745717      0.020209  \n",
       "3             0.878404   2014   7568   652  11691  0.720381      0.019509  \n",
       "4             0.945125    858   9981   454  12616  0.706888      0.000545  \n",
       "5             0.829807   2351   7562   939   8479  0.655188      0.010903  \n",
       "6             0.990188     45   3492    23   3370  0.657367     -0.000127  \n",
       "7             0.744261   2293   3764   336   3887  0.582362      0.072345  \n",
       "8             0.909643    776   5672   296   5120  0.626852      0.004935  \n",
       "9             0.829872   2015   7217   713   6090  0.595761      0.009907  \n",
       "10            0.444195   8692   3977  1716   4341  0.488803      0.115162  \n",
       "11            0.644675   2991   3856  1113   3590  0.578724      0.012271  \n",
       "12            0.404511   4116   1625   795   1711  0.466102      0.119656  \n",
       "13            0.579447   2086   1893   484   1648  0.517287      0.063710  \n",
       "14            0.668675   1816   2597   494   2065  0.536985      0.034958  \n",
       "15            0.389489   5079   1943   799   1807  0.426026      0.142571  \n",
       "16            0.404207   4250   1764  1018   1810  0.484662      0.080787  \n",
       "17            0.619332  14754  16958  3413  12599  0.502448      0.050516  \n",
       "18            0.473858   8310   4993  2025   4315  0.488011      0.063497  \n",
       "19            0.208254  28883   4041  3425   4457  0.323776      0.220424  \n",
       "20            0.488273   3832   2498   859   1978  0.472676      0.068279  \n",
       "21            0.433665   3297   1668   690   1385  0.455293      0.084878  \n",
       "22            0.340871   8251   2704  1222   2195  0.384170      0.143728  \n",
       "23            0.442994  15089   8171  2494   5813  0.416662      0.104893  \n",
       "24            0.718986   2338   4744   643   2883  0.498939      0.018052  \n",
       "25            0.652870   1808   2558   381   1559  0.470531      0.044245  \n",
       "26            0.746603   3178   7614   943   4528  0.503451      0.010715  \n",
       "27            0.440509   4677   2579   867   1786  0.422385      0.086592  \n",
       "28            0.629290   6237   8509  1562   4730  0.460446      0.023912  \n",
       "29            0.919077    549   5011   103   2394  0.473186      0.010353  \n",
       "30            0.280797   3962   1027   656    776  0.364701      0.115051  \n",
       "31            0.416937   7536   3977  1642   2586  0.423456      0.055832  \n",
       "32            0.275595   6215   1581   882   1119  0.339210      0.136859  \n",
       "33            0.653964   4691   7152  1057   3711  0.446045      0.028780  \n",
       "34            0.183871   5395    778   748    606  0.304921      0.137738  \n",
       "35            0.250935  25959   6101  3083   3628  0.295106      0.146257  \n",
       "36            0.490881   9968   7819  2231   3943  0.409756      0.029918  \n",
       "37            0.256756  40573   9975  4035   5435  0.272565      0.164332  \n",
       "38            0.841148   2879  13108   580   5208  0.419983      0.012144  \n",
       "39            0.270876   5370   1443   751    831  0.317129      0.113887  \n",
       "40            0.376308  36075  17069  6414   8567  0.360528      0.061316  \n",
       "41            0.632560   1896   2833   370   1068  0.378172      0.021903  \n",
       "42            0.622864   5867   8377  1084   3103  0.370236      0.025883  \n",
       "43            0.600159   9367  12278  1719   4362  0.359748      0.024214  \n",
       "44            0.428450   5069   3235   994   1310  0.356877      0.025660  \n",
       "45            0.136770   7071    817   364    361  0.155280      0.224121  \n",
       "46            0.286804  31050   9988  4935   4483  0.314594      0.060725  \n",
       "47            0.346468   4153   1821   574    685  0.296514      0.067363  \n",
       "48            0.195588  21444   4037  2369   1753  0.244448      0.109265  \n",
       "49            0.563758  20725  23695  3048   7027  0.312064      0.032422  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 11. best_by_game(게임별 1개)\n",
    "best_by_game = (\n",
    "    results_df.sort_values([\"appid\", \"test_f1\", \"test_recall\"], ascending=[True, False, False])\n",
    "              .groupby(\"appid\", as_index=False)\n",
    "              .head(1)\n",
    "              .sort_values(\"test_f1\", ascending=False)\n",
    "              .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "display(best_by_game.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8afce2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "튜닝 대상 appid 개수: 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>churn_rate</th>\n",
       "      <th>best_valid_f1</th>\n",
       "      <th>best_thr</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_pred_pos_rate</th>\n",
       "      <th>pos_gap</th>\n",
       "      <th>pos_mult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>730</td>\n",
       "      <td>272473</td>\n",
       "      <td>0.184881</td>\n",
       "      <td>0.347161</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.228729</td>\n",
       "      <td>0.697469</td>\n",
       "      <td>0.344486</td>\n",
       "      <td>0.563758</td>\n",
       "      <td>0.378877</td>\n",
       "      <td>3.049308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>553850</td>\n",
       "      <td>148012</td>\n",
       "      <td>0.139239</td>\n",
       "      <td>0.364004</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.302763</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>0.353713</td>\n",
       "      <td>0.195588</td>\n",
       "      <td>0.056350</td>\n",
       "      <td>1.404698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3405690</td>\n",
       "      <td>36162</td>\n",
       "      <td>0.174050</td>\n",
       "      <td>0.370243</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.273344</td>\n",
       "      <td>0.544083</td>\n",
       "      <td>0.363878</td>\n",
       "      <td>0.346468</td>\n",
       "      <td>0.172417</td>\n",
       "      <td>1.990620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1808500</td>\n",
       "      <td>252277</td>\n",
       "      <td>0.186660</td>\n",
       "      <td>0.384392</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.309792</td>\n",
       "      <td>0.476003</td>\n",
       "      <td>0.375319</td>\n",
       "      <td>0.286804</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>1.536508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1973530</td>\n",
       "      <td>43061</td>\n",
       "      <td>0.084206</td>\n",
       "      <td>0.346130</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0.497931</td>\n",
       "      <td>0.379401</td>\n",
       "      <td>0.136770</td>\n",
       "      <td>0.052564</td>\n",
       "      <td>1.624229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1551360</td>\n",
       "      <td>53036</td>\n",
       "      <td>0.217230</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.288229</td>\n",
       "      <td>0.568576</td>\n",
       "      <td>0.382538</td>\n",
       "      <td>0.428450</td>\n",
       "      <td>0.211220</td>\n",
       "      <td>1.972336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3240220</td>\n",
       "      <td>138626</td>\n",
       "      <td>0.219338</td>\n",
       "      <td>0.400922</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.262139</td>\n",
       "      <td>0.717316</td>\n",
       "      <td>0.383962</td>\n",
       "      <td>0.600159</td>\n",
       "      <td>0.380820</td>\n",
       "      <td>2.736223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>227300</td>\n",
       "      <td>92151</td>\n",
       "      <td>0.227171</td>\n",
       "      <td>0.404417</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.270296</td>\n",
       "      <td>0.741103</td>\n",
       "      <td>0.396119</td>\n",
       "      <td>0.622864</td>\n",
       "      <td>0.395693</td>\n",
       "      <td>2.741832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>294100</td>\n",
       "      <td>30831</td>\n",
       "      <td>0.233110</td>\n",
       "      <td>0.402726</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.273776</td>\n",
       "      <td>0.742698</td>\n",
       "      <td>0.400075</td>\n",
       "      <td>0.632560</td>\n",
       "      <td>0.399451</td>\n",
       "      <td>2.713576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3241660</td>\n",
       "      <td>340625</td>\n",
       "      <td>0.219902</td>\n",
       "      <td>0.422256</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.334178</td>\n",
       "      <td>0.571858</td>\n",
       "      <td>0.421843</td>\n",
       "      <td>0.376308</td>\n",
       "      <td>0.156407</td>\n",
       "      <td>1.711257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>394360</td>\n",
       "      <td>41971</td>\n",
       "      <td>0.188463</td>\n",
       "      <td>0.444881</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.365435</td>\n",
       "      <td>0.525284</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.270876</td>\n",
       "      <td>0.082412</td>\n",
       "      <td>1.437284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1245620</td>\n",
       "      <td>108874</td>\n",
       "      <td>0.265821</td>\n",
       "      <td>0.432670</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.284342</td>\n",
       "      <td>0.899793</td>\n",
       "      <td>0.432127</td>\n",
       "      <td>0.841148</td>\n",
       "      <td>0.575327</td>\n",
       "      <td>3.164340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2807960</td>\n",
       "      <td>300088</td>\n",
       "      <td>0.157780</td>\n",
       "      <td>0.444263</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.352693</td>\n",
       "      <td>0.573918</td>\n",
       "      <td>0.436897</td>\n",
       "      <td>0.256756</td>\n",
       "      <td>0.098976</td>\n",
       "      <td>1.627302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1091500</td>\n",
       "      <td>119802</td>\n",
       "      <td>0.257667</td>\n",
       "      <td>0.439219</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.335232</td>\n",
       "      <td>0.638646</td>\n",
       "      <td>0.439674</td>\n",
       "      <td>0.490881</td>\n",
       "      <td>0.233214</td>\n",
       "      <td>1.905100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>578080</td>\n",
       "      <td>193853</td>\n",
       "      <td>0.173090</td>\n",
       "      <td>0.440316</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.372906</td>\n",
       "      <td>0.540605</td>\n",
       "      <td>0.441363</td>\n",
       "      <td>0.250935</td>\n",
       "      <td>0.077845</td>\n",
       "      <td>1.449738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3513350</td>\n",
       "      <td>37631</td>\n",
       "      <td>0.179878</td>\n",
       "      <td>0.448748</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.437861</td>\n",
       "      <td>0.447563</td>\n",
       "      <td>0.442659</td>\n",
       "      <td>0.183871</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>1.022199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>108600</td>\n",
       "      <td>83054</td>\n",
       "      <td>0.287054</td>\n",
       "      <td>0.471217</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.341618</td>\n",
       "      <td>0.778314</td>\n",
       "      <td>0.474826</td>\n",
       "      <td>0.653964</td>\n",
       "      <td>0.366910</td>\n",
       "      <td>2.278191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>230410</td>\n",
       "      <td>48982</td>\n",
       "      <td>0.204279</td>\n",
       "      <td>0.473326</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.559220</td>\n",
       "      <td>0.476069</td>\n",
       "      <td>0.275595</td>\n",
       "      <td>0.071315</td>\n",
       "      <td>1.349108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3489700</td>\n",
       "      <td>78701</td>\n",
       "      <td>0.268586</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.394027</td>\n",
       "      <td>0.611637</td>\n",
       "      <td>0.479288</td>\n",
       "      <td>0.416937</td>\n",
       "      <td>0.148350</td>\n",
       "      <td>1.552339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3159330</td>\n",
       "      <td>32102</td>\n",
       "      <td>0.222946</td>\n",
       "      <td>0.486445</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.430394</td>\n",
       "      <td>0.541899</td>\n",
       "      <td>0.479753</td>\n",
       "      <td>0.280797</td>\n",
       "      <td>0.057852</td>\n",
       "      <td>1.259488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      appid  n_rows  churn_rate  best_valid_f1  best_thr  test_precision  \\\n",
       "49      730  272473    0.184881       0.347161      0.46        0.228729   \n",
       "48   553850  148012    0.139239       0.364004      0.58        0.302763   \n",
       "47  3405690   36162    0.174050       0.370243      0.52        0.273344   \n",
       "46  1808500  252277    0.186660       0.384392      0.50        0.309792   \n",
       "45  1973530   43061    0.084206       0.346130      0.68        0.306452   \n",
       "44  1551360   53036    0.217230       0.392500      0.48        0.288229   \n",
       "43  3240220  138626    0.219338       0.400922      0.46        0.262139   \n",
       "42   227300   92151    0.227171       0.404417      0.46        0.270296   \n",
       "41   294100   30831    0.233110       0.402726      0.44        0.273776   \n",
       "40  3241660  340625    0.219902       0.422256      0.50        0.334178   \n",
       "39   394360   41971    0.188463       0.444881      0.52        0.365435   \n",
       "38  1245620  108874    0.265821       0.432670      0.40        0.284342   \n",
       "37  2807960  300088    0.157780       0.444263      0.58        0.352693   \n",
       "36  1091500  119802    0.257667       0.439219      0.46        0.335232   \n",
       "35   578080  193853    0.173090       0.440316      0.58        0.372906   \n",
       "34  3513350   37631    0.179878       0.448748      0.58        0.437861   \n",
       "33   108600   83054    0.287054       0.471217      0.44        0.341618   \n",
       "32   230410   48982    0.204279       0.473326      0.56        0.414444   \n",
       "31  3489700   78701    0.268586       0.490909      0.48        0.394027   \n",
       "30  3159330   32102    0.222946       0.486445      0.54        0.430394   \n",
       "\n",
       "    test_recall   test_f1  test_pred_pos_rate   pos_gap  pos_mult  \n",
       "49     0.697469  0.344486            0.563758  0.378877  3.049308  \n",
       "48     0.425279  0.353713            0.195588  0.056350  1.404698  \n",
       "47     0.544083  0.363878            0.346468  0.172417  1.990620  \n",
       "46     0.476003  0.375319            0.286804  0.100144  1.536508  \n",
       "45     0.497931  0.379401            0.136770  0.052564  1.624229  \n",
       "44     0.568576  0.382538            0.428450  0.211220  1.972336  \n",
       "43     0.717316  0.383962            0.600159  0.380820  2.736223  \n",
       "42     0.741103  0.396119            0.622864  0.395693  2.741832  \n",
       "41     0.742698  0.400075            0.632560  0.399451  2.713576  \n",
       "40     0.571858  0.421843            0.376308  0.156407  1.711257  \n",
       "39     0.525284  0.431017            0.270876  0.082412  1.437284  \n",
       "38     0.899793  0.432127            0.841148  0.575327  3.164340  \n",
       "37     0.573918  0.436897            0.256756  0.098976  1.627302  \n",
       "36     0.638646  0.439674            0.490881  0.233214  1.905100  \n",
       "35     0.540605  0.441363            0.250935  0.077845  1.449738  \n",
       "34     0.447563  0.442659            0.183871  0.003993  1.022199  \n",
       "33     0.778314  0.474826            0.653964  0.366910  2.278191  \n",
       "32     0.559220  0.476069            0.275595  0.071315  1.349108  \n",
       "31     0.611637  0.479288            0.416937  0.148350  1.552339  \n",
       "30     0.541899  0.479753            0.280797  0.057852  1.259488  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 12. 튜닝 대상 선정(과대예측/저성능 게임)\n",
    "best_df = best_by_game.copy()\n",
    "\n",
    "F1_LOW = 0.50   # F1 스코어가 0.5 미만인 게임 필터링\n",
    "POS_GAP = 0.25  # 예측 양성 비율이 실제 churn_rate보다 0.25 이상 높으면 과대예측\n",
    "POS_MULT = 1.8  # 예측 양성 비율이 실제보다 1.8배 이상이면 심한 과대예측\n",
    "\n",
    "# 과대예측 지표 만들기\n",
    "# 예측 1비율 - 실제 1비율\n",
    "best_df[\"pos_gap\"]  = best_df[\"test_pred_pos_rate\"] - best_df[\"churn_rate\"]\n",
    "# 예측 1비율 / 실제 1비율\n",
    "best_df[\"pos_mult\"] = best_df[\"test_pred_pos_rate\"] / (best_df[\"churn_rate\"] + 1e-12)\n",
    "\n",
    "# 튜닝 대상 필터링\n",
    "need_tune = best_df[\n",
    "    (best_df[\"test_f1\"] < F1_LOW) |\n",
    "    (best_df[\"pos_gap\"] > POS_GAP) |\n",
    "    ((best_df[\"churn_rate\"] < 0.35) & (best_df[\"pos_mult\"] > POS_MULT))\n",
    "].copy()\n",
    "\n",
    "MAX_TUNE_GAMES = 20 # 최대 20개 제한\n",
    "need_tune = need_tune.sort_values(\"test_f1\", ascending=True).head(MAX_TUNE_GAMES)\n",
    "\n",
    "tune_appids = need_tune[\"appid\"].astype(int).tolist()\n",
    "\n",
    "print(\"튜닝 대상 appid 개수:\", len(tune_appids))\n",
    "\n",
    "display_cols = [\n",
    "    \"appid\",\"n_rows\",\"churn_rate\",\n",
    "    \"best_valid_f1\",\"best_thr\",\n",
    "    \"test_precision\",\"test_recall\",\"test_f1\",\"test_pred_pos_rate\",\n",
    "    \"pos_gap\",\"pos_mult\"\n",
    "]\n",
    "display(need_tune[display_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed79d82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tune_appids: 20\n"
     ]
    }
   ],
   "source": [
    "# 13. 튜닝 설정 + 저장 폴더 준비\n",
    "os.makedirs(\"dl_model_tuned\", exist_ok=True)\n",
    "\n",
    "# 데이터 분할은 ML과 동일 흐름\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.20\n",
    "VAL_SIZE_IN_TRAIN = 0.20\n",
    "\n",
    "# 튜닝 후보(너무 폭발하지 않게 \"작게\" 잡음)\n",
    "HIDDEN_CANDS  = [(128,64), (256,128), (256,128,64)] # 모델 용량(복잡도) 조절\n",
    "DROPOUT_CANDS = [0.15, 0.25, 0.35]                  # 과적합 방지 강도\n",
    "LR_CANDS      = [3e-4, 1e-3, 2e-3]                  # 학습 속도/수렴 특성\n",
    "WD_CANDS      = [0.0, 1e-5, 1e-4]                   # 과적합 방지(가중치 크기 억제)\n",
    "BATCH_CANDS   = [1024, 2048, 4096]                  # 업데이트 노이즈/속도/일반화에 영향\n",
    "\n",
    "# 학습 길이(튜닝은 조금 더 여유)\n",
    "MAX_EPOCHS = 40\n",
    "PATIENCE   = 6\n",
    "\n",
    "# threshold grid는 기존 그대로 쓰면 됨\n",
    "THR_GRID = np.round(np.arange(0.10, 0.91, 0.02), 2)\n",
    "\n",
    "print(\"tune_appids:\", len(tune_appids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ff36b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. threshold 선택 함수를 튜닝용으로 하나 더 추가\n",
    "#   recall이 너무 높게 나오는(=양성 과대예측) 걸 줄이려면\n",
    "#   F1 최대 대신 precision 최소조건 걸고 F1 최대를 택하는 방식이 도움이 됨.\n",
    "def best_threshold_by_f1_min_precision(y_true, proba, thr_grid=THR_GRID, min_precision=0.55):\n",
    "\n",
    "    # 1. precision >= min_precision 만족하는 thr 중에서\n",
    "    # 2. F1이 최대가 되는 thr 선택\n",
    "    # 3. 만족하는 thr이 하나도 없으면 -> 그냥 best_threshold_by_f1로 fallback\n",
    "\n",
    "    best = None  # (f1, thr, precision)\n",
    "    # threshold 하나씩 보면서 pred 생성, precision 계산, precision이 min_precision 미만이면 제외\n",
    "    # 남은 것 중 F1이 가장 큰 thr 선택\n",
    "    for thr in thr_grid:\n",
    "        pred = (proba >= thr).astype(int)\n",
    "        p = precision_score(y_true, pred, zero_division=0)\n",
    "        if p < min_precision:\n",
    "            continue\n",
    "        f1 = f1_score(y_true, pred, zero_division=0)\n",
    "        cand = (f1, float(thr), float(p))\n",
    "        if (best is None) or (cand[0] > best[0]):\n",
    "            best = cand\n",
    "\n",
    "    if best is None:\n",
    "        # 조건 만족하는 임계값 없으면 원래 방식으로 돌아감\n",
    "        thr, f1v = best_threshold_by_f1(y_true, proba, thr_grid=thr_grid)\n",
    "        return float(thr), float(f1v), float(precision_score(y_true, (proba>=thr).astype(int), zero_division=0))\n",
    "\n",
    "    return best[1], best[0], best[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 튜닝 1회(하이퍼파라미터 1세트) 실행 함수\n",
    "# val 기준 thr 선택 -> test 평가까지 한 번에 리턴\n",
    "def run_one_config_for_game(gdf, *, hidden_dims, dropout, lr, weight_decay, batch_size,\n",
    "                            use_min_precision=True, min_precision=0.55):\n",
    "    # X/y 구성\n",
    "    X = gdf[FEATURES].apply(pd.to_numeric, errors=\"coerce\").fillna(0).to_numpy(dtype=np.float32)\n",
    "    y = gdf[TARGET].astype(int).to_numpy(dtype=np.int64)\n",
    "\n",
    "    # split\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full,\n",
    "        test_size=VAL_SIZE_IN_TRAIN, random_state=RANDOM_STATE, stratify=y_train_full\n",
    "    )\n",
    "\n",
    "    # 스케일링(게임별 fit)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_val_s   = scaler.transform(X_val)\n",
    "    X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "    # 학습(기존 유틸 사용)\n",
    "    model, pos_weight, best_epoch, best_val_f1 = train_mlp_one_game(\n",
    "        X_train_s, y_train, X_val_s, y_val,\n",
    "        hidden_dims=hidden_dims,\n",
    "        dropout=dropout,\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "        batch_size=batch_size,\n",
    "        max_epochs=MAX_EPOCHS,\n",
    "        patience=PATIENCE\n",
    "    )\n",
    "\n",
    "    # val proba -> thr 선택\n",
    "    val_loader  = DataLoader(TabDataset(X_val_s, y_val), batch_size=4096, shuffle=False)\n",
    "    val_proba   = predict_proba_torch(model, val_loader)\n",
    "\n",
    "    # True일 때 precision이 min_precision 이상인 임계값 중에서 F1 최대 선택\n",
    "    # False이면 그냥 F1이 최대 임계값 선택\n",
    "    if use_min_precision:\n",
    "        best_thr, val_f1, val_prec = best_threshold_by_f1_min_precision(\n",
    "            y_val, val_proba, thr_grid=THR_GRID, min_precision=min_precision\n",
    "        )\n",
    "    else:\n",
    "        best_thr, val_f1 = best_threshold_by_f1(y_val, val_proba, thr_grid=THR_GRID)\n",
    "        val_prec = float(precision_score(y_val, (val_proba>=best_thr).astype(int), zero_division=0))\n",
    "\n",
    "    # test 평가\n",
    "    test_loader = DataLoader(TabDataset(X_test_s, y_test), batch_size=4096, shuffle=False)\n",
    "    test_proba  = predict_proba_torch(model, test_loader)\n",
    "    m = eval_from_proba(y_test, test_proba, best_thr)\n",
    "\n",
    "    # all-1 baseline 비교\n",
    "    churn_rate = float(y.mean())\n",
    "    all1_f1 = f1_score(y_test, np.ones_like(y_test), zero_division=0)\n",
    "    gain_vs_all1 = float(m[\"f1\"] - all1_f1)\n",
    "\n",
    "    row = {\n",
    "        \"n_rows\": int(len(gdf)),    # 데이터 메타: n_rows, churn_rate\n",
    "        \"churn_rate\": churn_rate,\n",
    "        \"pos_weight\": float(pos_weight), # 불균형 보정\n",
    "\n",
    "        \"hidden_dims\": str(hidden_dims),\n",
    "        \"dropout\": float(dropout),\n",
    "        \"lr\": float(lr),\n",
    "        \"weight_decay\": float(weight_decay),\n",
    "        \"batch_size\": int(batch_size),\n",
    "\n",
    "        \"best_epoch\": int(best_epoch),\n",
    "        \"best_valid_f1\": float(best_val_f1),\n",
    "\n",
    "        \"best_thr\": float(best_thr),\n",
    "        \"val_f1\": float(val_f1),\n",
    "        \"val_precision\": float(val_prec),\n",
    "\n",
    "        \"test_f1\": float(m[\"f1\"]),\n",
    "        \"test_precision\": float(m[\"precision\"]),\n",
    "        \"test_recall\": float(m[\"recall\"]),\n",
    "        \"test_roc_auc\": float(m[\"roc_auc\"]),\n",
    "        \"test_pred_pos_rate\": float(m[\"pred_pos_rate\"]),\n",
    "        \"tn\": int(m[\"tn\"]), \"fp\": int(m[\"fp\"]), \"fn\": int(m[\"fn\"]), \"tp\": int(m[\"tp\"]), # 혼동행렬\n",
    "        \"all1_f1\": float(all1_f1),\n",
    "        \"gain_vs_all1\": float(gain_vs_all1),\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model_state_dict\": {k: v.cpu() for k, v in model.state_dict().items()},\n",
    "        \"scaler\": scaler,\n",
    "        \"features\": FEATURES,\n",
    "        \"best_thr\": float(best_thr),\n",
    "        \"hparams\": {\n",
    "            \"hidden_dims\": hidden_dims,\n",
    "            \"dropout\": float(dropout),\n",
    "            \"lr\": float(lr),\n",
    "            \"weight_decay\": float(weight_decay),\n",
    "            \"batch_size\": int(batch_size),\n",
    "        },\n",
    "        \"meta\": {\n",
    "            \"pos_weight\": float(pos_weight),\n",
    "            \"best_epoch\": int(best_epoch),\n",
    "            \"best_valid_f1\": float(best_val_f1),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return row, payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6247480b",
   "metadata": {},
   "source": [
    "### 튜닝 후보 조합 만들기 + 게임당 25개 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee1ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total config candidates: 243\n",
      "sampled per-game configs: 5\n"
     ]
    }
   ],
   "source": [
    "# 16. 튜닝 후보 조합 만들기 (너무 많으면 제한 걸기)\n",
    "# 전체 조합이 크면 일부만 샘플링해서 쓰자.\n",
    "\n",
    "# hidden 3 × dropout 3 × lr 3 × wd 3 × batch 3 = 243\n",
    "# itertools.product는 모든 조합을 생성\n",
    "all_configs = list(itertools.product(HIDDEN_CANDS, DROPOUT_CANDS, LR_CANDS, WD_CANDS, BATCH_CANDS))\n",
    "print(\"total config candidates:\", len(all_configs))\n",
    "\n",
    "MAX_CONFIGS_PER_GAME = 5  # 너무 오래 걸리면 15~20으로 \n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# k: 샘플링할 개수\n",
    "# 조합수가 k보다 작으면 학습x\n",
    "def sample_configs(configs, k):\n",
    "    if len(configs) <= k:\n",
    "        return configs\n",
    "    idx = rng.choice(len(configs), size=k, replace=False)\n",
    "    return [configs[i] for i in idx]\n",
    "\n",
    "sampled_configs = sample_configs(all_configs, MAX_CONFIGS_PER_GAME)\n",
    "print(\"sampled per-game configs:\", len(sampled_configs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89e06cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DL Tuning: 100%|██████████| 20/20 [1:27:47<00:00, 263.36s/game, appid=3159330 hd=(256, 128, 64) dr=0.35 lr=0.002 wd=1e-05 bs=2048] \n"
     ]
    }
   ],
   "source": [
    "# 17. 튜닝 메인 루프 (tune_appids만)\n",
    "# 기준: val_f1 우선, 동점이면 test_f1, 그 다음엔 test_pred_pos_rate 낮은 쪽 선호(과대예측 억제)\n",
    "\n",
    "tuned_rows = []\n",
    "pbar = tqdm(tune_appids, desc=\"DL Tuning\", unit=\"game\")\n",
    "\n",
    "for appid in pbar:\n",
    "    gdf = df_model[df_model[\"appid\"] == appid].copy()\n",
    "    gdf = gdf.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    if gdf[TARGET].nunique() < 2:\n",
    "        continue\n",
    "\n",
    "    best_row = None       # config 25개 중 최고를 담을 변수\n",
    "    best_payload = None   # Min_prec는 threshold 선택시 precision 반환\n",
    "\n",
    "    # 최소 precision 설정값\n",
    "    MIN_PREC = 0.55\n",
    "\n",
    "    # 샘플링 된 config들만 실행\n",
    "    for (hidden_dims, dropout, lr, wd, bs) in sampled_configs:\n",
    "        pbar.set_postfix_str(f\"appid={appid} hd={hidden_dims} dr={dropout} lr={lr} wd={wd} bs={bs}\")\n",
    "\n",
    "        # 한 설정(config)에 대해\n",
    "        # split / scaling / train / thr 선택 / test 평가까지 수행\n",
    "        row, payload = run_one_config_for_game(\n",
    "            gdf,\n",
    "            hidden_dims=hidden_dims,\n",
    "            dropout=dropout,\n",
    "            lr=lr,\n",
    "            weight_decay=wd,\n",
    "            batch_size=bs,\n",
    "            use_min_precision=True,\n",
    "            min_precision=MIN_PREC\n",
    "        )\n",
    "\n",
    "\n",
    "        row[\"appid\"] = int(appid)\n",
    "\n",
    "        if best_row is None:\n",
    "            best_row, best_payload = row, payload\n",
    "        else:\n",
    "            # 튜닝은 val 성능을 우선으로 선택\n",
    "            key_new = (row[\"val_f1\"], row[\"test_f1\"], -row[\"test_pred_pos_rate\"])\n",
    "            key_old = (best_row[\"val_f1\"], best_row[\"test_f1\"], -best_row[\"test_pred_pos_rate\"])\n",
    "            if key_new > key_old:\n",
    "                best_row, best_payload = row, payload\n",
    "\n",
    "    # 유효한 config 없으면 스킵\n",
    "    if best_row is None:\n",
    "        continue\n",
    "    \n",
    "    # 게임별 best 저장\n",
    "    tuned_rows.append(best_row)\n",
    "\n",
    "    # appid별 best 저장\n",
    "    joblib.dump(best_payload, f\"dl_model_tuned/model_{int(appid)}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcda04d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "튜닝 완료 게임 수: 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "      <th>churn_rate</th>\n",
       "      <th>pos_weight</th>\n",
       "      <th>hidden_dims</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>best_valid_f1</th>\n",
       "      <th>...</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_pred_pos_rate</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>all1_f1</th>\n",
       "      <th>gain_vs_all1</th>\n",
       "      <th>appid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37631</td>\n",
       "      <td>0.179878</td>\n",
       "      <td>4.559326</td>\n",
       "      <td>(256, 128, 64)</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2048</td>\n",
       "      <td>15</td>\n",
       "      <td>0.448649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338996</td>\n",
       "      <td>0.734422</td>\n",
       "      <td>0.110004</td>\n",
       "      <td>5804</td>\n",
       "      <td>369</td>\n",
       "      <td>895</td>\n",
       "      <td>459</td>\n",
       "      <td>0.304921</td>\n",
       "      <td>0.115794</td>\n",
       "      <td>3513350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48982</td>\n",
       "      <td>0.204279</td>\n",
       "      <td>3.895066</td>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1024</td>\n",
       "      <td>13</td>\n",
       "      <td>0.472914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325337</td>\n",
       "      <td>0.740511</td>\n",
       "      <td>0.116873</td>\n",
       "      <td>7302</td>\n",
       "      <td>494</td>\n",
       "      <td>1350</td>\n",
       "      <td>651</td>\n",
       "      <td>0.339210</td>\n",
       "      <td>0.074649</td>\n",
       "      <td>230410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41971</td>\n",
       "      <td>0.188463</td>\n",
       "      <td>4.306203</td>\n",
       "      <td>(256, 128, 64)</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2048</td>\n",
       "      <td>14</td>\n",
       "      <td>0.445074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292035</td>\n",
       "      <td>0.719350</td>\n",
       "      <td>0.102204</td>\n",
       "      <td>6417</td>\n",
       "      <td>396</td>\n",
       "      <td>1120</td>\n",
       "      <td>462</td>\n",
       "      <td>0.317129</td>\n",
       "      <td>0.061559</td>\n",
       "      <td>394360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36162</td>\n",
       "      <td>0.174050</td>\n",
       "      <td>4.745531</td>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1024</td>\n",
       "      <td>19</td>\n",
       "      <td>0.377222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570294</td>\n",
       "      <td>0.681688</td>\n",
       "      <td>0.369556</td>\n",
       "      <td>4019</td>\n",
       "      <td>1955</td>\n",
       "      <td>541</td>\n",
       "      <td>718</td>\n",
       "      <td>0.296514</td>\n",
       "      <td>0.068694</td>\n",
       "      <td>3405690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300088</td>\n",
       "      <td>0.157780</td>\n",
       "      <td>5.338063</td>\n",
       "      <td>(256, 128)</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>0.446716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269166</td>\n",
       "      <td>0.757892</td>\n",
       "      <td>0.078910</td>\n",
       "      <td>48361</td>\n",
       "      <td>2187</td>\n",
       "      <td>6921</td>\n",
       "      <td>2549</td>\n",
       "      <td>0.272565</td>\n",
       "      <td>0.086297</td>\n",
       "      <td>2807960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32102</td>\n",
       "      <td>0.222946</td>\n",
       "      <td>3.485590</td>\n",
       "      <td>(256, 128, 64)</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2048</td>\n",
       "      <td>19</td>\n",
       "      <td>0.483516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268156</td>\n",
       "      <td>0.721557</td>\n",
       "      <td>0.117427</td>\n",
       "      <td>4619</td>\n",
       "      <td>370</td>\n",
       "      <td>1048</td>\n",
       "      <td>384</td>\n",
       "      <td>0.364701</td>\n",
       "      <td>-0.013375</td>\n",
       "      <td>3159330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78701</td>\n",
       "      <td>0.268586</td>\n",
       "      <td>2.723241</td>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1024</td>\n",
       "      <td>18</td>\n",
       "      <td>0.498222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249290</td>\n",
       "      <td>0.686852</td>\n",
       "      <td>0.127374</td>\n",
       "      <td>10562</td>\n",
       "      <td>951</td>\n",
       "      <td>3174</td>\n",
       "      <td>1054</td>\n",
       "      <td>0.423456</td>\n",
       "      <td>-0.085256</td>\n",
       "      <td>3489700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>193853</td>\n",
       "      <td>0.173090</td>\n",
       "      <td>4.777452</td>\n",
       "      <td>(256, 128)</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>4096</td>\n",
       "      <td>27</td>\n",
       "      <td>0.440779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227388</td>\n",
       "      <td>0.739390</td>\n",
       "      <td>0.069898</td>\n",
       "      <td>30876</td>\n",
       "      <td>1184</td>\n",
       "      <td>5185</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.295106</td>\n",
       "      <td>0.028851</td>\n",
       "      <td>578080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43061</td>\n",
       "      <td>0.084206</td>\n",
       "      <td>10.873330</td>\n",
       "      <td>(256, 128, 64)</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2048</td>\n",
       "      <td>18</td>\n",
       "      <td>0.356185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194483</td>\n",
       "      <td>0.785045</td>\n",
       "      <td>0.027052</td>\n",
       "      <td>7796</td>\n",
       "      <td>92</td>\n",
       "      <td>584</td>\n",
       "      <td>141</td>\n",
       "      <td>0.155280</td>\n",
       "      <td>0.139084</td>\n",
       "      <td>1973530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>83054</td>\n",
       "      <td>0.287054</td>\n",
       "      <td>2.483681</td>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1024</td>\n",
       "      <td>16</td>\n",
       "      <td>0.470781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191695</td>\n",
       "      <td>0.651476</td>\n",
       "      <td>0.094275</td>\n",
       "      <td>11191</td>\n",
       "      <td>652</td>\n",
       "      <td>3854</td>\n",
       "      <td>914</td>\n",
       "      <td>0.446045</td>\n",
       "      <td>-0.157444</td>\n",
       "      <td>108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>252277</td>\n",
       "      <td>0.186660</td>\n",
       "      <td>4.357401</td>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1024</td>\n",
       "      <td>18</td>\n",
       "      <td>0.386257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173710</td>\n",
       "      <td>0.674200</td>\n",
       "      <td>0.059438</td>\n",
       "      <td>39675</td>\n",
       "      <td>1363</td>\n",
       "      <td>7782</td>\n",
       "      <td>1636</td>\n",
       "      <td>0.314594</td>\n",
       "      <td>-0.051084</td>\n",
       "      <td>1808500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>53036</td>\n",
       "      <td>0.217230</td>\n",
       "      <td>3.602929</td>\n",
       "      <td>(256, 128, 64)</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2048</td>\n",
       "      <td>16</td>\n",
       "      <td>0.394158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157986</td>\n",
       "      <td>0.643224</td>\n",
       "      <td>0.061746</td>\n",
       "      <td>8013</td>\n",
       "      <td>291</td>\n",
       "      <td>1940</td>\n",
       "      <td>364</td>\n",
       "      <td>0.356877</td>\n",
       "      <td>-0.110848</td>\n",
       "      <td>1551360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>148012</td>\n",
       "      <td>0.139239</td>\n",
       "      <td>6.181729</td>\n",
       "      <td>(256, 128, 64)</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2048</td>\n",
       "      <td>4</td>\n",
       "      <td>0.361931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157205</td>\n",
       "      <td>0.713447</td>\n",
       "      <td>0.040773</td>\n",
       "      <td>24922</td>\n",
       "      <td>559</td>\n",
       "      <td>3474</td>\n",
       "      <td>648</td>\n",
       "      <td>0.244448</td>\n",
       "      <td>-0.001250</td>\n",
       "      <td>553850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>340625</td>\n",
       "      <td>0.219902</td>\n",
       "      <td>3.547541</td>\n",
       "      <td>(256, 128, 64)</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2048</td>\n",
       "      <td>37</td>\n",
       "      <td>0.425772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146118</td>\n",
       "      <td>0.676329</td>\n",
       "      <td>0.057791</td>\n",
       "      <td>51396</td>\n",
       "      <td>1748</td>\n",
       "      <td>12792</td>\n",
       "      <td>2189</td>\n",
       "      <td>0.360528</td>\n",
       "      <td>-0.129108</td>\n",
       "      <td>3241660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>108874</td>\n",
       "      <td>0.265821</td>\n",
       "      <td>2.761959</td>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1024</td>\n",
       "      <td>5</td>\n",
       "      <td>0.432250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130788</td>\n",
       "      <td>0.625065</td>\n",
       "      <td>0.065534</td>\n",
       "      <td>15317</td>\n",
       "      <td>670</td>\n",
       "      <td>5031</td>\n",
       "      <td>757</td>\n",
       "      <td>0.419983</td>\n",
       "      <td>-0.210143</td>\n",
       "      <td>1245620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>119802</td>\n",
       "      <td>0.257667</td>\n",
       "      <td>2.880948</td>\n",
       "      <td>(256, 128, 64)</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2048</td>\n",
       "      <td>13</td>\n",
       "      <td>0.439646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>0.642791</td>\n",
       "      <td>0.057969</td>\n",
       "      <td>17182</td>\n",
       "      <td>605</td>\n",
       "      <td>5390</td>\n",
       "      <td>784</td>\n",
       "      <td>0.409756</td>\n",
       "      <td>-0.202431</td>\n",
       "      <td>1091500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>138626</td>\n",
       "      <td>0.219338</td>\n",
       "      <td>3.559096</td>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1024</td>\n",
       "      <td>22</td>\n",
       "      <td>0.406547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084690</td>\n",
       "      <td>0.634626</td>\n",
       "      <td>0.034192</td>\n",
       "      <td>21212</td>\n",
       "      <td>433</td>\n",
       "      <td>5566</td>\n",
       "      <td>515</td>\n",
       "      <td>0.359748</td>\n",
       "      <td>-0.213212</td>\n",
       "      <td>3240220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30831</td>\n",
       "      <td>0.233110</td>\n",
       "      <td>3.290280</td>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>0.398125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064673</td>\n",
       "      <td>0.614410</td>\n",
       "      <td>0.023837</td>\n",
       "      <td>4675</td>\n",
       "      <td>54</td>\n",
       "      <td>1345</td>\n",
       "      <td>93</td>\n",
       "      <td>0.378172</td>\n",
       "      <td>-0.260822</td>\n",
       "      <td>294100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>92151</td>\n",
       "      <td>0.227171</td>\n",
       "      <td>3.401851</td>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>0.404160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055171</td>\n",
       "      <td>0.623205</td>\n",
       "      <td>0.023710</td>\n",
       "      <td>14038</td>\n",
       "      <td>206</td>\n",
       "      <td>3956</td>\n",
       "      <td>231</td>\n",
       "      <td>0.370236</td>\n",
       "      <td>-0.270323</td>\n",
       "      <td>227300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>272473</td>\n",
       "      <td>0.184881</td>\n",
       "      <td>4.408871</td>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1024</td>\n",
       "      <td>18</td>\n",
       "      <td>0.350254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027196</td>\n",
       "      <td>0.630957</td>\n",
       "      <td>0.009065</td>\n",
       "      <td>44200</td>\n",
       "      <td>220</td>\n",
       "      <td>9801</td>\n",
       "      <td>274</td>\n",
       "      <td>0.312064</td>\n",
       "      <td>-0.260215</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_rows  churn_rate  pos_weight     hidden_dims  dropout      lr  \\\n",
       "0    37631    0.179878    4.559326  (256, 128, 64)     0.35  0.0020   \n",
       "1    48982    0.204279    3.895066       (128, 64)     0.15  0.0003   \n",
       "2    41971    0.188463    4.306203  (256, 128, 64)     0.35  0.0020   \n",
       "3    36162    0.174050    4.745531       (128, 64)     0.15  0.0020   \n",
       "4   300088    0.157780    5.338063      (256, 128)     0.35  0.0010   \n",
       "5    32102    0.222946    3.485590  (256, 128, 64)     0.35  0.0010   \n",
       "6    78701    0.268586    2.723241       (128, 64)     0.15  0.0020   \n",
       "7   193853    0.173090    4.777452      (256, 128)     0.35  0.0010   \n",
       "8    43061    0.084206   10.873330  (256, 128, 64)     0.35  0.0020   \n",
       "9    83054    0.287054    2.483681       (128, 64)     0.15  0.0003   \n",
       "10  252277    0.186660    4.357401       (128, 64)     0.15  0.0020   \n",
       "11   53036    0.217230    3.602929  (256, 128, 64)     0.35  0.0020   \n",
       "12  148012    0.139239    6.181729  (256, 128, 64)     0.35  0.0020   \n",
       "13  340625    0.219902    3.547541  (256, 128, 64)     0.35  0.0010   \n",
       "14  108874    0.265821    2.761959       (128, 64)     0.15  0.0020   \n",
       "15  119802    0.257667    2.880948  (256, 128, 64)     0.35  0.0010   \n",
       "16  138626    0.219338    3.559096       (128, 64)     0.15  0.0020   \n",
       "17   30831    0.233110    3.290280       (128, 64)     0.15  0.0020   \n",
       "18   92151    0.227171    3.401851       (128, 64)     0.15  0.0020   \n",
       "19  272473    0.184881    4.408871       (128, 64)     0.15  0.0020   \n",
       "\n",
       "    weight_decay  batch_size  best_epoch  best_valid_f1  ...  test_recall  \\\n",
       "0        0.00001        2048          15       0.448649  ...     0.338996   \n",
       "1        0.00010        1024          13       0.472914  ...     0.325337   \n",
       "2        0.00001        2048          14       0.445074  ...     0.292035   \n",
       "3        0.00010        1024          19       0.377222  ...     0.570294   \n",
       "4        0.00010        4096          24       0.446716  ...     0.269166   \n",
       "5        0.00010        2048          19       0.483516  ...     0.268156   \n",
       "6        0.00010        1024          18       0.498222  ...     0.249290   \n",
       "7        0.00010        4096          27       0.440779  ...     0.227388   \n",
       "8        0.00001        2048          18       0.356185  ...     0.194483   \n",
       "9        0.00010        1024          16       0.470781  ...     0.191695   \n",
       "10       0.00010        1024          18       0.386257  ...     0.173710   \n",
       "11       0.00001        2048          16       0.394158  ...     0.157986   \n",
       "12       0.00001        2048           4       0.361931  ...     0.157205   \n",
       "13       0.00010        2048          37       0.425772  ...     0.146118   \n",
       "14       0.00010        1024           5       0.432250  ...     0.130788   \n",
       "15       0.00010        2048          13       0.439646  ...     0.126984   \n",
       "16       0.00010        1024          22       0.406547  ...     0.084690   \n",
       "17       0.00010        1024           2       0.398125  ...     0.064673   \n",
       "18       0.00010        1024           2       0.404160  ...     0.055171   \n",
       "19       0.00010        1024          18       0.350254  ...     0.027196   \n",
       "\n",
       "    test_roc_auc  test_pred_pos_rate     tn    fp     fn    tp   all1_f1  \\\n",
       "0       0.734422            0.110004   5804   369    895   459  0.304921   \n",
       "1       0.740511            0.116873   7302   494   1350   651  0.339210   \n",
       "2       0.719350            0.102204   6417   396   1120   462  0.317129   \n",
       "3       0.681688            0.369556   4019  1955    541   718  0.296514   \n",
       "4       0.757892            0.078910  48361  2187   6921  2549  0.272565   \n",
       "5       0.721557            0.117427   4619   370   1048   384  0.364701   \n",
       "6       0.686852            0.127374  10562   951   3174  1054  0.423456   \n",
       "7       0.739390            0.069898  30876  1184   5185  1526  0.295106   \n",
       "8       0.785045            0.027052   7796    92    584   141  0.155280   \n",
       "9       0.651476            0.094275  11191   652   3854   914  0.446045   \n",
       "10      0.674200            0.059438  39675  1363   7782  1636  0.314594   \n",
       "11      0.643224            0.061746   8013   291   1940   364  0.356877   \n",
       "12      0.713447            0.040773  24922   559   3474   648  0.244448   \n",
       "13      0.676329            0.057791  51396  1748  12792  2189  0.360528   \n",
       "14      0.625065            0.065534  15317   670   5031   757  0.419983   \n",
       "15      0.642791            0.057969  17182   605   5390   784  0.409756   \n",
       "16      0.634626            0.034192  21212   433   5566   515  0.359748   \n",
       "17      0.614410            0.023837   4675    54   1345    93  0.378172   \n",
       "18      0.623205            0.023710  14038   206   3956   231  0.370236   \n",
       "19      0.630957            0.009065  44200   220   9801   274  0.312064   \n",
       "\n",
       "    gain_vs_all1    appid  \n",
       "0       0.115794  3513350  \n",
       "1       0.074649   230410  \n",
       "2       0.061559   394360  \n",
       "3       0.068694  3405690  \n",
       "4       0.086297  2807960  \n",
       "5      -0.013375  3159330  \n",
       "6      -0.085256  3489700  \n",
       "7       0.028851   578080  \n",
       "8       0.139084  1973530  \n",
       "9      -0.157444   108600  \n",
       "10     -0.051084  1808500  \n",
       "11     -0.110848  1551360  \n",
       "12     -0.001250   553850  \n",
       "13     -0.129108  3241660  \n",
       "14     -0.210143  1245620  \n",
       "15     -0.202431  1091500  \n",
       "16     -0.213212  3240220  \n",
       "17     -0.260822   294100  \n",
       "18     -0.270323   227300  \n",
       "19     -0.260215      730  \n",
       "\n",
       "[20 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 18. 튜닝 결과 테이블 + 기존(best_df)와 비교\n",
    "\n",
    "tuned_df = pd.DataFrame(tuned_rows).sort_values(\"test_f1\", ascending=False).reset_index(drop=True)\n",
    "print(\"튜닝 완료 게임 수:\", len(tuned_df))\n",
    "display(tuned_df.head(30))\n",
    "\n",
    "# # 기존 결과(best_df)에서 튜닝 대상만 뽑아서 비교\n",
    "# base_part = best_df[best_df[\"appid\"].isin(tune_appids)].copy()\n",
    "# base_part = base_part[[\n",
    "#     \"appid\",\"n_rows\",\"churn_rate\",\n",
    "#     \"best_valid_f1\",\"best_thr\",\n",
    "#     \"test_precision\",\"test_recall\",\"test_f1\",\"test_pred_pos_rate\"\n",
    "# ]].rename(columns={\n",
    "#     \"best_valid_f1\":\"base_best_valid_f1\",\n",
    "#     \"best_thr\":\"base_best_thr\",\n",
    "#     \"test_precision\":\"base_test_precision\",\n",
    "#     \"test_recall\":\"base_test_recall\",\n",
    "#     \"test_f1\":\"base_test_f1\",\n",
    "#     \"test_pred_pos_rate\":\"base_test_pred_pos_rate\"\n",
    "# })\n",
    "\n",
    "# # appid 기준으로 base와 tuned를 붙임\n",
    "# # left join이라 base에 있는 appid를 유지, tuned가 없는 경우 NaN\n",
    "# cmp = base_part.merge(\n",
    "#     tuned_df[[\n",
    "#         \"appid\",\"best_valid_f1\",\"best_thr\",\n",
    "#         \"test_precision\",\"test_recall\",\"test_f1\",\"test_pred_pos_rate\",\n",
    "#         \"hidden_dims\",\"dropout\",\"lr\",\"weight_decay\",\"batch_size\"\n",
    "#     ]],\n",
    "#     on=\"appid\",\n",
    "#     how=\"left\"\n",
    "# )\n",
    "\n",
    "# # 개선량 계산\n",
    "# # delta_f1 > 0이면 튜닝으로 F1 개선\n",
    "# # delta_pos_rate < 0이면 과대예측(예측 양성 비율)이 줄어든 것\n",
    "# cmp[\"delta_f1\"] = cmp[\"test_f1\"] - cmp[\"base_test_f1\"]\n",
    "# cmp[\"delta_pos_rate\"] = cmp[\"test_pred_pos_rate\"] - cmp[\"base_test_pred_pos_rate\"]\n",
    "\n",
    "# cmp = cmp.sort_values(\"delta_f1\", ascending=False).reset_index(drop=True)\n",
    "# display(cmp.head(30))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
